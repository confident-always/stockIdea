#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä½¿ç”¨Tushareçš„bak_basicæ¥å£æ›´æ–°Aè‚¡è‚¡ç¥¨åˆ—è¡¨

åŠŸèƒ½ï¼š
1. ä»Tushareè·å–æœ€æ–°çš„è‚¡ç¥¨æ•°æ®
2. åŒ…å«å®Œæ•´çš„è´¢åŠ¡æŒ‡æ ‡
3. è‡ªåŠ¨æ›´æ–°stocklist.csv

ä½œè€…ï¼šAI Assistant
æ—¥æœŸï¼š2025-10-22
å‚è€ƒï¼šhttps://tushare.pro/document/2?doc_id=262
"""

import tushare as ts
import pandas as pd
import os
from datetime import datetime
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('update_stocklist.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)


def load_tushare_token():
    """ä»é…ç½®æ–‡ä»¶åŠ è½½Tushare token"""
    try:
        token_file = '.tushare_token'
        if os.path.exists(token_file):
            with open(token_file, 'r', encoding='utf-8') as f:
                token = f.read().strip()
                if token:
                    logger.info("âœ… å·²åŠ è½½Tushare token")
                    return token
    except Exception as e:
        logger.error(f"âŒ è¯»å–tokenå¤±è´¥: {e}")
    return None


def get_latest_trade_date():
    """è·å–æœ€æ–°äº¤æ˜“æ—¥æœŸ"""
    try:
        # è·å–ä»Šå¤©çš„æ—¥æœŸ
        today = datetime.now().strftime('%Y%m%d')
        logger.info(f"ğŸ“… å°è¯•è·å–æ—¥æœŸ: {today}")
        return today
    except Exception as e:
        logger.error(f"âŒ è·å–æ—¥æœŸå¤±è´¥: {e}")
        return None


def fetch_stock_data(token, trade_date):
    """ä»Tushareè·å–è‚¡ç¥¨æ•°æ®"""
    try:
        logger.info("=" * 70)
        logger.info("ğŸš€ å¼€å§‹ä»Tushareè·å–è‚¡ç¥¨æ•°æ®")
        logger.info("=" * 70)
        logger.info("")
        
        # è®¾ç½®token
        ts.set_token(token)
        pro = ts.pro_api()
        
        logger.info(f"ğŸ“¥ æ­£åœ¨è·å– {trade_date} çš„è‚¡ç¥¨æ•°æ®...")
        logger.info("   ä½¿ç”¨æ¥å£: bak_basic")
        logger.info("")
        
        # ä½¿ç”¨bak_basicæ¥å£è·å–æ•°æ®
        # æ ¹æ®æ–‡æ¡£ï¼ŒåŒ…å«æ‰€æœ‰éœ€è¦çš„å­—æ®µ
        fields = [
            'trade_date', 'ts_code', 'name', 'industry', 'area',
            'pe', 'float_share', 'total_share', 'total_assets',
            'liquid_assets', 'fixed_assets', 'reserved', 'reserved_pershare',
            'eps', 'bvps', 'pb', 'list_date', 'undp', 'per_undp',
            'rev_yoy', 'profit_yoy', 'gpr', 'npr', 'holder_num'
        ]
        
        df = pro.bak_basic(
            trade_date=trade_date,
            fields=','.join(fields)
        )
        
        if df is None or df.empty:
            logger.warning(f"âš ï¸ {trade_date} æ— æ•°æ®ï¼Œå¯èƒ½ä¸æ˜¯äº¤æ˜“æ—¥")
            # å°è¯•å‰ä¸€å¤©
            prev_date = get_previous_date(trade_date)
            logger.info(f"ğŸ“¥ å°è¯•è·å– {prev_date} çš„æ•°æ®...")
            df = pro.bak_basic(
                trade_date=prev_date,
                fields=','.join(fields)
            )
        
        if df is not None and not df.empty:
            logger.info(f"âœ… æˆåŠŸè·å– {len(df)} åªè‚¡ç¥¨æ•°æ®")
            logger.info("")
            return df
        else:
            logger.error("âŒ è·å–æ•°æ®å¤±è´¥")
            return None
            
    except Exception as e:
        logger.error(f"âŒ è·å–æ•°æ®å¼‚å¸¸: {e}")
        import traceback
        logger.debug(traceback.format_exc())
        return None


def get_previous_date(date_str):
    """è·å–å‰ä¸€å¤©çš„æ—¥æœŸ"""
    try:
        date_obj = datetime.strptime(date_str, '%Y%m%d')
        from datetime import timedelta
        prev_date = date_obj - timedelta(days=1)
        return prev_date.strftime('%Y%m%d')
    except:
        return date_str


def process_data(df):
    """å¤„ç†æ•°æ®æ ¼å¼"""
    try:
        logger.info("ğŸ”„ æ­£åœ¨å¤„ç†æ•°æ®...")
        
        # åˆ›å»ºsymbolåˆ—ï¼ˆ6ä½è‚¡ç¥¨ä»£ç ï¼‰
        df['symbol'] = df['ts_code'].str.split('.').str[0]
        
        # é‡å‘½ååˆ—ä»¥åŒ¹é…åŸæœ‰æ ¼å¼
        df_result = df[[
            'ts_code', 'symbol', 'name', 'area', 'industry',
            'pe', 'float_share', 'total_share', 'total_assets',
            'liquid_assets', 'fixed_assets', 'reserved', 'reserved_pershare',
            'eps', 'bvps', 'pb', 'list_date', 'undp', 'per_undp',
            'rev_yoy', 'profit_yoy', 'gpr', 'npr', 'holder_num'
        ]].copy()
        
        # å¤„ç†ç©ºå€¼
        df_result['area'] = df_result['area'].fillna('æœªçŸ¥')
        df_result['industry'] = df_result['industry'].fillna('æœªçŸ¥')
        
        # æŒ‰è‚¡ç¥¨ä»£ç æ’åº
        df_result = df_result.sort_values('symbol').reset_index(drop=True)
        
        logger.info(f"âœ… æ•°æ®å¤„ç†å®Œæˆ")
        logger.info("")
        
        return df_result
        
    except Exception as e:
        logger.error(f"âŒ æ•°æ®å¤„ç†å¤±è´¥: {e}")
        import traceback
        logger.debug(traceback.format_exc())
        return None


def backup_file(file_path):
    """å¤‡ä»½ç°æœ‰æ–‡ä»¶"""
    try:
        if os.path.exists(file_path):
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            backup_path = f"{file_path}.backup_{timestamp}"
            import shutil
            shutil.copy2(file_path, backup_path)
            logger.info(f"âœ… å·²å¤‡ä»½: {backup_path}")
            return True
    except Exception as e:
        logger.warning(f"âš ï¸ å¤‡ä»½å¤±è´¥: {e}")
    return False


def save_to_csv(df, file_path):
    """ä¿å­˜åˆ°CSVæ–‡ä»¶"""
    try:
        logger.info(f"ğŸ’¾ æ­£åœ¨ä¿å­˜åˆ° {file_path}...")
        
        df.to_csv(file_path, index=False, encoding='utf-8')
        
        logger.info(f"âœ… ä¿å­˜æˆåŠŸï¼")
        logger.info("")
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        logger.info("ğŸ“Š æ•°æ®ç»Ÿè®¡:")
        logger.info(f"   æ€»è‚¡ç¥¨æ•°: {len(df)}")
        logger.info(f"   ä¸Šæµ·å¸‚åœº: {len(df[df['ts_code'].str.endswith('.SH')])}")
        logger.info(f"   æ·±åœ³å¸‚åœº: {len(df[df['ts_code'].str.endswith('.SZ')])}")
        logger.info(f"   åŒ—äº¬å¸‚åœº: {len(df[df['ts_code'].str.endswith('.BJ')])}")
        logger.info(f"   STè‚¡ç¥¨: {len(df[df['name'].str.contains('ST', na=False)])}")
        
        # æ•°æ®å®Œæ•´æ€§
        has_industry = len(df[df['industry'] != 'æœªçŸ¥'])
        has_area = len(df[df['area'] != 'æœªçŸ¥'])
        logger.info(f"   æœ‰è¡Œä¸šä¿¡æ¯: {has_industry} ({has_industry/len(df)*100:.1f}%)")
        logger.info(f"   æœ‰åœ°åŒºä¿¡æ¯: {has_area} ({has_area/len(df)*100:.1f}%)")
        
        # è´¢åŠ¡æ•°æ®
        has_pe = len(df[df['pe'].notna()])
        logger.info(f"   æœ‰å¸‚ç›ˆç‡æ•°æ®: {has_pe} ({has_pe/len(df)*100:.1f}%)")
        
        logger.info("")
        
        # æ˜¾ç¤ºæ•°æ®ç¤ºä¾‹
        logger.info("ğŸ“ æ•°æ®ç¤ºä¾‹ï¼ˆå‰5è¡Œï¼‰:")
        for idx, row in df.head(5).iterrows():
            logger.info(f"   {row['symbol']} | {row['name']:<8} | {row['area']:<6} | {row['industry']:<10} | PE:{row['pe']}")
        
        logger.info("")
        
    except Exception as e:
        logger.error(f"âŒ ä¿å­˜å¤±è´¥: {e}")
        raise


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description='ä½¿ç”¨Tushareçš„bak_basicæ¥å£æ›´æ–°è‚¡ç¥¨åˆ—è¡¨',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument('-o', '--output', type=str, default='stocklist.csv',
                       help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤: stocklist.csvï¼‰')
    parser.add_argument('--no-backup', action='store_true',
                       help='ä¸å¤‡ä»½æ—§æ–‡ä»¶')
    parser.add_argument('--date', type=str, default=None,
                       help='æŒ‡å®šäº¤æ˜“æ—¥æœŸï¼ˆæ ¼å¼: YYYYMMDDï¼‰ï¼Œé»˜è®¤ä»Šå¤©')
    
    args = parser.parse_args()
    
    try:
        logger.info("=" * 70)
        logger.info("ğŸš€ Aè‚¡è‚¡ç¥¨åˆ—è¡¨æ›´æ–°å·¥å…·ï¼ˆTushare bak_basicï¼‰")
        logger.info("=" * 70)
        logger.info("")
        
        # 1. åŠ è½½token
        token = load_tushare_token()
        if not token:
            logger.error("âŒ æœªæ‰¾åˆ°Tushare token")
            logger.error("   è¯·ç¡®ä¿ .tushare_token æ–‡ä»¶å­˜åœ¨")
            return 1
        
        logger.info("")
        
        # 2. å¤‡ä»½
        if not args.no_backup:
            backup_file(args.output)
            logger.info("")
        
        # 3. è·å–äº¤æ˜“æ—¥æœŸ
        trade_date = args.date if args.date else get_latest_trade_date()
        if not trade_date:
            logger.error("âŒ æ— æ³•ç¡®å®šäº¤æ˜“æ—¥æœŸ")
            return 1
        
        # 4. è·å–æ•°æ®
        df = fetch_stock_data(token, trade_date)
        if df is None:
            logger.error("âŒ è·å–æ•°æ®å¤±è´¥")
            return 1
        
        # 5. å¤„ç†æ•°æ®
        df = process_data(df)
        if df is None:
            logger.error("âŒ æ•°æ®å¤„ç†å¤±è´¥")
            return 1
        
        # 6. ä¿å­˜æ•°æ®
        save_to_csv(df, args.output)
        
        logger.info("=" * 70)
        logger.info("ğŸ‰ æ›´æ–°å®Œæˆï¼")
        logger.info("=" * 70)
        
        return 0
        
    except Exception as e:
        logger.error("")
        logger.error("=" * 70)
        logger.error(f"âŒ æ›´æ–°å¤±è´¥: {e}")
        logger.error("=" * 70)
        
        import traceback
        logger.debug(traceback.format_exc())
        return 1


if __name__ == "__main__":
    import sys
    sys.exit(main())

