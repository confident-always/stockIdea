#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸­é—´å±‚ç”»çº¿è„šæœ¬ - æ•´åˆåŸºç¡€å±‚åŠŸèƒ½å¹¶æ·»åŠ AnchorBackçº¿
åŒ…å«å®Œæ•´çš„åŸºç¡€ç”»çº¿åŠŸèƒ½ + AnchorBackçº¿åˆ†æ

æ ¸å¿ƒç®—æ³•å·®å¼‚:
- AnchorBackç®—æ³•: B = A + N Ã— K (åŠ æ³•æ¨¡å‹)
  å…¶ä¸­:
  A = é”šå®šä½ç‚¹é™„è¿‘5æ ¹Kçº¿æ”¶ç›˜ä»·ä¸­çš„æœ€ä½å€¼
  N = æ­¥é•¿å‚æ•° (0.23 ~ 0.68, æ­¥é•¿0.01)
  K = å¥‡æ•°åºåˆ— (1, 3, 5, 7, 9, ...)
  
åŠŸèƒ½ç‰¹æ€§:
1. ä»resByFilterä¸­æå–æ‰€æœ‰è‚¡ç¥¨æ•°æ®
2. æ™ºèƒ½æ•°æ®éªŒè¯å’Œæ¸…æ´—
3. ZigZagé˜¶æ®µä½ç‚¹æ£€æµ‹
4. é«˜è´¨é‡Kçº¿å›¾è¡¨ç»˜åˆ¶ï¼ˆçº¢æ¶¨ç»¿è·Œï¼‰
5. AnchorBackçº¿åŠ¨æ€ä¼˜åŒ–å’Œç»˜åˆ¶
6. å¤šçº¿ç¨‹æ‰¹é‡å¤„ç†
7. å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•

ä½¿ç”¨æ–¹æ³•:
    # å¤„ç†æŒ‡å®šæ—¥æœŸçš„è‚¡ç¥¨
    python draw_line_back.py --date 2025-10-20
    
    # æŒ‡å®šçº¿ç¨‹æ•°
    python draw_line_back.py --date 2025-10-20 --workers 4
"""

import os
import sys
import json
import pandas as pd
import numpy as np
from pathlib import Path
from typing import List, Dict, Tuple, Optional
import logging
from datetime import datetime
import glob
import argparse
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
import time

# è®¾ç½®matplotlibåç«¯å’Œå­—ä½“
import matplotlib
matplotlib.use('Agg')  # éäº¤äº’å¼åç«¯ï¼Œæ”¯æŒå¤šçº¿ç¨‹
import matplotlib.pyplot as plt

# å­—ä½“é…ç½® - ä½¿ç”¨macOSç³»ç»Ÿæ”¯æŒçš„ä¸­æ–‡å­—ä½“
plt.rcParams['font.family'] = ['Heiti TC', 'PingFang HK', 'Arial Unicode MS', 'Arial', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] [%(threadName)s] %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('draw_lines_back.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

# çº¿ç¨‹é”
progress_lock = threading.Lock()
matplotlib_lock = threading.Lock()
class BackLineDrawer:
    """ä¸­é—´å±‚ç”»çº¿å™¨ - æ•´åˆåŸºç¡€å±‚åŠŸèƒ½å¹¶æ·»åŠ AnchorBackçº¿"""
    
    def __init__(self, config_file: str = "lineConfig.json"):
        """åˆå§‹åŒ–ä¸­é—´å±‚ç”»çº¿å™¨"""
        self.config_file = config_file
        self.percent_list, self.anchor_back_config = self._load_config()
        self.stock_info = self._load_stock_info()
        self.processed_count = 0
        self.total_count = 0
        logger.info(f"âœ… ä¸­é—´å±‚ç”»çº¿å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"ğŸ“Š åŠ è½½{len(self.percent_list)}ä¸ªç™¾åˆ†æ¯”é…ç½®: {self.percent_list}")
        logger.info(f"ğŸ“ˆ åŠ è½½{len(self.stock_info)}åªè‚¡ç¥¨ä¿¡æ¯")
        logger.info(f"ğŸ”§ AnchorBackåŠŸèƒ½: {'å¯ç”¨' if self.anchor_back_config.get('enabled', True) else 'ç¦ç”¨'}")
    
    def _load_config(self) -> Tuple[List[str], Dict]:
        """åŠ è½½é…ç½®æ–‡ä»¶ä¸­çš„ç™¾åˆ†æ¯”æ•°æ®ã€ZigZagå‚æ•°å’ŒAnchorBacké…ç½®"""
        try:
            config_path = Path(self.config_file)
            if not config_path.exists():
                config_path = Path("..") / self.config_file
                if not config_path.exists():
                    logger.warning(f"âš ï¸ é…ç½®æ–‡ä»¶ {self.config_file} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
                    default_percents = ["3%", "16%", "25%", "34%", "50%", "67%", "128%", "228%", "247%", "323%", "457%", "589%", "636%", "770%", "823%", "935%"]
                    self.zigzag_period = 49
                    default_anchor_back = {
                        'enabled': True,
                        'zigzag_percent': 15,
                        'pivot_window': 5,
                        'n_range': {'start': 0.23, 'end': 0.68, 'step': 0.01},
                        'k_list': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19],
                        'match_tolerance_ratio': 0.006,
                        'min_matches': 1,
                        'tiebreaker_prefer_higher_N': True,
                        'line_style': {'color': '#1E90FF', 'linewidth': 3.0, 'alpha': 0.9},
                        'text_style': {'fontsize': 14},
                        'annotate_format': 'K={K} ä»·æ ¼={price}'
                    }
                    return default_percents, default_anchor_back
            
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
                percent_dic = config.get('percent_dic', [])
                self.zigzag_period = config.get('zigzag_period', 49)
                anchor_back_config = config.get('anchorBackLines', {})
                
                if not anchor_back_config:
                    anchor_back_config = {'enabled': False}
                
                logger.info(f"âœ… æˆåŠŸåŠ è½½é…ç½®æ–‡ä»¶: {config_path}")
                logger.info(f"ğŸ”§ ZigZagå‘¨æœŸ: {self.zigzag_period}%")
                return percent_dic, anchor_back_config
        except Exception as e:
            logger.error(f"âŒ åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            default_percents = ["3%", "16%", "25%", "34%", "50%", "67%", "128%", "228%", "247%", "323%", "457%", "589%", "636%", "770%", "823%", "935%"]
            self.zigzag_period = 49
            default_anchor_back = {'enabled': False}
            return default_percents, default_anchor_back
    
    def _load_stock_info(self) -> Dict[str, Dict[str, str]]:
        """ä»stocklist.csvåŠ è½½è‚¡ç¥¨ä¿¡æ¯ï¼ˆåç§°ã€è¡Œä¸šã€å¸‚ç›ˆç‡ã€æ€»è‚¡æœ¬ï¼‰"""
        stock_info = {}
        try:
            possible_paths = ["../stocklist.csv", "stocklist.csv", "./stocklist.csv"]
            stocklist_file = None
            
            for path in possible_paths:
                if os.path.exists(path):
                    stocklist_file = path
                    break
            
            if stocklist_file:
                try:
                    df = pd.read_csv(stocklist_file)
                    logger.info(f"ğŸ“ ä»{stocklist_file}åŠ è½½è‚¡ç¥¨ä¿¡æ¯")
                    
                    required_cols = ['symbol', 'name', 'industry', 'pe', 'total_share']
                    if all(col in df.columns for col in required_cols):
                        for _, row in df.iterrows():
                            code = str(row['symbol']).zfill(6)
                            name = str(row['name'])
                            industry = str(row['industry']) if pd.notna(row['industry']) else "æœªçŸ¥è¡Œä¸š"
                            pe = row['pe'] if pd.notna(row['pe']) else 0
                            total_share = row['total_share'] if pd.notna(row['total_share']) else 0
                            
                            stock_info[code] = {
                                'name': name, 
                                'industry': industry,
                                'pe': pe,
                                'total_share': total_share  # æ€»è‚¡æœ¬ï¼ˆäº¿è‚¡ï¼‰ï¼Œç”¨äºè®¡ç®—æ€»å¸‚å€¼
                            }
                        
                        logger.info(f"âœ… ä»stocklist.csvåŠ è½½è‚¡ç¥¨ä¿¡æ¯å®Œæˆï¼Œå…±{len(stock_info)}åªè‚¡ç¥¨")
                        return stock_info
                    else:
                        logger.warning(f"âš ï¸ stocklist.csvç¼ºå°‘å¿…è¦åˆ—")
                except Exception as e:
                    logger.warning(f"âš ï¸ è¯»å–stocklist.csvå¤±è´¥: {e}")
            
            logger.info("ğŸ“ stocklist.csvä¸å¯ç”¨")
            return stock_info
            
        except Exception as e:
            logger.error(f"âŒ åŠ è½½è‚¡ç¥¨ä¿¡æ¯å¤±è´¥: {e}")
            return stock_info
    
    def validate_and_load_data(self, stock_code: str, data_dir: str) -> Optional[pd.DataFrame]:
        """éªŒè¯å¹¶åŠ è½½è‚¡ç¥¨æ•°æ®"""
        try:
            normalized_code = str(stock_code).zfill(6)
            data_path = Path(data_dir)
            csv_file = data_path / f"{normalized_code}.csv"
            
            if not csv_file.exists():
                logger.warning(f"âš ï¸ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {csv_file}")
                return None
            
            file_size = csv_file.stat().st_size
            if file_size < 1000:
                logger.warning(f"âš ï¸ æ•°æ®æ–‡ä»¶è¿‡å°: {csv_file} ({file_size} bytes)")
                return None
            
            df = pd.read_csv(csv_file)
            
            required_columns = ['date', 'open', 'high', 'low', 'close']
            missing_columns = [col for col in required_columns if col not in df.columns]
            if missing_columns:
                logger.warning(f"âš ï¸ ç¼ºå°‘å¿…è¦åˆ— {missing_columns}: {stock_code}")
                return None
            
            if len(df) < 100:
                logger.warning(f"âš ï¸ æ•°æ®è¡Œæ•°ä¸è¶³: {stock_code} ({len(df)} rows)")
                return None
            
            df = df.dropna(subset=required_columns)
            df['date'] = pd.to_datetime(df['date'])
            df = df.sort_values('date').reset_index(drop=True)
            
            price_columns = ['open', 'high', 'low', 'close']
            for col in price_columns:
                if (df[col] <= 0).any():
                    logger.warning(f"âš ï¸ å‘ç°éæ­£ä»·æ ¼æ•°æ®: {stock_code}")
                    df = df[df[col] > 0]
            
            invalid_rows = (df['high'] < df['low']) | (df['high'] < df['open']) | (df['high'] < df['close']) | \
                          (df['low'] > df['open']) | (df['low'] > df['close'])
            if invalid_rows.any():
                logger.warning(f"âš ï¸ å‘ç°ä»·æ ¼é€»è¾‘é”™è¯¯: {stock_code}")
                df = df[~invalid_rows]
            
            if len(df) < 50:
                logger.warning(f"âš ï¸ æ¸…æ´—åæ•°æ®ä¸è¶³: {stock_code} ({len(df)} rows)")
                return None
            
            logger.debug(f"âœ… æ•°æ®éªŒè¯é€šè¿‡: {stock_code} ({len(df)} rows)")
            return df
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åŠ è½½å¤±è´¥ {stock_code}: {e}")
            return None
    
    def zigzag(self, high_prices: np.ndarray, low_prices: np.ndarray, 
               threshold_pct: float = 0.49) -> List[Tuple[int, float, str]]:
        """
        å®ç°ZigZagæŒ‡æ ‡ç®—æ³•ï¼Œæ‰¾åˆ°æ˜¾è‘—çš„è½¬æŠ˜ç‚¹
        """
        if len(high_prices) < 3:
            return []
        
        pivots = []
        last_pivot_idx = 0
        last_pivot_price = low_prices[0]
        last_pivot_type = 'low'
        searching_for = 'high'
        
        for i in range(1, len(high_prices)):
            if searching_for == 'high':
                current_high = high_prices[i]
                if last_pivot_type == 'low':
                    pct_change = (current_high - last_pivot_price) / last_pivot_price
                    if pct_change >= threshold_pct:
                        pivots.append((last_pivot_idx, last_pivot_price, 'low'))
                        last_pivot_idx = i
                        last_pivot_price = current_high
                        last_pivot_type = 'high'
                        searching_for = 'low'
                    else:
                        if low_prices[i] < last_pivot_price:
                            last_pivot_idx = i
                            last_pivot_price = low_prices[i]
            else:
                current_low = low_prices[i]
                if last_pivot_type == 'high':
                    pct_change = (last_pivot_price - current_low) / last_pivot_price
                    if pct_change >= threshold_pct:
                        pivots.append((last_pivot_idx, last_pivot_price, 'high'))
                        last_pivot_idx = i
                        last_pivot_price = current_low
                        last_pivot_type = 'low'
                        searching_for = 'high'
                    else:
                        if high_prices[i] > last_pivot_price:
                            last_pivot_idx = i
                            last_pivot_price = high_prices[i]
        
        if pivots and last_pivot_idx != pivots[-1][0]:
            pivots.append((last_pivot_idx, last_pivot_price, last_pivot_type))
        
        return pivots

    def find_stage_lows_unified(self, df: pd.DataFrame) -> List[Tuple[int, float, str]]:
        """
        ç»Ÿä¸€ç‰ˆé˜¶æ®µä½ç‚¹æ£€æµ‹ - ä½¿ç”¨ZigZag(L,49)ç®—æ³•
        """
        try:
            threshold_pct = self.zigzag_period / 100.0
            logger.debug(f"ğŸ” å¼€å§‹ZigZagé˜¶æ®µä½ç‚¹æ£€æµ‹ (é˜ˆå€¼={self.zigzag_period}%)")
            
            high_prices = df['high'].values
            low_prices = df['low'].values
            
            pivots = self.zigzag(high_prices, low_prices, threshold_pct)
            
            stage_lows = []
            
            if not pivots:
                logger.warning("âš ï¸ ZigZagæœªæ‰¾åˆ°è½¬æŠ˜ç‚¹ï¼Œä½¿ç”¨å…¨å±€æœ€ä½ç‚¹")
                min_idx = df['low'].idxmin()
                min_price = df.loc[min_idx, 'low']
                min_date = df.loc[min_idx, 'date']
                
                if hasattr(min_date, 'strftime'):
                    min_date_str = min_date.strftime("%Y-%m-%d")
                else:
                    min_date_str = str(min_date)
                
                stage_lows = [(min_idx, min_price, min_date_str)]
            else:
                low_pivots = [(idx, price, pivot_type) for idx, price, pivot_type in pivots if pivot_type == 'low']
                
                if not low_pivots:
                    logger.warning("âš ï¸ ZigZagæœªæ‰¾åˆ°ä½ç‚¹è½¬æŠ˜ï¼Œä½¿ç”¨å…¨å±€æœ€ä½ç‚¹")
                    min_idx = df['low'].idxmin()
                    min_price = df.loc[min_idx, 'low']
                    min_date = df.loc[min_idx, 'date']
                else:
                    idx, price, _ = low_pivots[-1]
                    low_date = df.loc[idx, 'date']
                    
                    logger.debug(f"âœ… ZigZagæ‰¾åˆ° {len(low_pivots)} ä¸ªä½ç‚¹è½¬æŠ˜")
                    logger.debug(f"âœ… ZigZagæœ€è¿‘ä½ç‚¹: ç´¢å¼•={idx}, ä»·æ ¼={price:.2f}")
                    
                    if idx < len(df) - 1:
                        after_low_df = df.iloc[idx+1:]
                        after_min_idx = after_low_df['low'].idxmin()
                        after_min_price = after_low_df.loc[after_min_idx, 'low']
                        
                        if after_min_price < price:
                            logger.debug(f"ğŸ”½ å‘ç°æ›´ä½ä»·æ ¼: åŸä»·æ ¼={price:.2f}, æ–°ä»·æ ¼={after_min_price:.2f}")
                            idx = after_min_idx
                            price = after_min_price
                            low_date = df.loc[after_min_idx, 'date']
                            logger.debug(f"âœ… æ›´æ–°é”šå®šä½ç‚¹: ç´¢å¼•={idx}, æ—¥æœŸ={low_date}, ä»·æ ¼={price:.2f}")
                    
                    min_idx = idx
                    min_price = price
                    min_date = low_date
                
                if hasattr(min_date, 'strftime'):
                    min_date_str = min_date.strftime("%Y-%m-%d")
                else:
                    min_date_str = str(min_date)
                
                stage_lows = [(min_idx, min_price, min_date_str)]
            
            logger.debug(f"âœ… æœ€ç»ˆé˜¶æ®µä½ç‚¹: ç´¢å¼•={stage_lows[0][0]}, æ—¥æœŸ={stage_lows[0][2]}, ä»·æ ¼={stage_lows[0][1]:.2f}")
            return stage_lows
            
        except Exception as e:
            logger.error(f"âŒ ZigZagé˜¶æ®µä½ç‚¹æ£€æµ‹å¤±è´¥: {e}")
            import traceback
            logger.debug(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            
            try:
                global_min_idx = df['low'].idxmin()
                global_min_price = df.loc[global_min_idx, 'low']
                global_min_date = df.loc[global_min_idx, 'date']
                
                if hasattr(global_min_date, 'strftime'):
                    global_min_date_str = global_min_date.strftime('%Y-%m-%d')
                else:
                    global_min_date_str = str(global_min_date)
                
                return [(global_min_idx, global_min_price, global_min_date_str)]
            except Exception as backup_e:
                logger.error(f"âŒ å¤‡é€‰æ–¹æ¡ˆä¹Ÿå¤±è´¥: {backup_e}")
                return []
    
    # ==================== AnchorBack Lines åŠŸèƒ½å‡½æ•° ====================
    
    def get_local_extremes_around_turns(self, highs: np.ndarray, lows: np.ndarray,
                                       opens: np.ndarray, closes: np.ndarray,
                                       turns: List[Tuple[int, float, str]], window: int) -> List[Tuple[float, int]]:
        """è·å–ZigZagæ‹ç‚¹é™„è¿‘çš„å±€éƒ¨æå€¼
        
        Args:
            highs: æœ€é«˜ä»·æ•°ç»„
            lows: æœ€ä½ä»·æ•°ç»„
            opens: å¼€ç›˜ä»·æ•°ç»„ï¼ˆä¿ç•™å‚æ•°ä½†ä¸ä½¿ç”¨ï¼‰
            closes: æ”¶ç›˜ä»·æ•°ç»„
            turns: ZigZagè½¬æŠ˜ç‚¹åˆ—è¡¨ [(index, price, type)]ï¼Œtypeä¸º'high'æˆ–'low'
            window: æœç´¢çª—å£å¤§å°
        
        Returns:
            æå€¼ç‚¹åˆ—è¡¨ [(price, index)]
            
        é‡è¦é€»è¾‘ï¼š
            - å½“è½¬æŠ˜ç‚¹ç±»å‹ä¸º'high'æ—¶ï¼Œåªå–è¯¥è½¬æŠ˜ç‚¹é™„è¿‘çª—å£å†…çš„å±€éƒ¨æœ€é«˜ä»·
            - å½“è½¬æŠ˜ç‚¹ç±»å‹ä¸º'low'æ—¶ï¼Œå–çª—å£å†…æ‰€æœ‰æ”¶ç›˜ä»·ä¸­çš„æœ€å°å€¼
              ï¼ˆåªä½¿ç”¨æ”¶ç›˜ä»·ï¼Œä¸ä½¿ç”¨å¼€ç›˜ä»·å’Œæœ€ä½ä»·ï¼Œæ”¶ç›˜ä»·ä»£è¡¨å½“å¤©ä¹°å–åŒæ–¹æœ€ç»ˆå…±è¯†ï¼‰
        """
        extremes = []
        
        for turn_idx, turn_price, turn_type in turns:
            start_idx = max(0, turn_idx - window)
            end_idx = min(len(highs), turn_idx + window + 1)
            
            if turn_type == 'high':
                # é«˜ç‚¹è½¬æŠ˜ï¼šåªå–å±€éƒ¨æœ€é«˜ä»·
                window_highs = highs[start_idx:end_idx]
                local_max_idx = start_idx + np.argmax(window_highs)
                local_max_price = highs[local_max_idx]
                extremes.append((local_max_price, local_max_idx))
            else:  # turn_type == 'low'
                # ä½ç‚¹è½¬æŠ˜ï¼šå–çª—å£å†…æ‰€æœ‰æ”¶ç›˜ä»·çš„æœ€å°å€¼
                window_closes = closes[start_idx:end_idx]
                local_min_idx = start_idx + np.argmin(window_closes)
                local_min_price = closes[local_min_idx]
                extremes.append((local_min_price, local_min_idx))
        
        # å»é‡å¹¶æ’åº
        extremes = list(set(extremes))
        extremes.sort(key=lambda x: x[0])
        
        return extremes
    
    def generate_B_series_back(self, A: float, N: float, k_list: List[int], 
                               max_price: float) -> Tuple[List[float], List[int]]:
        """ç”ŸæˆBåºåˆ—: B_k = A + N Ã— K (AnchorBackç®—æ³•)
        
        Args:
            A: é”šå®šä½ç‚¹ä»·æ ¼ï¼ˆ5æ ¹Kçº¿æ”¶ç›˜ä»·æœ€ä½å€¼ï¼‰
            N: æ­¥é•¿å‚æ•°
            k_list: Kå€¼åˆ—è¡¨ï¼ˆå¥‡æ•°åºåˆ—ï¼Œä»…ç”¨äºç¡®å®šå¥‡æ•°è§„åˆ™ï¼‰
            max_price: æ•°æ®ä¸­çš„æœ€é«˜ä»·
            
        Returns:
            B_values: Båºåˆ—ä»·æ ¼åˆ—è¡¨
            K_values: Kå€¼åˆ—è¡¨
            
        ç­–ç•¥ï¼š
        1. è‡ªåŠ¨è®¡ç®—éœ€è¦å¤šå°‘ä¸ªKå€¼æ‰èƒ½è¦†ç›–åˆ°æœ€é«˜ä»·
        2. åœ¨æ­¤åŸºç¡€ä¸Šå†é¢å¤–ç”Ÿæˆ3ä¸ªKå€¼
        3. ä¸å— k_list é™åˆ¶ï¼ˆå¿½ç•¥è¯¥å‚æ•°ï¼Œä»…ç”¨äºç¡®å®šå¥‡æ•°è§„åˆ™ï¼‰
        """
        if N <= 0:
            return [], []
        
        # è®¡ç®—è¦†ç›–åˆ°æœ€é«˜ä»·éœ€è¦çš„Kå€¼ï¼ˆå¥‡æ•°åºåˆ—ï¼‰
        # B_k = A + N Ã— Kï¼Œå½“ B_k >= max_price æ—¶ï¼ŒK = (max_price - A) / N
        k_to_reach_max = int((max_price - A) / N)
        
        # ç¡®ä¿Kæ˜¯å¥‡æ•°
        if k_to_reach_max % 2 == 0:
            k_to_reach_max += 1
        
        # åœ¨è¦†ç›–æœ€é«˜ä»·çš„åŸºç¡€ä¸Šå†åŠ 3ä¸ªå¥‡æ•°ï¼ˆå³ +2, +4, +6ï¼‰
        k_final = k_to_reach_max + 6
        
        # å®‰å…¨é™åˆ¶ï¼šé˜²æ­¢Nå€¼è¿‡å°å¯¼è‡´Kå€¼è¿‡å¤§ï¼ˆä¾‹å¦‚ > 1000ï¼‰
        if k_final > 500:
            logger.warning(f"âš ï¸ Kå€¼è¿‡å¤§({k_final})ï¼ŒNå€¼å¯èƒ½è¿‡å°({N:.2f})ï¼Œé™åˆ¶ä¸º501ï¼ˆæœ€å¤§å¥‡æ•°ï¼‰")
            k_final = 501  # ç¡®ä¿æ˜¯å¥‡æ•°
        
        B_values = []
        K_values = []
        
        # ç”Ÿæˆå¥‡æ•°åºåˆ—ï¼š1, 3, 5, 7, 9, ...
        k = 1
        while k <= k_final:
            B_k = A + N * k
            B_values.append(B_k)
            K_values.append(k)
            k += 2  # æ¯æ¬¡åŠ 2ï¼Œä¿æŒå¥‡æ•°
        
        return B_values, K_values
    
    def score_N(self, B_values: List[float], K_values: List[int], extremes: List[Tuple[float, int]], 
                match_tolerance_ratio: float, time_decay_min_weight: float = 0.3) -> Dict:
        """å¯¹æŸä¸ªNå€¼è¿›è¡Œè¯„åˆ†ï¼ˆå«æ—¶é—´è¡°å‡å› å­ï¼‰
        
        Args:
            B_values: Båºåˆ—ä»·æ ¼åˆ—è¡¨
            K_values: Kå€¼åˆ—è¡¨
            extremes: List[Tuple[price, idx]] - ä»·æ ¼å’Œç´¢å¼•ï¼ˆè·é”šå®šç‚¹çš„å¤©æ•°ï¼‰
            match_tolerance_ratio: åŒ¹é…å®¹å·®æ¯”ä¾‹
            time_decay_min_weight: æ—¶é—´è¡°å‡æœ€å°æƒé‡ (0-1)ï¼Œè¶Šå°è¡°å‡è¶Šå¼º
        
        æ—¶é—´è¡°å‡è§„åˆ™:
            - é”šå®šç‚¹ä½ç½®ï¼ˆidx=0ï¼‰: æƒé‡ = 1.0
            - æœ€è¿œç‚¹ï¼ˆidx=maxï¼‰: æƒé‡ = time_decay_min_weight
            - ä¸­é—´ç‚¹: çº¿æ€§æ’å€¼
        """
        if not B_values or not extremes:
            return {'avg_score': 0, 'matches_count': 0, 'per_k_matches': []}
        
        # åˆ›å»ºä»·æ ¼åˆ°ç´¢å¼•çš„æ˜ å°„ï¼ˆç”¨äºæŸ¥æ‰¾æ—¶é—´ä¿¡æ¯ï¼‰
        price_to_idx = {e[0]: e[1] for e in extremes}
        extreme_prices = [e[0] for e in extremes]
        extreme_prices_sorted = sorted(extreme_prices)
        
        # è®¡ç®—æ—¶é—´è¡°å‡ç³»æ•°ï¼šæœ€è¿œçš„æå€¼ç‚¹ç´¢å¼•
        max_idx = max(e[1] for e in extremes) if extremes else 1
        
        scores = []
        per_k_matches = []
        
        for idx, (B_k, k_val) in enumerate(zip(B_values, K_values)):
            upper = None
            lower = None
            
            for e_price in extreme_prices_sorted:
                if e_price >= B_k:
                    upper = e_price
                    break
            
            for e_price in reversed(extreme_prices_sorted):
                if e_price <= B_k:
                    lower = e_price
                    break
            
            selected_extremes = []
            if upper is not None:
                selected_extremes.append(upper)
            if lower is not None and lower != upper:
                selected_extremes.append(lower)
            
            if not selected_extremes:
                distances = [(abs(e_price - B_k), e_price) for e_price in extreme_prices]
                distances.sort()
                if distances:
                    selected_extremes.append(distances[0][1])
            
            k_scores = []
            for e_price in selected_extremes:
                # åŸºç¡€åŒ¹é…å¾—åˆ†ï¼ˆä»·æ ¼ç›¸ä¼¼åº¦ï¼‰
                r = abs(e_price - B_k) / B_k
                base_score = 100 * max(0, 1 - min(r / match_tolerance_ratio, 1))
                
                # æ—¶é—´è¡°å‡å› å­ï¼šç¦»é”šå®šç‚¹è¶Šè¿‘ï¼Œæƒé‡è¶Šé«˜
                e_idx = price_to_idx.get(e_price, max_idx)
                if max_idx > 0:
                    # æ—¶é—´æƒé‡ï¼šä» 1.0 (é”šå®šç‚¹) çº¿æ€§è¡°å‡åˆ° time_decay_min_weight (æœ€è¿œç‚¹)
                    decay_range = 1.0 - time_decay_min_weight
                    time_weight = 1.0 - decay_range * (e_idx / max_idx)
                else:
                    time_weight = 1.0
                
                # æœ€ç»ˆå¾—åˆ† = åŸºç¡€å¾—åˆ† Ã— æ—¶é—´æƒé‡
                final_score = base_score * time_weight
                k_scores.append(final_score)
            
            if k_scores:
                avg_k_score = sum(k_scores) / len(k_scores)
                scores.append(avg_k_score)
                per_k_matches.append({
                    'k': k_val,
                    'B_k': B_k,
                    'matched_extremes': selected_extremes,
                    'score': avg_k_score
                })
        
        avg_score = sum(scores) / len(scores) if scores else 0
        matches_count = len([s for s in scores if s > 0])
        
        return {
            'avg_score': avg_score,
            'matches_count': matches_count,
            'per_k_matches': per_k_matches
        }
    
    def select_best_N(self, N_results: Dict[float, Dict], min_matches: int,
                     prefer_higher_N: bool = True) -> Tuple[Optional[float], Optional[Dict]]:
        """ä»æ‰€æœ‰Nå€™é€‰ä¸­é€‰æ‹©æœ€ä½³N"""
        valid_N = {N: result for N, result in N_results.items() 
                   if result['matches_count'] >= min_matches}
        
        if not valid_N:
            return None, None
        
        sorted_N = sorted(valid_N.items(), 
                         key=lambda x: (x[1]['avg_score'], 
                                       x[1]['matches_count'],
                                       x[0] if prefer_higher_N else -x[0]),
                         reverse=True)
        
        best_N, best_result = sorted_N[0]
        return best_N, best_result
    
    def compute_anchor_back_lines(self, df: pd.DataFrame, anchor_idx: int, anchor_date, 
                                  stock_code: str = "") -> Optional[Dict]:
        """è®¡ç®—æœ€ä½³Nå€¼ä¸Båºåˆ— (AnchorBackç®—æ³•)
        
        æ ¸å¿ƒç®—æ³•: B_k = A + N Ã— K
        å…¶ä¸­:
        - A: é”šå®šä½ç‚¹é™„è¿‘5æ ¹Kçº¿æ”¶ç›˜ä»·çš„æœ€ä½å€¼
        - N: æ­¥é•¿å‚æ•° (0.23 ~ 0.68, æ­¥é•¿0.01)
        - K: å¥‡æ•°åºåˆ— (1, 3, 5, 7, 9, ...)
        """
        try:
            config = self.anchor_back_config
            
            if not config.get('enabled', True):
                return None
            
            # 1. è®¡ç®—é”šå®šç‚¹Aï¼šé”šå®šä½ç‚¹é™„è¿‘5æ ¹Kçº¿æ”¶ç›˜ä»·çš„æœ€ä½å€¼
            pivot_window = config.get('pivot_window', 5)
            start_idx = max(0, anchor_idx - pivot_window // 2)
            end_idx = min(len(df), anchor_idx + pivot_window // 2 + 1)
            
            window_data = df.iloc[start_idx:end_idx]
            anchor_close_price = window_data['close'].min()  # çª—å£å†…æœ€ä½æ”¶ç›˜ä»·
            anchor_A = float(anchor_close_price)
            
            logger.debug(f"ğŸ¯ [{stock_code}] é”šå®šç‚¹A={anchor_A:.2f} (çª—å£[{start_idx}:{end_idx}]å†…æœ€ä½æ”¶ç›˜ä»·)")
            
            # ç¡®ä¿ anchor_date æ˜¯ pd.Timestamp
            if isinstance(anchor_date, str):
                anchor_date = pd.to_datetime(anchor_date)
            
            df_after = df[df['date'] > anchor_date].copy()
            
            if len(df_after) < 10:
                logger.info(f"âš ï¸ [{stock_code}] é”šå®šæ—¥æœŸä¹‹åæ•°æ®ä¸è¶³: {len(df_after)}å¤©ï¼Œè·³è¿‡AnchorBackçº¿")
                return None
            
            # 2. ä½¿ç”¨é…ç½®çš„ZigZagå‚æ•°å¯»æ‰¾è½¬æŠ˜ç‚¹
            zigzag_percent = config.get('zigzag_percent', 15) / 100.0
            highs_after = df_after['high'].values
            lows_after = df_after['low'].values
            opens_after = df_after['open'].values
            closes_after = df_after['close'].values
            
            turns = self.zigzag(highs_after, lows_after, zigzag_percent)
            
            if not turns:
                logger.info(f"âš ï¸ [{stock_code}] é”šå®šæ—¥æœŸåæœªæ‰¾åˆ°ZigZagè½¬æŠ˜ç‚¹ï¼Œè·³è¿‡AnchorBackçº¿")
                return None
            
            # 3. æå–å±€éƒ¨æå€¼ç‚¹
            pivot_window = config.get('pivot_window', 5)
            extremes = self.get_local_extremes_around_turns(
                highs_after, lows_after, opens_after, closes_after, turns, pivot_window
            )
            
            if not extremes:
                logger.info(f"âš ï¸ [{stock_code}] æœªæ‰¾åˆ°å±€éƒ¨æå€¼ï¼Œè·³è¿‡AnchorBackçº¿")
                return None
            
            # 4. éå†Nå€¼èŒƒå›´
            n_range = config.get('n_range', {'start': 0.23, 'end': 0.68, 'step': 0.01})
            N_start = n_range['start']
            N_end = n_range['end']
            N_step = n_range['step']
            
            N_values = []
            N_current = N_start
            while N_current <= N_end + 0.001:
                N_values.append(round(N_current, 2))
                N_current += N_step
            
            k_list = config.get('k_list', [1, 3, 5, 7, 9, 11, 13, 15, 17, 19])
            max_price = df_after['high'].max()
            match_tolerance = config.get('match_tolerance_ratio', 0.006)
            time_decay_min_weight = config.get('time_decay_min_weight', 0.3)
            
            N_results = {}
            
            for N in N_values:
                B_values, K_values = self.generate_B_series_back(anchor_A, N, k_list, max_price)
                
                if not B_values:
                    continue
                
                score_result = self.score_N(B_values, K_values, extremes, match_tolerance, time_decay_min_weight)
                N_results[N] = {
                    'B_values': B_values,
                    'K_values': K_values,
                    'avg_score': score_result['avg_score'],
                    'matches_count': score_result['matches_count'],
                    'per_k_matches': score_result['per_k_matches']
                }
            
            # 5. é€‰æ‹©æœ€ä½³Nå€¼ï¼ˆåŠ¨æ€è°ƒæ•´ç­–ç•¥ï¼‰
            min_matches = config.get('min_matches', 1)
            prefer_higher_N = config.get('tiebreaker_prefer_higher_N', True)
            
            # é¦–å…ˆå°è¯•è·å–æ»¡è¶³min_matchesçš„æœ€ä½³Nå€¼
            best_N, best_result = self.select_best_N(N_results, min_matches, prefer_higher_N)
            
            # åŠ¨æ€è°ƒæ•´ç­–ç•¥ï¼šå¦‚æœåŒ¹é…æ•°<2ï¼Œå°è¯•é™ä½Nå€¼ä»¥è·å¾—>=2ä¸ªåŒ¹é…
            if best_N is None or (best_result and best_result['matches_count'] < 2):
                current_min_matches = best_result['matches_count'] if best_result else 0
                
                if N_results:
                    # æ‰¾å‡ºæ‰€æœ‰åŒ¹é…æ•°>=2çš„Nå€¼
                    valid_N_ge2 = {N: result for N, result in N_results.items() 
                                   if result['matches_count'] >= 2}
                    
                    if valid_N_ge2:
                        # å¦‚æœæœ‰åŒ¹é…æ•°>=2çš„Nå€¼ï¼Œé€‰æ‹©å…¶ä¸­æœ€ä½³çš„ï¼ˆä¼˜å…ˆé€‰æ‹©æ›´å°çš„Nå€¼ï¼‰
                        sorted_N = sorted(valid_N_ge2.items(), 
                                        key=lambda x: (x[1]['avg_score'], 
                                                      x[1]['matches_count'],
                                                      -x[0]),  # è´Ÿå·è¡¨ç¤ºä¼˜å…ˆé€‰æ‹©æ›´å°çš„N
                                        reverse=True)
                        best_N, best_result = sorted_N[0]
                        logger.info(f"ğŸ“Š [{stock_code}] åŠ¨æ€è°ƒæ•´ï¼šé™ä½Nå€¼ä»¥è·å¾—>=2ä¸ªåŒ¹é… â†’ N={best_N:.2f}, åŒ¹é…æ•°={best_result['matches_count']}")
                    else:
                        # å¦‚æœæ²¡æœ‰åŒ¹é…æ•°>=2çš„ï¼Œè‡³å°‘é€‰æ‹©åŒ¹é…æ•°æœ€å¤šçš„
                        sorted_by_matches = sorted(N_results.items(), 
                                                  key=lambda x: (x[1]['matches_count'], 
                                                                x[1]['avg_score'],
                                                                -x[0]),  # ä¼˜å…ˆå°Nå€¼
                                                  reverse=True)
                        best_N, best_result = sorted_by_matches[0]
                        if best_result['matches_count'] >= 1:
                            logger.info(f"ğŸ“Š [{stock_code}] åŠ¨æ€è°ƒæ•´ï¼šæœªæ‰¾åˆ°>=2ä¸ªåŒ¹é…ï¼Œä½¿ç”¨æœ€ä½³ç»“æœ â†’ N={best_N:.2f}, åŒ¹é…æ•°={best_result['matches_count']}")
                        else:
                            logger.info(f"âš ï¸ [{stock_code}] æ‰€æœ‰Nå€¼åŒ¹é…æ•°å‡<1ï¼Œè·³è¿‡AnchorBackçº¿")
                            return None
                else:
                    logger.info(f"âš ï¸ [{stock_code}] æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„Nå€¼ï¼Œè·³è¿‡AnchorBackçº¿")
                    return None
            
            logger.debug(f"âœ… æœ€ä½³N={best_N:.2f}, å¹³å‡åˆ†={best_result['avg_score']:.2f}, "
                        f"åŒ¹é…æ•°={best_result['matches_count']}")
            
            return {
                'best_N': best_N,
                'B_values': best_result['B_values'],
                'K_values': best_result['K_values'],
                'avg_score': best_result['avg_score'],
                'matches_count': best_result['matches_count'],
                'per_k_matches': best_result['per_k_matches'],
                'anchor_A': anchor_A,
                'anchor_date': anchor_date,
                'anchor_idx': anchor_idx,
                'extremes': extremes
            }
            
        except Exception as e:
            logger.error(f"âŒ è®¡ç®—AnchorBackçº¿å¤±è´¥: {e}")
            import traceback
            logger.debug(traceback.format_exc())
            return None

    def create_back_chart(self, stock_code: str, stock_name: str, df: pd.DataFrame,
                          output_file: str) -> Tuple[bool, Optional[Dict]]:
        """
        åˆ›å»ºä¸­é—´å±‚å›¾è¡¨ï¼šåŸºç¡€Kçº¿å›¾ + AnchorBackçº¿
        """
        try:
            # 1. æ£€æµ‹é˜¶æ®µä½ç‚¹
            stage_lows = self.find_stage_lows_unified(df)
            if not stage_lows:
                logger.warning(f"âš ï¸ æœªæ£€æµ‹åˆ°é˜¶æ®µä½ç‚¹: {stock_code}")
                return False, None
            
            # 2. è®¡ç®—AnchorBackçº¿æ•°æ®ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            back_lines_result = None
            if self.anchor_back_config.get('enabled', True):
                anchor_idx, anchor_low, anchor_date = stage_lows[0]
                back_lines_result = self.compute_anchor_back_lines(df, anchor_idx, anchor_date, stock_code)
            
            # 3. ç»˜åˆ¶å›¾è¡¨
            with matplotlib_lock:
                import mplfinance as mpf
                
                # å‡†å¤‡æ•°æ®ï¼šç¡®ä¿åŒ…å«é”šå®šç‚¹
                if stage_lows:
                    lowest_idx, _, _ = stage_lows[0]
                    # å¦‚æœæœ‰AnchorBackç»“æœï¼Œéœ€è¦ç¡®ä¿æ˜¾ç¤ºèŒƒå›´åŒ…å«é”šå®šç‚¹
                    start_idx = lowest_idx
                    if back_lines_result and back_lines_result.get('anchor_idx') is not None:
                        anchor_idx = back_lines_result['anchor_idx']
                        pivot_window = self.anchor_back_config.get('pivot_window', 5)
                        # å‘å‰æ‰©å±•çª—å£ä»¥åŒ…å«é”šå®šç‚¹
                        anchor_start = max(0, anchor_idx - pivot_window // 2)
                        start_idx = min(start_idx, anchor_start)
                        logger.debug(f"ğŸ“Š [{stock_code}] è°ƒæ•´æ˜¾ç¤ºèµ·ç‚¹: {lowest_idx} â†’ {start_idx} (åŒ…å«é”šå®šç‚¹)")
                    
                    df_display = df.iloc[start_idx:].copy()
                else:
                    df_display = df.copy()
                
                # é™åˆ¶æ˜¾ç¤ºçš„Kçº¿æ•°é‡ï¼Œé¿å…"æ•°æ®å¤ªå¤š"è­¦å‘Š
                max_candles = 750
                if len(df_display) > max_candles:
                    logger.info(f"ğŸ“Š [{stock_code}] æ•°æ®é‡å¤§({len(df_display)}æ ¹Kçº¿)ï¼Œ"
                               f"åªæ˜¾ç¤ºæœ€è¿‘{max_candles}æ ¹")
                    df_display = df_display.iloc[-max_candles:].copy()
                
                df_mpf = df_display.copy()
                df_mpf['date'] = pd.to_datetime(df_mpf['date'])
                df_mpf.set_index('date', inplace=True)
                df_mpf = df_mpf[['open', 'high', 'low', 'close']].copy()
                
                if df_mpf.empty:
                    logger.warning(f"âš ï¸ å¤„ç†åçš„æ•°æ®ä¸ºç©º: {stock_code}")
                    return False, None
                
                logger.info(f"ğŸ“Š [{stock_code}] ç»˜åˆ¶{len(df_mpf)}æ ¹Kçº¿")
                
                # å‡†å¤‡é¢å¤–çš„ç»˜å›¾å…ƒç´ 
                additional_plots = []
                
                # æ·»åŠ é˜¶æ®µä½ç‚¹æ°´å¹³çº¿
                for i, (idx, price, date_str) in enumerate(stage_lows):
                    hline_data = [price] * len(df_mpf)
                    additional_plots.append(mpf.make_addplot(hline_data, color='blue', linestyle='-', width=2, alpha=0.8))
                
                # æ·»åŠ ç™¾åˆ†æ¯”æ¶¨å¹…çº¿
                if stage_lows:
                    base_price = min(price for _, price, _ in stage_lows)
                    max_price = df_mpf['high'].max()
                    
                    visible_percent_lines = []
                    highest_visible_idx = -1
                    
                    for i, percent_str in enumerate(self.percent_list):
                        try:
                            percent = float(percent_str.rstrip('%')) / 100
                            target_price = base_price * (1 + percent)
                            
                            if target_price <= max_price:
                                visible_percent_lines.append((percent_str, target_price))
                                highest_visible_idx = i
                                hline_data = [target_price] * len(df_mpf)
                                additional_plots.append(mpf.make_addplot(hline_data, color='hotpink', linestyle='--', width=3, alpha=0.8))
                        except (ValueError, TypeError):
                            continue
                
                    if highest_visible_idx >= 0 and highest_visible_idx + 1 < len(self.percent_list):
                        try:
                            next_percent_str = self.percent_list[highest_visible_idx + 1]
                            next_percent = float(next_percent_str.rstrip('%')) / 100
                            next_target_price = base_price * (1 + next_percent)
                            hline_data = [next_target_price] * len(df_mpf)
                            additional_plots.append(mpf.make_addplot(hline_data, color='hotpink', linestyle='--', width=3, alpha=0.8))
                            visible_percent_lines.append((next_percent_str, next_target_price))
                        except (ValueError, TypeError):
                            pass
                
                # æ„å»ºæ ‡é¢˜ï¼ˆåŒ…å«è¡Œä¸šã€æ€»å¸‚å€¼ã€å¸‚ç›ˆç‡ï¼‰
                industry = ""
                pe_val = 0
                total_share = 0
                total_market_cap = 0
                
                if stock_code in self.stock_info:
                    info = self.stock_info[stock_code]
                    industry = info.get('industry', '')
                    pe_val = float(info.get('pe', 0))
                    total_share = float(info.get('total_share', 0))
                    
                    # è®¡ç®—æ€»å¸‚å€¼ = æ€»è‚¡æœ¬ï¼ˆäº¿è‚¡ï¼‰Ã— å½“å‰è‚¡ä»·ï¼ˆå…ƒï¼‰
                    if total_share > 0 and len(df_mpf) > 0:
                        current_price = float(df_mpf['close'].iloc[-1])
                        total_market_cap = total_share * current_price  # æ€»å¸‚å€¼ï¼ˆäº¿å…ƒï¼‰
                
                title_parts = [stock_code, stock_name]
                
                # æ·»åŠ è¡Œä¸š
                if industry and industry != "æœªçŸ¥è¡Œä¸š":
                    title_parts.append(f"({industry})")
                
                # æ·»åŠ æ€»å¸‚å€¼
                if total_market_cap > 0:
                    if total_market_cap >= 1000:
                        title_parts.append(f"æ€»å¸‚å€¼:{total_market_cap:.0f}äº¿")
                    else:
                        title_parts.append(f"æ€»å¸‚å€¼:{total_market_cap:.1f}äº¿")
                
                # æ·»åŠ å¸‚ç›ˆç‡
                if pe_val > 0:
                    title_parts.append(f"PE:{pe_val:.2f}")
                elif pe_val == 0:
                    title_parts.append("PE:äºæŸ")
                
                title = " ".join(title_parts) + " - AnchorBack"
                
                # è®¾ç½®æ ·å¼
                plt.rcParams['font.sans-serif'] = ['Heiti TC', 'PingFang HK', 'Arial Unicode MS', 'DejaVu Sans']
                plt.rcParams['axes.unicode_minus'] = False
                
                style = mpf.make_mpf_style(
                    base_mpf_style='charles',
                    marketcolors=mpf.make_marketcolors(
                        up='red', down='green', edge='inherit', wick='inherit', volume='inherit'
                    ),
                    gridstyle='-', gridcolor='lightgray', y_on_right=True,
                    facecolor='white', edgecolor='black', figcolor='white',
                    rc={'font.size': 12, 'axes.titlesize': 20, 'axes.labelsize': 14, 
                        'font.sans-serif': ['Heiti TC', 'PingFang HK', 'Arial Unicode MS', 'DejaVu Sans'],
                        'axes.unicode_minus': False}
                )
                
                # åˆ›å»ºå›¾è¡¨
                fig, axes = mpf.plot(
                    df_mpf, type='candle', style=style, title=title, ylabel='Price',
                    volume=False, addplot=additional_plots if additional_plots else None,
                    figsize=(20, 12), tight_layout=True, returnfig=True,
                    panel_ratios=(1,), show_nontrading=False, 
                    datetime_format='%Y-%m', xrotation=45
                )
                
                ax = axes[0]
                
                # æ ‡æ³¨é˜¶æ®µä½ç‚¹ä»·æ ¼
                for i, (idx, price, date_str) in enumerate(stage_lows):
                    ax.text(1.02, price, f'{price:.2f}', 
                           fontsize=16, color='blue', fontweight='bold',
                           bbox=dict(boxstyle="round,pad=0.3", facecolor='white', alpha=0.8),
                           transform=ax.get_yaxis_transform(), ha='left', va='center')
                
                # æ ‡æ³¨ç™¾åˆ†æ¯”æ¶¨å¹…çº¿
                if stage_lows:
                    base_price = min(price for _, price, _ in stage_lows)
                    max_price = df_mpf['high'].max()
                    
                    highest_visible_idx = -1
                    for i, percent_str in enumerate(self.percent_list):
                        try:
                            percent = float(percent_str.rstrip('%')) / 100
                            target_price = base_price * (1 + percent)
                            
                            if target_price <= max_price:
                                highest_visible_idx = i
                                ax.text(1.02, target_price, f'+{percent_str}', 
                                       fontsize=18, color='#8B7355', fontweight='bold',
                                       bbox=dict(boxstyle="round,pad=0.3", facecolor='white', 
                                                alpha=0.9, edgecolor='#8B7355', linewidth=2),
                                       transform=ax.get_yaxis_transform(), ha='left', va='center')
                        except (ValueError, TypeError):
                            continue
                    
                    if highest_visible_idx >= 0 and highest_visible_idx + 1 < len(self.percent_list):
                        try:
                            next_percent_str = self.percent_list[highest_visible_idx + 1]
                            next_percent = float(next_percent_str.rstrip('%')) / 100
                            next_target_price = base_price * (1 + next_percent)
                            
                            ax.text(1.02, next_target_price, f'+{next_percent_str}', 
                                   fontsize=18, color='#8B7355', fontweight='bold',
                                   bbox=dict(boxstyle="round,pad=0.3", facecolor='white', 
                                            alpha=0.9, edgecolor='#8B7355', linewidth=2),
                                   transform=ax.get_yaxis_transform(), ha='left', va='center')
                        except (ValueError, TypeError):
                            pass
                
                # 4. æ·»åŠ AnchorBackçº¿å¹¶æ ‡æ³¨é”šå®šä½ç‚¹
                if back_lines_result:
                    best_N = back_lines_result['best_N']
                    B_values = back_lines_result['B_values']
                    K_values = back_lines_result['K_values']
                    anchor_A = back_lines_result['anchor_A']
                    anchor_idx = back_lines_result['anchor_idx']
                    
                    line_style = self.anchor_back_config.get('line_style', {})
                    line_color = line_style.get('color', '#1E90FF')
                    line_width = line_style.get('linewidth', 3.0)
                    line_alpha = line_style.get('alpha', 0.9)
                    
                    text_style = self.anchor_back_config.get('text_style', {})
                    text_fontsize = text_style.get('fontsize', 14)
                    annotate_format = self.anchor_back_config.get('annotate_format', 'K={K} ä»·æ ¼={price}')
                    
                    # ç»˜åˆ¶è“è‰²æ¨ªçº¿
                    for k_val, B_k_price in zip(K_values, B_values):
                        ax.axhline(y=B_k_price, color=line_color, 
                                  linestyle='-', linewidth=line_width, 
                                  alpha=line_alpha, zorder=2.5)
                        
                        label_text = annotate_format.replace('{K}', str(k_val)).replace('{price}', f'{B_k_price:.2f}')
                        ax.text(-0.02, B_k_price, label_text,
                               fontsize=text_fontsize, color=line_color, fontweight='bold',
                               bbox=dict(boxstyle="round,pad=0.4", facecolor='white', alpha=0.85, 
                                        edgecolor=line_color, linewidth=2),
                               transform=ax.get_yaxis_transform(), ha='right', va='center')
                    
                    # æ ‡æ³¨é”šå®šä½ç‚¹ï¼ˆæœ€ä½æ”¶ç›˜ä»·ï¼‰
                    if stage_lows:
                        # è·å–é”šå®šç‚¹çš„æ—¥æœŸï¼ˆä½¿ç”¨åŸå§‹dfï¼‰
                        pivot_window = self.anchor_back_config.get('pivot_window', 5)
                        start_idx = max(0, anchor_idx - pivot_window // 2)
                        end_idx = min(len(df), anchor_idx + pivot_window // 2 + 1)
                        
                        # æ‰¾åˆ°çª—å£å†…çš„æœ€ä½æ”¶ç›˜ä»·åŠå…¶ç´¢å¼•
                        window_data = df.iloc[start_idx:end_idx]
                        min_close_idx = window_data['close'].idxmin()
                        anchor_close_price = df.loc[min_close_idx, 'close']
                        anchor_close_date = df.loc[min_close_idx, 'date']
                        
                        # æ£€æŸ¥é”šå®šç‚¹æ—¥æœŸæ˜¯å¦åœ¨æ˜¾ç¤ºèŒƒå›´å†…ï¼ˆdf_mpfå·²ç»è®¾ç½®äº†dateä¸ºç´¢å¼•ï¼‰
                        anchor_date_dt = pd.to_datetime(anchor_close_date)
                        
                        if anchor_date_dt in df_mpf.index:
                            # ç»˜åˆ¶çº¢è‰²åœ†ç‚¹ï¼ˆæé«˜zorderç¡®ä¿åœ¨æœ€ä¸Šå±‚ï¼‰
                            ax.plot(anchor_date_dt, anchor_close_price, 
                                   marker='o', markersize=15, color='red', 
                                   markeredgecolor='white', markeredgewidth=2,
                                   zorder=10)
                            
                            # æ·»åŠ å¸¦ç®­å¤´çš„æ ‡æ³¨ï¼ˆä½¿ç”¨è‹±æ–‡é¿å…ä¸­æ–‡ä¹±ç ï¼‰
                            ax.annotate(f'Anchor\n{anchor_close_price:.2f}',
                                       xy=(anchor_date_dt, anchor_close_price),
                                       xytext=(15, -40),
                                       textcoords='offset points',
                                       fontsize=13, color='red', fontweight='bold',
                                       bbox=dict(boxstyle='round,pad=0.6', 
                                               facecolor='yellow', edgecolor='red', linewidth=2.5),
                                       arrowprops=dict(arrowstyle='->', color='red', lw=3),
                                       zorder=10)
                            logger.info(f"âœ… [{stock_code}] æ ‡æ³¨é”šå®šç‚¹: æ—¥æœŸ={anchor_date_dt}, ä»·æ ¼={anchor_close_price:.2f}")
                        else:
                            logger.warning(f"âš ï¸ [{stock_code}] é”šå®šç‚¹æ—¥æœŸ {anchor_date_dt} ä¸åœ¨æ˜¾ç¤ºèŒƒå›´å†…ï¼Œè·³è¿‡æ ‡æ³¨")
                    
                    # åœ¨å›¾ç‰‡å·¦ä¸Šè§’æ·»åŠ Nå€¼ä¿¡æ¯ - åªæ˜¾ç¤ºåŒ¹é…çš„Bå€¼
                    text_lines = [f"N={best_N:.2f}"]
                    
                    # æå–å¾—åˆ† > 0 çš„ B å€¼ï¼ˆä¸æå€¼ç‚¹åŒ¹é…çš„ï¼‰
                    if 'per_k_matches' in back_lines_result:
                        matched_B = []
                        for match in back_lines_result['per_k_matches']:
                            if match.get('score', 0) > 0:
                                k_val = match['k']
                                B_k = match['B_k']
                                score = match['score']
                                matched_B.append(f"K{k_val}:{B_k:.2f}({score:.0f})")
                                if len(matched_B) >= 10:  # æœ€å¤šæ˜¾ç¤º10ä¸ª
                                    break
                        
                        if matched_B:
                            if len(back_lines_result['per_k_matches']) > len(matched_B):
                                matched_B.append('...')
                            text_lines.append(f"Match_B: [{', '.join(matched_B)}]")
                        else:
                            text_lines.append(f"Match_B: [æ— åŒ¹é…]")
                    
                    text_lines.append(f"AvgScore: {back_lines_result['avg_score']:.1f}")
                    text_lines.append(f"Matches: {back_lines_result['matches_count']}/{len(B_values)}")
                    
                    text_content = '\n'.join(text_lines)
                    ax.text(0.01, 0.98, text_content,
                           transform=ax.transAxes,
                           fontsize=11, color='#1E90FF', fontweight='bold',
                           bbox=dict(boxstyle="round,pad=0.5", facecolor='white', alpha=0.95, 
                                    edgecolor='#1E90FF', linewidth=2.5),
                           ha='left', va='top', family='monospace')
                    
                    logger.info(f"âœ… [{stock_code}] ç»˜åˆ¶AnchorBackçº¿: N={best_N:.2f}, {len(B_values)}æ¡çº¿")
                
                # 4.5 ç»Ÿä¸€è°ƒæ•´Yè½´èŒƒå›´ï¼ˆè€ƒè™‘ç™¾åˆ†æ¯”çº¿å’ŒAnchorBackçº¿ï¼‰
                if stage_lows:
                    base_price = min(price for _, price, _ in stage_lows)
                    max_price = df_mpf['high'].max()
                    min_price = df_mpf['low'].min()
                    
                    # è®¡ç®—æœ€é«˜çš„ç™¾åˆ†æ¯”çº¿
                    highest_percent_price = max_price
                    highest_visible_idx = -1
                    
                    for i, percent_str in enumerate(self.percent_list):
                        try:
                            percent = float(percent_str.rstrip('%')) / 100
                            target_price = base_price * (1 + percent)
                            if target_price <= max_price:
                                highest_visible_idx = i
                                highest_percent_price = target_price
                        except (ValueError, TypeError):
                            continue
                    
                    # åŠ ä¸ŠKçº¿ä¸Šæ–¹çš„é¢å¤–ç™¾åˆ†æ¯”çº¿
                    if highest_visible_idx >= 0 and highest_visible_idx + 1 < len(self.percent_list):
                        try:
                            next_percent_str = self.percent_list[highest_visible_idx + 1]
                            next_percent = float(next_percent_str.rstrip('%')) / 100
                            next_target_price = base_price * (1 + next_percent)
                            highest_percent_price = next_target_price
                        except (ValueError, TypeError):
                            pass
                    
                    # è€ƒè™‘AnchorBackçº¿çš„æœ€é«˜ä»·æ ¼
                    highest_line_price = highest_percent_price
                    if back_lines_result and back_lines_result['B_values']:
                        highest_back_price = max(back_lines_result['B_values'])
                        highest_line_price = max(highest_percent_price, highest_back_price)
                    
                    # è®¾ç½®Yè½´èŒƒå›´ï¼Œç¡®ä¿æ‰€æœ‰çº¿éƒ½å¯è§
                    y_margin = (highest_line_price - min_price) * 0.05
                    ax.set_ylim(min_price - y_margin, highest_line_price + y_margin)
                    logger.debug(f"ğŸ“Š [{stock_code}] Yè½´èŒƒå›´: {min_price:.2f} - {highest_line_price:.2f}")
                
                # 4.6 ç»˜åˆ¶æœ€åä¸€ä¸ªäº¤æ˜“æ—¥çš„æ”¶ç›˜ä»·æ¨ªçº¿
                last_close_price = df_mpf['close'].iloc[-1]
                ax.axhline(y=last_close_price, color='red', linestyle='-', linewidth=3, alpha=0.8, zorder=3)
                
                # åœ¨å³ä¾§æ ‡æ³¨æ”¶ç›˜ä»·
                ax.text(1.02, last_close_price, f'{last_close_price:.2f}', 
                       fontsize=16, color='red', fontweight='bold',
                       transform=ax.get_yaxis_transform(), ha='left', va='center')
                logger.debug(f"ğŸ“Š [{stock_code}] æœ€åäº¤æ˜“æ—¥æ”¶ç›˜ä»·æ¨ªçº¿: {last_close_price:.2f}")
                
                # 5. ä¿å­˜å›¾è¡¨
                plt.savefig(output_file, dpi=200, bbox_inches='tight', facecolor='white', edgecolor='none')
                plt.close(fig)
                
                # 6. è°ƒæ•´å›¾ç‰‡å°ºå¯¸
                try:
                    from PIL import Image
                    with Image.open(output_file) as img:
                        target_width = 3991
                        target_height = 2392
                        resized_img = img.resize((target_width, target_height), Image.Resampling.LANCZOS)
                        resized_img.save(output_file, 'PNG', quality=95)
                        logger.debug(f"âœ… å›¾ç‰‡å°ºå¯¸å·²è°ƒæ•´: {target_width}x{target_height}")
                except ImportError:
                    logger.warning("âš ï¸ PILæœªå®‰è£…ï¼Œæ— æ³•è°ƒæ•´å›¾ç‰‡å°ºå¯¸")
                except Exception as e:
                    logger.warning(f"âš ï¸ è°ƒæ•´å›¾ç‰‡å°ºå¯¸å¤±è´¥: {e}")
                
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æˆåŠŸç”Ÿæˆ
                if os.path.exists(output_file):
                    file_size = os.path.getsize(output_file)
                    if file_size > 1000:
                        logger.debug(f"âœ… å›¾è¡¨ç”ŸæˆæˆåŠŸ: {output_file} ({file_size} bytes)")
                        return True, back_lines_result
                    else:
                        logger.warning(f"âš ï¸ ç”Ÿæˆçš„å›¾ç‰‡æ–‡ä»¶è¿‡å°: {output_file} ({file_size} bytes)")
                        return False, None
                else:
                    logger.error(f"âŒ å›¾è¡¨æ–‡ä»¶æœªç”Ÿæˆ: {output_file}")
                    return False, None
                    
        except Exception as e:
            logger.error(f"âŒ å›¾è¡¨åˆ›å»ºå¤±è´¥ {stock_code}: {type(e).__name__}: {e}")
            import traceback
            logger.debug(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            return False, None
        finally:
            try:
                plt.close('all')
            except:
                pass
    
    def process_stock_list(self, stock_list: List[Tuple[str, str, str, str]], 
                          output_dir: Optional[str] = None, data_dir: str = "../data", workers: int = 4):
        """å¤„ç†æŒ‡å®šçš„è‚¡ç¥¨åˆ—è¡¨"""
        if output_dir is None:
            current_date = datetime.now().strftime('%Y%m%d')
            output_dir = f'{current_date}-drawLineBack'
        
        logger.info(f"ğŸš€ å¼€å§‹å¤„ç†è‚¡ç¥¨åˆ—è¡¨ï¼ˆä¸­é—´å±‚ - AnchorBackï¼‰")
        logger.info(f"ğŸ“ æ•°æ®ç›®å½•: {data_dir}")
        logger.info(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        logger.info(f"ğŸ§µ çº¿ç¨‹æ•°: {workers}")
        
        if not stock_list:
            logger.error("âŒ è‚¡ç¥¨åˆ—è¡¨ä¸ºç©º")
            return
        
        self.total_count = len(stock_list)
        self.processed_count = 0
        
        logger.info(f"ğŸ“Š å¾…å¤„ç†è‚¡ç¥¨æ•°é‡: {self.total_count}")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆè¦†ç›–æ¨¡å¼ï¼Œä¸æ¸…ç©ºï¼‰
        os.makedirs(output_dir, exist_ok=True)
        if os.path.exists(output_dir) and os.listdir(output_dir):
            logger.info(f"ğŸ“ è¾“å‡ºç›®å½•å·²å­˜åœ¨: {output_dir}ï¼ˆå°†è¦†ç›–åŒåæ–‡ä»¶ï¼‰")
        else:
            logger.info(f"ğŸ“ åˆ›å»ºè¾“å‡ºç›®å½•: {output_dir}")
        
        # å¤šçº¿ç¨‹å¤„ç†
        start_time = time.time()
        results = []
        
        with ThreadPoolExecutor(max_workers=workers) as executor:
            future_to_stock = {
                executor.submit(self._process_single_stock, code, name, output_dir, data_dir, file_prefix): (code, name, industry, file_prefix)
                for code, name, industry, file_prefix in stock_list
            }
            
            for future in as_completed(future_to_stock):
                result = future.result()
                results.append(result)
        
        # ç»Ÿè®¡ç»“æœ
        total_time = time.time() - start_time
        success_count = sum(1 for r in results if r['success'])
        failed_count = len(results) - success_count
        
        logger.info(f"ğŸ‰ è‚¡ç¥¨åˆ—è¡¨å¤„ç†å®Œæˆ!")
        logger.info(f"ğŸ“Š æ€»è®¡: {len(results)}åªè‚¡ç¥¨")
        logger.info(f"âœ… æˆåŠŸ: {success_count}åª")
        logger.info(f"âŒ å¤±è´¥: {failed_count}åª")
        logger.info(f"â±ï¸ æ€»è€—æ—¶: {total_time:.2f}ç§’")
        logger.info(f"âš¡ å¹³å‡é€Ÿåº¦: {len(results)/total_time:.2f}åª/ç§’")
        
        # ä¿å­˜å¤„ç†ç»“æœ
        results_file = os.path.join(output_dir, "processing_results.json")
        try:
            with open(results_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            logger.info(f"ğŸ“„ å¤„ç†ç»“æœå·²ä¿å­˜: {results_file}")
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")
        
        # æ˜¾ç¤ºå¤±è´¥çš„è‚¡ç¥¨
        failed_stocks = [r for r in results if not r['success']]
        if failed_stocks:
            logger.warning(f"âš ï¸ å¤±è´¥çš„è‚¡ç¥¨:")
            for r in failed_stocks[:10]:
                logger.warning(f"   {r['stock_code']} {r['stock_name']}: {r['error']}")
            if len(failed_stocks) > 10:
                logger.warning(f"   ... è¿˜æœ‰{len(failed_stocks)-10}åªè‚¡ç¥¨å¤±è´¥")

    def _process_single_stock(self, stock_code: str, stock_name: str, 
                           output_dir: str, data_dir: str, file_prefix: str = "") -> dict:
        """å¤„ç†å•åªè‚¡ç¥¨ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰"""
        start_time = time.time()
        result = {
            'stock_code': stock_code,
            'stock_name': stock_name,
            'success': False,
            'elapsed_time': 0,
            'error': None
        }
        
        try:
            # 1. åŠ è½½æ•°æ®
            df = self.validate_and_load_data(stock_code, data_dir)
            if df is None:
                result['error'] = "æ•°æ®åŠ è½½å¤±è´¥"
                return result
            
            # 2. åˆ›å»ºè¾“å‡ºç›®å½•
            os.makedirs(output_dir, exist_ok=True)
            
            # 3. ç”Ÿæˆå›¾è¡¨
            if file_prefix and file_prefix != "UNKNOWN":
                output_file = os.path.join(output_dir, f"{file_prefix}_{stock_code}_{stock_name}_2back.png")
            else:
                output_file = os.path.join(output_dir, f"{stock_code}_{stock_name}_2back.png")
            
            success, back_lines_result = self.create_back_chart(stock_code, stock_name, df, output_file)
            
            if success:
                result['success'] = True
                
                # æ·»åŠ AnchorBackçº¿ç»“æœ
                if back_lines_result:
                    result['anchorBackLines'] = {
                        'best_N': back_lines_result['best_N'],
                        'avg_score': back_lines_result['avg_score'],
                        'matches_count': back_lines_result['matches_count'],
                        'B_values': back_lines_result['B_values'][:10],
                        'anchor_A': back_lines_result['anchor_A'],
                        'anchor_date': str(back_lines_result['anchor_date'])
                    }
                
                # æ›´æ–°è¿›åº¦
                with progress_lock:
                    self.processed_count += 1
                    n_info = f", N={back_lines_result['best_N']:.2f}" if back_lines_result else ""
                    logger.info(f"âœ… [{self.processed_count}/{self.total_count}] {stock_code} {stock_name}{n_info}")
            else:
                result['error'] = "å›¾è¡¨åˆ›å»ºå¤±è´¥"
            
        except Exception as e:
            result['error'] = str(e)
            logger.error(f"âŒ å¤„ç†è‚¡ç¥¨å¤±è´¥ {stock_code}: {e}")
        finally:
            result['elapsed_time'] = time.time() - start_time
        
        return result


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="ä¸­é—´å±‚ç”»çº¿è„šæœ¬ - åŸºç¡€å›¾è¡¨ + AnchorBackçº¿",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # å¤„ç†å½“å‰æ—¥æœŸçš„resByFilterä¸­çš„è‚¡ç¥¨
  python draw_line_back.py
  
  # å¤„ç†æŒ‡å®šæ—¥æœŸçš„resByFilterä¸­çš„è‚¡ç¥¨
  python draw_line_back.py --date 2025-10-20
  
  # æŒ‡å®šçº¿ç¨‹æ•°
  python draw_line_back.py --date 2025-10-20 --workers 6
  
  # å¤„ç†æŒ‡å®šè‚¡ç¥¨ä»£ç 
  python draw_line_back.py --codes 000001 600000 002603
        """
    )
    
    current_date = datetime.now().strftime('%Y%m%d')
    
    parser.add_argument('--date', type=str, 
                       help='æ—¥æœŸå‚æ•°ï¼Œæ ¼å¼ä¸ºYYYY-MM-DDï¼Œç”¨äºæ„å»ºresByFilterç›®å½•')
    parser.add_argument('--workers', type=int, default=4,
                       help='å¹¶å‘å¤„ç†çš„çº¿ç¨‹æ•° (é»˜è®¤: 4)')
    parser.add_argument('--codes', nargs='+', type=str,
                       help='è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œå¤šä¸ªä»£ç ç”¨ç©ºæ ¼åˆ†éš”ï¼ˆå¦‚ï¼š000001 600000ï¼‰')
    
    args = parser.parse_args()
    
    # å¤„ç†æ—¥æœŸå‚æ•°
    if args.date:
        try:
            date_obj = datetime.strptime(args.date, '%Y-%m-%d')
            date_str = date_obj.strftime('%Y%m%d')
        except ValueError:
            logger.error(f"âŒ æ—¥æœŸæ ¼å¼é”™è¯¯: {args.date}ï¼Œè¯·ä½¿ç”¨YYYY-MM-DDæ ¼å¼")
            sys.exit(1)
    else:
        date_str = current_date
    
    # åˆ›å»ºä¸­é—´å±‚ç”»çº¿å™¨
    drawer = BackLineDrawer()
    
    # å¦‚æœæŒ‡å®šäº†è‚¡ç¥¨ä»£ç ï¼Œç›´æ¥ä»dataç›®å½•è¯»å–
    if args.codes:
        logger.info(f"ğŸ“Š å¤„ç†æŒ‡å®šçš„è‚¡ç¥¨ä»£ç : {', '.join(args.codes)}")
        stock_list = []
        
        # è¯»å–stocklist.csvè·å–è‚¡ç¥¨åç§°å’Œè¡Œä¸šä¿¡æ¯
        stocklist_path = "../stocklist.csv"
        stock_info_dict = {}
        if os.path.exists(stocklist_path):
            try:
                stocklist_df = pd.read_csv(stocklist_path)
                for _, row in stocklist_df.iterrows():
                    code = str(row.get('symbol', '')).zfill(6)
                    name = str(row.get('name', code))
                    industry = str(row.get('industry', 'æœªçŸ¥è¡Œä¸š'))
                    stock_info_dict[code] = (name, industry)
                logger.info(f"âœ… å·²åŠ è½½ {len(stock_info_dict)} åªè‚¡ç¥¨çš„åŸºç¡€ä¿¡æ¯")
            except Exception as e:
                logger.warning(f"âš ï¸ è¯»å–stocklist.csvå¤±è´¥: {e}")
        
        # å¤„ç†æ¯ä¸ªè‚¡ç¥¨ä»£ç 
        for code in args.codes:
            normalized_code = code.zfill(6)
            
            # è·å–è‚¡ç¥¨åç§°å’Œè¡Œä¸š
            if normalized_code in stock_info_dict:
                name, industry = stock_info_dict[normalized_code]
            else:
                name = normalized_code
                industry = "æœªçŸ¥è¡Œä¸š"
                logger.warning(f"âš ï¸ æœªæ‰¾åˆ°è‚¡ç¥¨ {normalized_code} çš„åŸºç¡€ä¿¡æ¯ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            
            stock_list.append((normalized_code, name, industry, ""))
        
        logger.info(f"ğŸ“‹ å…±æœ‰ {len(stock_list)} åªè‚¡ç¥¨å¾…å¤„ç†")
        
        # ç”Ÿæˆè¾“å‡ºç›®å½•
        output_dir = f"{date_str}-drawLineBack"
        
        # æ‰¹é‡å¤„ç†è‚¡ç¥¨åˆ—è¡¨
        drawer.process_stock_list(stock_list, output_dir, "../data", args.workers)
        
    else:
        # åŸæœ‰é€»è¾‘ï¼šä»resByFilterè¯»å–è‚¡ç¥¨
        filter_dir = f"../{date_str}-resByFilter"
        if not os.path.exists(filter_dir):
            logger.error(f"âŒ ç›®å½•ä¸å­˜åœ¨: {filter_dir}")
            logger.info(f"ğŸ’¡ æç¤ºï¼šè¯·ç¡®ä¿å­˜åœ¨ {filter_dir} ç›®å½•ï¼Œæˆ–ä½¿ç”¨ --codes å‚æ•°æŒ‡å®šè‚¡ç¥¨ä»£ç ")
            sys.exit(1)
        
        # æŸ¥æ‰¾æ‰€æœ‰CSVæ–‡ä»¶
        csv_files = glob.glob(os.path.join(filter_dir, "*.csv"))
        if not csv_files:
            logger.error(f"âŒ åœ¨ç›®å½• {filter_dir} ä¸­æœªæ‰¾åˆ°CSVæ–‡ä»¶")
            sys.exit(1)
        
        logger.info(f"ğŸ“ æ‰¾åˆ° {len(csv_files)} ä¸ªCSVæ–‡ä»¶")
        
        # è¯»å–æ‰€æœ‰CSVæ–‡ä»¶ä¸­çš„è‚¡ç¥¨ï¼Œå¹¶å»é‡
        all_stocks = {}
        
        for file_path in csv_files:
            logger.info(f"ğŸ“„ è¯»å–æ–‡ä»¶: {file_path}")
            try:
                df = pd.read_csv(file_path)
                
                # ä»æ–‡ä»¶åæå–å‰ç¼€
                file_name = os.path.basename(file_path)
                file_prefix = ""
                
                import re
                patterns = [
                    (r'^ADX(\d+)', 'ADX'),
                    (r'^PDI(\d+)', 'PDI'),
                    (r'ADX(\d+)', 'ADX'),
                    (r'PDI(\d+)', 'PDI')
                ]
                
                for pattern, prefix_type in patterns:
                    match = re.search(pattern, file_name.upper())
                    if match:
                        file_prefix = f"{prefix_type}{match.group(1)}"
                        break
                
                logger.info(f"ğŸ“Š æ–‡ä»¶ç±»å‹: {file_prefix}")
                
                # æå–è‚¡ç¥¨ä¿¡æ¯
                for _, row in df.iterrows():
                    code = str(row.get('code', ''))
                    name = str(row.get('name', code))
                    industry = str(row.get('industry', 'æœªçŸ¥è¡Œä¸š'))
                    
                    if code:
                        normalized_code = code.zfill(6)
                        if normalized_code not in all_stocks:
                            all_stocks[normalized_code] = (normalized_code, name, industry, file_prefix)
                            
            except Exception as e:
                logger.error(f"âŒ è¯»å–æ–‡ä»¶ {file_path} å¤±è´¥: {e}")
                continue
        
        if not all_stocks:
            logger.error(f"âŒ æœªè¯»å–åˆ°æœ‰æ•ˆçš„è‚¡ç¥¨æ•°æ®")
            sys.exit(1)
        
        stock_list = list(all_stocks.values())
        logger.info(f"ğŸ“‹ å»é‡åå…±æœ‰ {len(stock_list)} åªè‚¡ç¥¨")
        
        # ç”Ÿæˆè¾“å‡ºç›®å½•
        output_dir = f"{date_str}-drawLineBack"
        
        # æ‰¹é‡å¤„ç†è‚¡ç¥¨åˆ—è¡¨
        drawer.process_stock_list(stock_list, output_dir, "../data", args.workers)
    
    logger.info("ğŸ‰ ç¨‹åºæ‰§è¡Œå®Œæˆ!")


if __name__ == "__main__":
    main()

