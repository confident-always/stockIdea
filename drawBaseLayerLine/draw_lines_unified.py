#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç»Ÿä¸€ç‰ˆåŸºç¡€å±‚ç”»çº¿è„šæœ¬
æ•´åˆæ‰€æœ‰drawBaseLayerLineåŠŸèƒ½ä¸ºå•ä¸€å¯æ‰§è¡Œè„šæœ¬

åŠŸèƒ½ç‰¹æ€§ï¼š
1. ä»resByFilterä¸­æå–æ‰€æœ‰è‚¡ç¥¨æ•°æ®
2. æ™ºèƒ½æ•°æ®éªŒè¯å’Œæ¸…æ´—
3. å¤šç®—æ³•é˜¶æ®µä½ç‚¹æ£€æµ‹ï¼ˆå…¨å±€æœ€ä½ç‚¹ã€æ»‘åŠ¨çª—å£ã€ä»·æ ¼åˆ†ä½æ•°ã€æŠ€æœ¯æŒ‡æ ‡ï¼‰
4. é«˜è´¨é‡å›¾è¡¨ç»˜åˆ¶ï¼ˆKçº¿å›¾ã€é˜¶æ®µä½ç‚¹çº¿ã€ç™¾åˆ†æ¯”æ¶¨å¹…çº¿ï¼‰
5. å¤šçº¿ç¨‹æ‰¹é‡å¤„ç†
6. å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•
7. å‘½ä»¤è¡Œå‚æ•°æ”¯æŒ

ä½¿ç”¨æ–¹æ³•ï¼š
    # å¤„ç†å•åªè‚¡ç¥¨
    python draw_lines_unified.py --stock 002895
    
    # æ‰¹é‡å¤„ç†æ‰€æœ‰è‚¡ç¥¨
    python draw_lines_unified.py --all
    
    # æŒ‡å®šè¾“å‡ºç›®å½•å’Œçº¿ç¨‹æ•°
    python draw_lines_unified.py --all --output drawLineRes --workers 4
    
    # ä»æŒ‡å®šæ•°æ®ç›®å½•è¯»å–
    python draw_lines_unified.py --all --data-dir ../data
"""

import os
import sys
import json
import pandas as pd
import numpy as np
from pathlib import Path
from typing import List, Dict, Tuple, Optional, Union
import logging
from datetime import datetime
import glob
import argparse
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
import time
from scipy.signal import argrelextrema

# è®¾ç½®matplotlibåç«¯å’Œå­—ä½“
import matplotlib
matplotlib.use('Agg')  # éäº¤äº’å¼åç«¯ï¼Œæ”¯æŒå¤šçº¿ç¨‹
import matplotlib.pyplot as plt
import matplotlib.dates as mdates

# å­—ä½“é…ç½® - ä¼˜å…ˆä½¿ç”¨è‹±æ–‡é¿å…å­—ä½“é—®é¢˜
plt.rcParams['font.family'] = ['Arial', 'DejaVu Sans', 'SimHei']
plt.rcParams['axes.unicode_minus'] = False

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] [%(threadName)s] %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('draw_lines_unified.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

# çº¿ç¨‹é”
progress_lock = threading.Lock()
matplotlib_lock = threading.Lock()  # ç”¨äºmatplotlibæ“ä½œçš„çº¿ç¨‹å®‰å…¨


class UnifiedLineDrawer:
    """ç»Ÿä¸€ç‰ˆç”»çº¿å™¨ - æ•´åˆæ‰€æœ‰åŠŸèƒ½"""
    
    def __init__(self, config_file: str = "lineConfig.json"):
        """åˆå§‹åŒ–ç»Ÿä¸€ç”»çº¿å™¨"""
        self.config_file = config_file
        self.percent_list = self._load_config()
        self.stock_info = self._load_stock_info()
        self.processed_count = 0
        self.total_count = 0
        logger.info(f"âœ… ç»Ÿä¸€ç”»çº¿å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"ğŸ“Š åŠ è½½{len(self.percent_list)}ä¸ªç™¾åˆ†æ¯”é…ç½®: {self.percent_list}")
        logger.info(f"ğŸ“ˆ åŠ è½½{len(self.stock_info)}åªè‚¡ç¥¨ä¿¡æ¯")
    
    def _load_config(self) -> List[str]:
        """åŠ è½½é…ç½®æ–‡ä»¶ä¸­çš„ç™¾åˆ†æ¯”æ•°æ®"""
        try:
            config_path = Path(self.config_file)
            if not config_path.exists():
                # å°è¯•åœ¨ä¸Šçº§ç›®å½•æŸ¥æ‰¾
                config_path = Path("..") / self.config_file
                if not config_path.exists():
                    logger.warning(f"âš ï¸ é…ç½®æ–‡ä»¶ {self.config_file} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
                    return ["3%", "16%", "25%", "34%", "50%", "67%", "128%", "228%", "247%", "323%", "457%", "589%", "636%", "770%", "823%", "935%"]
            
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
                percent_dic = config.get('percent_dic', [])
                logger.info(f"âœ… æˆåŠŸåŠ è½½é…ç½®æ–‡ä»¶: {config_path}")
                return percent_dic
        except Exception as e:
            logger.error(f"âŒ åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            # ä½¿ç”¨é»˜è®¤é…ç½®
            default_percents = ["3%", "16%", "25%", "34%", "50%", "67%", "128%", "228%", "247%", "323%", "457%", "589%", "636%", "770%", "823%", "935%"]
            logger.info(f"ä½¿ç”¨é»˜è®¤ç™¾åˆ†æ¯”é…ç½®")
            return default_percents
    
    def _load_stock_info(self) -> Dict[str, str]:
        """ä»resByFilterç›®å½•åŠ è½½è‚¡ç¥¨ä¿¡æ¯"""
        stock_info = {}
        try:
            # å°è¯•å¤šä¸ªå¯èƒ½çš„è·¯å¾„
            possible_paths = ["../resByFilter", "resByFilter", "./resByFilter"]
            res_dir = None
            
            for path in possible_paths:
                if os.path.exists(path):
                    res_dir = path
                    break
            
            if not res_dir:
                logger.warning(f"âš ï¸ æœªæ‰¾åˆ°resByFilterç›®å½•ï¼Œå°è¯•çš„è·¯å¾„: {possible_paths}")
                return stock_info
            
            csv_files = glob.glob(os.path.join(res_dir, "*.csv"))
            logger.info(f"ğŸ“ åœ¨{res_dir}ä¸­æ‰¾åˆ°{len(csv_files)}ä¸ªCSVæ–‡ä»¶")
            
            for csv_file in csv_files:
                try:
                    df = pd.read_csv(csv_file)
                    if 'code' in df.columns and 'name' in df.columns:
                        for _, row in df.iterrows():
                            code = str(row['code']).zfill(6)
                            name = str(row['name'])
                            stock_info[code] = name
                except Exception as e:
                    logger.warning(f"âš ï¸ è¯»å–æ–‡ä»¶å¤±è´¥ {csv_file}: {e}")
            
            logger.info(f"âœ… åŠ è½½è‚¡ç¥¨ä¿¡æ¯å®Œæˆï¼Œå…±{len(stock_info)}åªè‚¡ç¥¨")
            return stock_info
            
        except Exception as e:
            logger.error(f"âŒ åŠ è½½è‚¡ç¥¨ä¿¡æ¯å¤±è´¥: {e}")
            return stock_info
    
    def get_stock_list(self, data_dir: str = "../data") -> List[Tuple[str, str]]:
        """è·å–è‚¡ç¥¨åˆ—è¡¨"""
        stock_list = []
        
        # å¦‚æœæœ‰resByFilterçš„è‚¡ç¥¨ä¿¡æ¯ï¼Œä¼˜å…ˆä½¿ç”¨
        if self.stock_info:
            for code, name in self.stock_info.items():
                stock_list.append((code, name))
            logger.info(f"ğŸ“‹ ä»resByFilterè·å–è‚¡ç¥¨åˆ—è¡¨: {len(stock_list)}åª")
            return stock_list
        
        # å¦åˆ™ä»æ•°æ®ç›®å½•è·å–
        try:
            data_path = Path(data_dir)
            if not data_path.exists():
                logger.error(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
                return stock_list
            
            csv_files = list(data_path.glob("*.csv"))
            for csv_file in csv_files:
                code = csv_file.stem
                # å°è¯•ä»æ–‡ä»¶åæ¨æ–­è‚¡ç¥¨åç§°ï¼Œæˆ–ä½¿ç”¨ä»£ç ä½œä¸ºåç§°
                name = code
                stock_list.append((code, name))
            
            logger.info(f"ğŸ“‹ ä»æ•°æ®ç›®å½•è·å–è‚¡ç¥¨åˆ—è¡¨: {len(stock_list)}åª")
            return stock_list
            
        except Exception as e:
            logger.error(f"âŒ è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
            return stock_list
    
    def validate_and_load_data(self, stock_code: str, data_dir: str) -> Optional[pd.DataFrame]:
        """éªŒè¯å¹¶åŠ è½½è‚¡ç¥¨æ•°æ®"""
        try:
            # æ„å»ºæ–‡ä»¶è·¯å¾„
            data_path = Path(data_dir)
            csv_file = data_path / f"{stock_code}.csv"
            
            if not csv_file.exists():
                logger.warning(f"âš ï¸ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {csv_file}")
                return None
            
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            file_size = csv_file.stat().st_size
            if file_size < 1000:  # å°äº1KBçš„æ–‡ä»¶å¯èƒ½æœ‰é—®é¢˜
                logger.warning(f"âš ï¸ æ•°æ®æ–‡ä»¶è¿‡å°: {csv_file} ({file_size} bytes)")
                return None
            
            # è¯»å–æ•°æ®
            df = pd.read_csv(csv_file)
            
            # éªŒè¯å¿…è¦åˆ—
            required_columns = ['date', 'open', 'high', 'low', 'close']
            missing_columns = [col for col in required_columns if col not in df.columns]
            if missing_columns:
                logger.warning(f"âš ï¸ ç¼ºå°‘å¿…è¦åˆ— {missing_columns}: {stock_code}")
                return None
            
            # æ£€æŸ¥æ•°æ®è¡Œæ•°
            if len(df) < 100:  # è‡³å°‘éœ€è¦100å¤©çš„æ•°æ®
                logger.warning(f"âš ï¸ æ•°æ®è¡Œæ•°ä¸è¶³: {stock_code} ({len(df)} rows)")
                return None
            
            # æ•°æ®æ¸…æ´—
            df = df.dropna(subset=required_columns)
            
            # è½¬æ¢æ—¥æœŸæ ¼å¼
            df['date'] = pd.to_datetime(df['date'])
            df = df.sort_values('date').reset_index(drop=True)
            
            # éªŒè¯ä»·æ ¼æ•°æ®åˆç†æ€§
            price_columns = ['open', 'high', 'low', 'close']
            for col in price_columns:
                if (df[col] <= 0).any():
                    logger.warning(f"âš ï¸ å‘ç°éæ­£ä»·æ ¼æ•°æ®: {stock_code}")
                    df = df[df[col] > 0]
            
            # éªŒè¯é«˜ä½ä»·å…³ç³»
            invalid_rows = (df['high'] < df['low']) | (df['high'] < df['open']) | (df['high'] < df['close']) | \
                          (df['low'] > df['open']) | (df['low'] > df['close'])
            if invalid_rows.any():
                logger.warning(f"âš ï¸ å‘ç°ä»·æ ¼é€»è¾‘é”™è¯¯: {stock_code}")
                df = df[~invalid_rows]
            
            if len(df) < 50:  # æ¸…æ´—åæ•°æ®å¤ªå°‘
                logger.warning(f"âš ï¸ æ¸…æ´—åæ•°æ®ä¸è¶³: {stock_code} ({len(df)} rows)")
                return None
            
            logger.debug(f"âœ… æ•°æ®éªŒè¯é€šè¿‡: {stock_code} ({len(df)} rows)")
            return df
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åŠ è½½å¤±è´¥ {stock_code}: {e}")
            return None
    
    def find_stage_lows_unified(self, df: pd.DataFrame) -> List[Tuple[int, float, str]]:
        """ç»Ÿä¸€ç‰ˆé˜¶æ®µä½ç‚¹æ£€æµ‹ - åŸºäºzigzagè½¬æŠ˜æ£€æµ‹ï¼Œåªä¿ç•™ä¸€ä¸ªæœ€ç»ˆä½ç‚¹"""
        try:
            if len(df) < 50:
                logger.warning("âš ï¸ æ•°æ®ä¸è¶³ï¼Œæ— æ³•æ£€æµ‹é˜¶æ®µä½ç‚¹")
                return []
            
            # å®ç°zigzagè½¬æŠ˜æ£€æµ‹ç®—æ³•
            def detect_zigzag_turning_points(prices: np.ndarray, threshold: float = 0.6) -> List[int]:
                """æ£€æµ‹zigzagè½¬æŠ˜ç‚¹ï¼Œthresholdä¸ºè½¬æŠ˜å¹…åº¦é˜ˆå€¼ï¼ˆ60%å¯¹åº”0.6ï¼‰"""
                if len(prices) < 3:
                    return []
                
                turning_points = []
                current_trend = None  # 'up' or 'down'
                last_extreme_idx = 0
                last_extreme_price = prices[0]
                
                for i in range(1, len(prices)):
                    current_price = prices[i]
                    
                    # è®¡ç®—ç›¸å¯¹äºä¸Šä¸€ä¸ªæå€¼ç‚¹çš„å˜åŒ–å¹…åº¦
                    if last_extreme_price > 0:
                        change_ratio = abs(current_price - last_extreme_price) / last_extreme_price
                    else:
                        change_ratio = 0
                    
                    # æ£€æµ‹è½¬æŠ˜ç‚¹
                    if change_ratio >= threshold:
                        if current_price > last_extreme_price:
                            # ä¸Šæ¶¨è¶…è¿‡é˜ˆå€¼
                            if current_trend != 'up':
                                # è¶‹åŠ¿è½¬ä¸ºä¸Šæ¶¨ï¼Œè®°å½•å‰ä¸€ä¸ªä½ç‚¹
                                if current_trend == 'down':
                                    turning_points.append(last_extreme_idx)
                                current_trend = 'up'
                                last_extreme_idx = i
                                last_extreme_price = current_price
                        else:
                            # ä¸‹è·Œè¶…è¿‡é˜ˆå€¼
                            if current_trend != 'down':
                                # è¶‹åŠ¿è½¬ä¸ºä¸‹è·Œï¼Œè®°å½•å‰ä¸€ä¸ªé«˜ç‚¹
                                if current_trend == 'up':
                                    turning_points.append(last_extreme_idx)
                                current_trend = 'down'
                                last_extreme_idx = i
                                last_extreme_price = current_price
                    else:
                        # æ›´æ–°å½“å‰æå€¼ç‚¹
                        if current_trend == 'up' and current_price > last_extreme_price:
                            last_extreme_idx = i
                            last_extreme_price = current_price
                        elif current_trend == 'down' and current_price < last_extreme_price:
                            last_extreme_idx = i
                            last_extreme_price = current_price
                
                return turning_points
            
            # æ£€æµ‹zigzagè½¬æŠ˜ç‚¹
            turning_points = detect_zigzag_turning_points(df['close'].values, threshold=0.6)
            
            # æ‰¾åˆ°æœ€åä¸€ä¸ªè½¬æŠ˜ç‚¹ä¹‹åçš„æœ€ä½ç‚¹
            final_low_idx = None
            final_low_price = float('inf')
            
            if turning_points:
                # ä»æœ€åä¸€ä¸ªè½¬æŠ˜ç‚¹å¼€å§‹å¯»æ‰¾æœ€ä½ç‚¹
                last_turning_point = turning_points[-1]
                search_start = max(0, last_turning_point)
                
                # åœ¨è½¬æŠ˜ç‚¹ä¹‹åå¯»æ‰¾æœ€ä½ç‚¹
                for i in range(search_start, len(df)):
                    current_low = df.loc[i, 'low']
                    if current_low < final_low_price:
                        final_low_price = current_low
                        final_low_idx = i
            else:
                # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°è½¬æŠ˜ç‚¹ï¼Œä½¿ç”¨å…¨å±€æœ€ä½ç‚¹
                final_low_idx = df['low'].idxmin()
                final_low_price = df.loc[final_low_idx, 'low']
            
            # å¦‚æœä»ç„¶æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„ä½ç‚¹ï¼Œä½¿ç”¨å…¨å±€æœ€ä½ç‚¹ä½œä¸ºå¤‡é€‰
            if final_low_idx is None:
                final_low_idx = df['low'].idxmin()
                final_low_price = df.loc[final_low_idx, 'low']
            
            # æ ¼å¼åŒ–æ—¥æœŸ
            final_low_date = df.loc[final_low_idx, 'date'].strftime('%Y-%m-%d')
            
            # è¿”å›å•ä¸€ä½ç‚¹
            stage_lows = [(final_low_idx, final_low_price, final_low_date)]
            
            logger.debug(f"âœ… æ£€æµ‹åˆ°1ä¸ªæœ€ç»ˆä½ç‚¹: æ—¥æœŸ={final_low_date}, ä»·æ ¼={final_low_price:.2f}")
            return stage_lows
            
        except Exception as e:
            logger.error(f"âŒ é˜¶æ®µä½ç‚¹æ£€æµ‹å¤±è´¥: {e}")
            # å¤‡é€‰æ–¹æ¡ˆï¼šè¿”å›å…¨å±€æœ€ä½ç‚¹
            try:
                global_min_idx = df['low'].idxmin()
                global_min_price = df.loc[global_min_idx, 'low']
                global_min_date = df.loc[global_min_idx, 'date'].strftime('%Y-%m-%d')
                return [(global_min_idx, global_min_price, global_min_date)]
            except:
                return []
    
    def create_unified_chart(self, stock_code: str, stock_name: str, df: pd.DataFrame, 
                           stage_lows: List[Tuple[int, float, str]], output_file: str) -> bool:
        """åˆ›å»ºç»Ÿä¸€ç‰ˆé«˜è´¨é‡å›¾è¡¨"""
        fig = None
        try:
            # ä½¿ç”¨çº¿ç¨‹é”ç¡®ä¿matplotlibæ“ä½œçš„çº¿ç¨‹å®‰å…¨
            with matplotlib_lock:
                # åœ¨å¤šçº¿ç¨‹ç¯å¢ƒä¸‹ï¼Œç¡®ä¿matplotlibæ“ä½œçš„çº¿ç¨‹å®‰å…¨
                import matplotlib
                matplotlib.use('Agg')  # ç¡®ä¿ä½¿ç”¨éäº¤äº’å¼åç«¯
                
                # åˆ›å»ºé«˜è´¨é‡å›¾è¡¨
                fig, ax = plt.subplots(figsize=(20, 12), dpi=200)
                
                # è®¾ç½®æ—¥æœŸæ ¼å¼
                dates = df['date']
                
                # 1. ç»˜åˆ¶Kçº¿å›¾ï¼ˆç®€åŒ–ç‰ˆï¼‰
                for i in range(len(df)):
                    try:
                        date = dates.iloc[i]
                        open_price = df['open'].iloc[i]
                        high_price = df['high'].iloc[i]
                        low_price = df['low'].iloc[i]
                        close_price = df['close'].iloc[i]
                        
                        # æ•°æ®éªŒè¯
                        if pd.isna(open_price) or pd.isna(high_price) or pd.isna(low_price) or pd.isna(close_price):
                            continue
                        if high_price < low_price or high_price <= 0 or low_price <= 0:
                            continue
                        
                        # ç¡®å®šé¢œè‰²
                        color = 'red' if close_price >= open_price else 'green'
                        
                        # ç»˜åˆ¶é«˜ä½çº¿
                        ax.plot([date, date], [low_price, high_price], color='black', linewidth=0.5)
                        
                        # ç»˜åˆ¶å®ä½“ï¼ˆæ¯10æ ¹Kçº¿ç»˜åˆ¶ä¸€æ ¹ï¼Œæé«˜æ€§èƒ½ï¼‰
                        if i % 10 == 0 or i == len(df) - 1:
                            body_height = abs(close_price - open_price)
                            body_bottom = min(open_price, close_price)
                            
                            # ä½¿ç”¨çŸ©å½¢ç»˜åˆ¶å®ä½“
                            rect = plt.Rectangle((date, body_bottom), pd.Timedelta(days=1), body_height, 
                                               facecolor=color, alpha=0.7, linewidth=0.5)
                            ax.add_patch(rect)
                    except Exception as e:
                        logger.debug(f"è·³è¿‡Kçº¿æ•°æ® {i}: {e}")
                        continue
                
                # 2. ç»˜åˆ¶é˜¶æ®µä½ç‚¹æ°´å¹³çº¿ï¼ˆè“è‰²ç›´çº¿ï¼‰
                for i, (idx, price, date_str) in enumerate(stage_lows):
                    # ç»˜åˆ¶è“è‰²æ°´å¹³çº¿
                    ax.axhline(y=price, color='blue', linestyle='-', linewidth=2, alpha=0.8)
                    
                    # æ ‡æ³¨ä»·æ ¼
                    ax.text(dates.iloc[-1], price, f'{price:.2f}', 
                           fontsize=10, color='blue', fontweight='bold',
                           bbox=dict(boxstyle="round,pad=0.3", facecolor='white', alpha=0.8))
                
                # 3. ç»˜åˆ¶ç™¾åˆ†æ¯”æ¶¨å¹…çº¿ï¼ˆç²‰çº¢è‰²çº¿æ®µï¼ŒåŠ ç²—æ˜¾ç¤ºï¼‰
                if stage_lows:
                    base_price = min(price for _, price, _ in stage_lows)  # ä½¿ç”¨æœ€ä½ä»·ä½œä¸ºåŸºå‡†
                    
                    for i, percent_str in enumerate(self.percent_list):
                        try:
                            percent = float(percent_str.rstrip('%')) / 100
                            target_price = base_price * (1 + percent)
                            
                            # æ£€æŸ¥ç›®æ ‡ä»·æ ¼æ˜¯å¦åœ¨åˆç†èŒƒå›´å†…
                            max_price = df['high'].max()
                            if target_price <= max_price * 1.5:  # ä¸è¶…è¿‡å†å²æœ€é«˜ä»·çš„1.5å€
                                # ç»˜åˆ¶ç²‰çº¢è‰²è™šçº¿ï¼ˆåŠ ç²—ï¼‰
                                ax.axhline(y=target_price, color='hotpink', linestyle='--', linewidth=3, alpha=0.8)
                                
                                # æ ‡æ³¨ç™¾åˆ†æ¯”ï¼ˆåŠ ç²—å­—ä½“ï¼‰
                                ax.text(dates.iloc[0], target_price, f'+{percent_str}', 
                                       fontsize=12, color='hotpink', fontweight='bold',
                                       bbox=dict(boxstyle="round,pad=0.3", facecolor='white', alpha=0.9, edgecolor='hotpink', linewidth=2))
                        except (ValueError, TypeError):
                            continue
                
                # 4. è®¾ç½®å›¾è¡¨å±æ€§
                ax.set_title(f'{stock_code} {stock_name} - Stage Low Points Analysis', 
                            fontsize=16, fontweight='bold', pad=20)
                ax.set_xlabel('Date', fontsize=12)
                ax.set_ylabel('Price', fontsize=12)
                
                # è®¾ç½®æ—¥æœŸæ ¼å¼
                ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))
                ax.xaxis.set_major_locator(mdates.MonthLocator(interval=3))
                plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)
                
                # ç½‘æ ¼
                ax.grid(True, alpha=0.3)
                
                # è‡ªåŠ¨è°ƒæ•´å¸ƒå±€
                plt.tight_layout()
                
                # ä¿å­˜å›¾è¡¨
                plt.savefig(output_file, dpi=200, bbox_inches='tight', 
                           facecolor='white', edgecolor='none')
                
                # éªŒè¯è¾“å‡ºæ–‡ä»¶
                if os.path.exists(output_file):
                    file_size = os.path.getsize(output_file)
                    if file_size > 50000:  # è‡³å°‘50KB
                        logger.debug(f"âœ… å›¾è¡¨åˆ›å»ºæˆåŠŸ: {output_file} ({file_size} bytes)")
                        return True
                    else:
                        logger.warning(f"âš ï¸ ç”Ÿæˆçš„å›¾ç‰‡æ–‡ä»¶è¿‡å°: {output_file} ({file_size} bytes)")
                        return False
                else:
                    logger.error(f"âŒ å›¾è¡¨æ–‡ä»¶æœªç”Ÿæˆ: {output_file}")
                    return False
                    
        except Exception as e:
            logger.error(f"âŒ å›¾è¡¨åˆ›å»ºå¤±è´¥ {stock_code}: {type(e).__name__}: {e}")
            import traceback
            logger.debug(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            return False
        finally:
            # ç¡®ä¿é‡Šæ”¾matplotlibèµ„æº
            try:
                if fig is not None:
                    plt.close(fig)
                plt.close('all')  # å…³é—­æ‰€æœ‰å›¾å½¢
            except Exception as cleanup_error:
                logger.debug(f"èµ„æºæ¸…ç†å¼‚å¸¸: {cleanup_error}")
                pass
    
    def process_single_stock(self, stock_code: str, stock_name: str, 
                           output_dir: str, data_dir: str) -> dict:
        """å¤„ç†å•åªè‚¡ç¥¨"""
        start_time = time.time()
        result = {
            'stock_code': stock_code,
            'stock_name': stock_name,
            'success': False,
            'elapsed_time': 0,
            'error': None,
            'stage_lows_count': 0
        }
        
        try:
            # 1. éªŒè¯å¹¶åŠ è½½æ•°æ®
            df = self.validate_and_load_data(stock_code, data_dir)
            if df is None:
                result['error'] = "æ•°æ®åŠ è½½å¤±è´¥"
                return result
            
            # 2. æ£€æµ‹é˜¶æ®µä½ç‚¹
            stage_lows = self.find_stage_lows_unified(df)
            if not stage_lows:
                result['error'] = "æœªæ£€æµ‹åˆ°é˜¶æ®µä½ç‚¹"
                return result
            
            result['stage_lows_count'] = len(stage_lows)
            
            # 3. åˆ›å»ºè¾“å‡ºç›®å½•
            os.makedirs(output_dir, exist_ok=True)
            
            # 4. ç”Ÿæˆå›¾è¡¨
            output_file = os.path.join(output_dir, f"{stock_code}_{stock_name}.png")
            success = self.create_unified_chart(stock_code, stock_name, df, stage_lows, output_file)
            
            if success:
                result['success'] = True
                
                # æ›´æ–°è¿›åº¦
                with progress_lock:
                    self.processed_count += 1
                    logger.info(f"âœ… [{self.processed_count}/{self.total_count}] {stock_code} {stock_name} - {len(stage_lows)}ä¸ªä½ç‚¹")
            else:
                result['error'] = "å›¾è¡¨åˆ›å»ºå¤±è´¥"
            
        except Exception as e:
            result['error'] = str(e)
            logger.error(f"âŒ å¤„ç†è‚¡ç¥¨å¤±è´¥ {stock_code}: {e}")
        
        finally:
            result['elapsed_time'] = time.time() - start_time
        
        return result
    
    def process_all_stocks(self, output_dir: str = "drawLineRes", 
                          data_dir: str = "../data", workers: int = 4):
        """æ‰¹é‡å¤„ç†æ‰€æœ‰è‚¡ç¥¨"""
        logger.info(f"ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç†è‚¡ç¥¨")
        logger.info(f"ğŸ“ æ•°æ®ç›®å½•: {data_dir}")
        logger.info(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        logger.info(f"ğŸ§µ çº¿ç¨‹æ•°: {workers}")
        
        # è·å–è‚¡ç¥¨åˆ—è¡¨
        stock_list = self.get_stock_list(data_dir)
        if not stock_list:
            logger.error("âŒ æœªæ‰¾åˆ°ä»»ä½•è‚¡ç¥¨æ•°æ®")
            return
        
        self.total_count = len(stock_list)
        self.processed_count = 0
        
        logger.info(f"ğŸ“Š å¾…å¤„ç†è‚¡ç¥¨æ•°é‡: {self.total_count}")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        
        # å¤šçº¿ç¨‹å¤„ç†
        start_time = time.time()
        results = []
        
        with ThreadPoolExecutor(max_workers=workers) as executor:
            # æäº¤ä»»åŠ¡
            future_to_stock = {
                executor.submit(self.process_single_stock, code, name, output_dir, data_dir): (code, name)
                for code, name in stock_list
            }
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_stock):
                result = future.result()
                results.append(result)
        
        # ç»Ÿè®¡ç»“æœ
        total_time = time.time() - start_time
        success_count = sum(1 for r in results if r['success'])
        failed_count = len(results) - success_count
        
        logger.info(f"ğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆ!")
        logger.info(f"ğŸ“Š æ€»è®¡: {len(results)}åªè‚¡ç¥¨")
        logger.info(f"âœ… æˆåŠŸ: {success_count}åª")
        logger.info(f"âŒ å¤±è´¥: {failed_count}åª")
        logger.info(f"â±ï¸ æ€»è€—æ—¶: {total_time:.2f}ç§’")
        logger.info(f"âš¡ å¹³å‡é€Ÿåº¦: {len(results)/total_time:.2f}åª/ç§’")
        
        # ä¿å­˜å¤„ç†ç»“æœ
        results_file = os.path.join(output_dir, "processing_results.json")
        try:
            with open(results_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            logger.info(f"ğŸ“„ å¤„ç†ç»“æœå·²ä¿å­˜: {results_file}")
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")
        
        # æ˜¾ç¤ºå¤±è´¥çš„è‚¡ç¥¨
        failed_stocks = [r for r in results if not r['success']]
        if failed_stocks:
            logger.warning(f"âš ï¸ å¤±è´¥çš„è‚¡ç¥¨:")
            for r in failed_stocks[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                logger.warning(f"   {r['stock_code']} {r['stock_name']}: {r['error']}")
            if len(failed_stocks) > 10:
                logger.warning(f"   ... è¿˜æœ‰{len(failed_stocks)-10}åªè‚¡ç¥¨å¤±è´¥")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="ç»Ÿä¸€ç‰ˆåŸºç¡€å±‚ç”»çº¿è„šæœ¬ - æ•´åˆæ‰€æœ‰åŠŸèƒ½",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # å¤„ç†å•åªè‚¡ç¥¨
  python draw_lines_unified.py --stock 002895
  
  # æ‰¹é‡å¤„ç†æ‰€æœ‰è‚¡ç¥¨
  python draw_lines_unified.py --all
  
  # æŒ‡å®šè¾“å‡ºç›®å½•å’Œçº¿ç¨‹æ•°
  python draw_lines_unified.py --all --output drawLineRes --workers 4
  
  # ä»æŒ‡å®šæ•°æ®ç›®å½•è¯»å–
  python draw_lines_unified.py --all --data-dir ../data
        """
    )
    
    # äº’æ–¥å‚æ•°ç»„
    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument('--stock', type=str, help='å¤„ç†å•åªè‚¡ç¥¨ï¼ˆè‚¡ç¥¨ä»£ç ï¼‰')
    group.add_argument('--all', action='store_true', help='æ‰¹é‡å¤„ç†æ‰€æœ‰è‚¡ç¥¨')
    
    # å¯é€‰å‚æ•°
    parser.add_argument('--output', type=str, default='drawLineRes', 
                       help='è¾“å‡ºç›®å½• (é»˜è®¤: drawLineRes)')
    parser.add_argument('--data-dir', type=str, default='../data', 
                       help='æ•°æ®ç›®å½• (é»˜è®¤: ../data)')
    parser.add_argument('--workers', type=int, default=4, 
                       help='çº¿ç¨‹æ•° (é»˜è®¤: 4)')
    parser.add_argument('--config', type=str, default='lineConfig.json', 
                       help='é…ç½®æ–‡ä»¶ (é»˜è®¤: lineConfig.json)')
    
    args = parser.parse_args()
    
    # åˆ›å»ºç»Ÿä¸€ç”»çº¿å™¨
    drawer = UnifiedLineDrawer(config_file=args.config)
    
    if args.stock:
        # å¤„ç†å•åªè‚¡ç¥¨
        stock_code = args.stock
        stock_name = drawer.stock_info.get(stock_code, stock_code)
        
        logger.info(f"ğŸ¯ å¤„ç†å•åªè‚¡ç¥¨: {stock_code} {stock_name}")
        
        result = drawer.process_single_stock(stock_code, stock_name, args.output, args.data_dir)
        
        if result['success']:
            logger.info(f"âœ… å¤„ç†æˆåŠŸ: {stock_code} {stock_name}")
            logger.info(f"ğŸ“Š æ£€æµ‹åˆ°{result['stage_lows_count']}ä¸ªé˜¶æ®µä½ç‚¹")
            logger.info(f"â±ï¸ è€—æ—¶: {result['elapsed_time']:.2f}ç§’")
        else:
            logger.error(f"âŒ å¤„ç†å¤±è´¥: {stock_code} {stock_name} - {result['error']}")
            sys.exit(1)
    
    elif args.all:
        # æ‰¹é‡å¤„ç†æ‰€æœ‰è‚¡ç¥¨
        drawer.process_all_stocks(args.output, args.data_dir, args.workers)
    
    logger.info("ğŸ‰ ç¨‹åºæ‰§è¡Œå®Œæˆ!")


if __name__ == "__main__":
    main()