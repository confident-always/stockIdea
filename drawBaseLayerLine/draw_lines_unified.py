#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç»Ÿä¸€ç‰ˆåŸºç¡€å±‚ç”»çº¿è„šæœ¬
æ•´åˆæ‰€æœ‰drawBaseLayerLineåŠŸèƒ½ä¸ºå•ä¸€å¯æ‰§è¡Œè„šæœ¬

åŠŸèƒ½ç‰¹æ€§ï¼š
1. ä»resByFilterä¸­æå–æ‰€æœ‰è‚¡ç¥¨æ•°æ®
2. æ™ºèƒ½æ•°æ®éªŒè¯å’Œæ¸…æ´—
3. å¤šç®—æ³•é˜¶æ®µä½ç‚¹æ£€æµ‹ï¼ˆå…¨å±€æœ€ä½ç‚¹ã€æ»‘åŠ¨çª—å£ã€ä»·æ ¼åˆ†ä½æ•°ã€æŠ€æœ¯æŒ‡æ ‡ï¼‰
4. é«˜è´¨é‡å›¾è¡¨ç»˜åˆ¶ï¼ˆKçº¿å›¾ã€é˜¶æ®µä½ç‚¹çº¿ã€ç™¾åˆ†æ¯”æ¶¨å¹…çº¿ï¼‰
5. å¤šçº¿ç¨‹æ‰¹é‡å¤„ç†
6. å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•
7. å‘½ä»¤è¡Œå‚æ•°æ”¯æŒ

ä½¿ç”¨æ–¹æ³•ï¼š
    # å¤„ç†å•åªè‚¡ç¥¨
    python draw_lines_unified.py --stock 002895
    
    # æ‰¹é‡å¤„ç†æ‰€æœ‰è‚¡ç¥¨
    python draw_lines_unified.py --all
    
    # æŒ‡å®šè¾“å‡ºç›®å½•å’Œçº¿ç¨‹æ•°
    python draw_lines_unified.py --all --output drawLineRes --workers 4
    
    # ä»æŒ‡å®šæ•°æ®ç›®å½•è¯»å–
    python draw_lines_unified.py --all --data-dir ../data
"""

import os
import sys
import json
import pandas as pd
import numpy as np
from pathlib import Path
from typing import List, Dict, Tuple, Optional, Union
import logging
from datetime import datetime
import glob
import argparse
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
import time
from scipy.signal import argrelextrema

# è®¾ç½®matplotlibåç«¯å’Œå­—ä½“
import matplotlib
matplotlib.use('Agg')  # éäº¤äº’å¼åç«¯ï¼Œæ”¯æŒå¤šçº¿ç¨‹
import matplotlib.pyplot as plt
import matplotlib.dates as mdates

# å­—ä½“é…ç½® - ä½¿ç”¨macOSç³»ç»Ÿæ”¯æŒçš„ä¸­æ–‡å­—ä½“
plt.rcParams['font.family'] = ['Heiti TC', 'PingFang HK', 'Arial Unicode MS', 'Arial', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] [%(threadName)s] %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('draw_lines_unified.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

# çº¿ç¨‹é”
progress_lock = threading.Lock()
matplotlib_lock = threading.Lock()  # ç”¨äºmatplotlibæ“ä½œçš„çº¿ç¨‹å®‰å…¨


class UnifiedLineDrawer:
    """ç»Ÿä¸€ç‰ˆç”»çº¿å™¨ - æ•´åˆæ‰€æœ‰åŠŸèƒ½"""
    
    def __init__(self, config_file: str = "lineConfig.json"):
        """åˆå§‹åŒ–ç»Ÿä¸€ç”»çº¿å™¨"""
        self.config_file = config_file
        self.percent_list = self._load_config()
        self.stock_info = self._load_stock_info()
        self.processed_count = 0
        self.total_count = 0
        logger.info(f"âœ… ç»Ÿä¸€ç”»çº¿å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"ğŸ“Š åŠ è½½{len(self.percent_list)}ä¸ªç™¾åˆ†æ¯”é…ç½®: {self.percent_list}")
        logger.info(f"ğŸ“ˆ åŠ è½½{len(self.stock_info)}åªè‚¡ç¥¨ä¿¡æ¯")
    
    def _load_config(self) -> List[str]:
        """åŠ è½½é…ç½®æ–‡ä»¶ä¸­çš„ç™¾åˆ†æ¯”æ•°æ®"""
        try:
            config_path = Path(self.config_file)
            if not config_path.exists():
                # å°è¯•åœ¨ä¸Šçº§ç›®å½•æŸ¥æ‰¾
                config_path = Path("..") / self.config_file
                if not config_path.exists():
                    logger.warning(f"âš ï¸ é…ç½®æ–‡ä»¶ {self.config_file} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
                    return ["3%", "16%", "25%", "34%", "50%", "67%", "128%", "228%", "247%", "323%", "457%", "589%", "636%", "770%", "823%", "935%"]
            
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
                percent_dic = config.get('percent_dic', [])
                logger.info(f"âœ… æˆåŠŸåŠ è½½é…ç½®æ–‡ä»¶: {config_path}")
                return percent_dic
        except Exception as e:
            logger.error(f"âŒ åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            # ä½¿ç”¨é»˜è®¤é…ç½®
            default_percents = ["3%", "16%", "25%", "34%", "50%", "67%", "128%", "228%", "247%", "323%", "457%", "589%", "636%", "770%", "823%", "935%"]
            logger.info(f"ä½¿ç”¨é»˜è®¤ç™¾åˆ†æ¯”é…ç½®")
            return default_percents
    
    def _load_stock_info(self) -> Dict[str, Dict[str, str]]:
        """ä»stocklist.csvåŠ è½½è‚¡ç¥¨ä¿¡æ¯ï¼ˆåç§°å’Œè¡Œä¸šï¼‰"""
        stock_info = {}
        try:
            # å°è¯•å¤šä¸ªå¯èƒ½çš„stocklist.csvè·¯å¾„
            possible_paths = ["../stocklist.csv", "stocklist.csv", "./stocklist.csv"]
            stocklist_file = None
            
            for path in possible_paths:
                if os.path.exists(path):
                    stocklist_file = path
                    break
            
            if stocklist_file:
                # ä»stocklist.csvåŠ è½½è‚¡ç¥¨ä¿¡æ¯
                try:
                    df = pd.read_csv(stocklist_file)
                    logger.info(f"ğŸ“ ä»{stocklist_file}åŠ è½½è‚¡ç¥¨ä¿¡æ¯")
                    
                    if 'symbol' in df.columns and 'name' in df.columns and 'industry' in df.columns:
                        for _, row in df.iterrows():
                            code = str(row['symbol']).zfill(6)
                            name = str(row['name'])
                            industry = str(row['industry']) if pd.notna(row['industry']) else "æœªçŸ¥è¡Œä¸š"
                            stock_info[code] = {'name': name, 'industry': industry}
                        
                        logger.info(f"âœ… ä»stocklist.csvåŠ è½½è‚¡ç¥¨ä¿¡æ¯å®Œæˆï¼Œå…±{len(stock_info)}åªè‚¡ç¥¨")
                        return stock_info
                    else:
                        logger.warning(f"âš ï¸ stocklist.csvç¼ºå°‘å¿…è¦å­—æ®µ: symbol, name, industry")
                except Exception as e:
                    logger.warning(f"âš ï¸ è¯»å–stocklist.csvå¤±è´¥: {e}")
            
            # å¦‚æœstocklist.csvä¸å¯ç”¨ï¼Œå›é€€åˆ°ä»resByFilterç›®å½•åŠ è½½
            logger.info("ğŸ“ stocklist.csvä¸å¯ç”¨ï¼Œå›é€€åˆ°ä»resByFilterç›®å½•åŠ è½½è‚¡ç¥¨ä¿¡æ¯")
            possible_paths = ["../resByFilter", "resByFilter", "./resByFilter"]
            res_dir = None
            
            for path in possible_paths:
                if os.path.exists(path):
                    res_dir = path
                    break
            
            if not res_dir:
                logger.warning(f"âš ï¸ æœªæ‰¾åˆ°resByFilterç›®å½•ï¼Œå°è¯•çš„è·¯å¾„: {possible_paths}")
                return stock_info
            
            csv_files = glob.glob(os.path.join(res_dir, "*.csv"))
            logger.info(f"ğŸ“ åœ¨{res_dir}ä¸­æ‰¾åˆ°{len(csv_files)}ä¸ªCSVæ–‡ä»¶")
            
            for csv_file in csv_files:
                try:
                    df = pd.read_csv(csv_file)
                    if 'code' in df.columns and 'name' in df.columns:
                        for _, row in df.iterrows():
                            code = str(row['code']).zfill(6)
                            name = str(row['name'])
                            stock_info[code] = {'name': name, 'industry': "æœªçŸ¥è¡Œä¸š"}
                except Exception as e:
                    logger.warning(f"âš ï¸ è¯»å–æ–‡ä»¶å¤±è´¥ {csv_file}: {e}")
            
            logger.info(f"âœ… åŠ è½½è‚¡ç¥¨ä¿¡æ¯å®Œæˆï¼Œå…±{len(stock_info)}åªè‚¡ç¥¨")
            return stock_info
            
        except Exception as e:
            logger.error(f"âŒ åŠ è½½è‚¡ç¥¨ä¿¡æ¯å¤±è´¥: {e}")
            return stock_info
    
    def get_stock_list(self, data_dir: str = "../data") -> List[Tuple[str, str, str]]:
        """è·å–è‚¡ç¥¨åˆ—è¡¨ï¼Œè¿”å›(code, name, industry)"""
        stock_list = []
        
        # å¦‚æœæœ‰è‚¡ç¥¨ä¿¡æ¯ï¼Œä¼˜å…ˆä½¿ç”¨
        if self.stock_info:
            for code, info in self.stock_info.items():
                name = info.get('name', code)
                industry = info.get('industry', 'æœªçŸ¥è¡Œä¸š')
                stock_list.append((code, name, industry))
            logger.info(f"ğŸ“‹ ä»è‚¡ç¥¨ä¿¡æ¯è·å–è‚¡ç¥¨åˆ—è¡¨: {len(stock_list)}åª")
            return stock_list
        
        # å¦åˆ™ä»æ•°æ®ç›®å½•è·å–
        try:
            data_path = Path(data_dir)
            if not data_path.exists():
                logger.error(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
                return stock_list
            
            csv_files = list(data_path.glob("*.csv"))
            for csv_file in csv_files:
                code = csv_file.stem
                # å°è¯•ä»æ–‡ä»¶åæ¨æ–­è‚¡ç¥¨åç§°ï¼Œæˆ–ä½¿ç”¨ä»£ç ä½œä¸ºåç§°
                name = code
                industry = "æœªçŸ¥è¡Œä¸š"
                stock_list.append((code, name, industry))
            
            logger.info(f"ğŸ“‹ ä»æ•°æ®ç›®å½•è·å–è‚¡ç¥¨åˆ—è¡¨: {len(stock_list)}åª")
            return stock_list
            
        except Exception as e:
            logger.error(f"âŒ è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
            return stock_list
    
    def validate_and_load_data(self, stock_code: str, data_dir: str) -> Optional[pd.DataFrame]:
        """éªŒè¯å¹¶åŠ è½½è‚¡ç¥¨æ•°æ®"""
        try:
            # æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç ï¼ˆè¡¥é›¶åˆ°6ä½ï¼‰
            normalized_code = str(stock_code).zfill(6)
            
            # æ„å»ºæ–‡ä»¶è·¯å¾„
            data_path = Path(data_dir)
            csv_file = data_path / f"{normalized_code}.csv"
            
            if not csv_file.exists():
                logger.warning(f"âš ï¸ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {csv_file}")
                return None
            
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            file_size = csv_file.stat().st_size
            if file_size < 1000:  # å°äº1KBçš„æ–‡ä»¶å¯èƒ½æœ‰é—®é¢˜
                logger.warning(f"âš ï¸ æ•°æ®æ–‡ä»¶è¿‡å°: {csv_file} ({file_size} bytes)")
                return None
            
            # è¯»å–æ•°æ®
            df = pd.read_csv(csv_file)
            
            # éªŒè¯å¿…è¦åˆ—
            required_columns = ['date', 'open', 'high', 'low', 'close']
            missing_columns = [col for col in required_columns if col not in df.columns]
            if missing_columns:
                logger.warning(f"âš ï¸ ç¼ºå°‘å¿…è¦åˆ— {missing_columns}: {stock_code}")
                return None
            
            # æ£€æŸ¥æ•°æ®è¡Œæ•°
            if len(df) < 100:  # è‡³å°‘éœ€è¦100å¤©çš„æ•°æ®
                logger.warning(f"âš ï¸ æ•°æ®è¡Œæ•°ä¸è¶³: {stock_code} ({len(df)} rows)")
                return None
            
            # æ•°æ®æ¸…æ´—
            df = df.dropna(subset=required_columns)
            
            # è½¬æ¢æ—¥æœŸæ ¼å¼
            df['date'] = pd.to_datetime(df['date'])
            df = df.sort_values('date').reset_index(drop=True)
            
            # éªŒè¯ä»·æ ¼æ•°æ®åˆç†æ€§
            price_columns = ['open', 'high', 'low', 'close']
            for col in price_columns:
                if (df[col] <= 0).any():
                    logger.warning(f"âš ï¸ å‘ç°éæ­£ä»·æ ¼æ•°æ®: {stock_code}")
                    df = df[df[col] > 0]
            
            # éªŒè¯é«˜ä½ä»·å…³ç³»
            invalid_rows = (df['high'] < df['low']) | (df['high'] < df['open']) | (df['high'] < df['close']) | \
                          (df['low'] > df['open']) | (df['low'] > df['close'])
            if invalid_rows.any():
                logger.warning(f"âš ï¸ å‘ç°ä»·æ ¼é€»è¾‘é”™è¯¯: {stock_code}")
                df = df[~invalid_rows]
            
            if len(df) < 50:  # æ¸…æ´—åæ•°æ®å¤ªå°‘
                logger.warning(f"âš ï¸ æ¸…æ´—åæ•°æ®ä¸è¶³: {stock_code} ({len(df)} rows)")
                return None
            
            logger.debug(f"âœ… æ•°æ®éªŒè¯é€šè¿‡: {stock_code} ({len(df)} rows)")
            return df
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åŠ è½½å¤±è´¥ {stock_code}: {e}")
            return None
    
    def find_stage_lows_unified(self, df: pd.DataFrame) -> List[Tuple[int, float, str]]:
        """ç»Ÿä¸€ç‰ˆé˜¶æ®µä½ç‚¹æ£€æµ‹ - åŸºäºå†å²æœ€é«˜ä»·åçš„æœ€ä½ç‚¹ï¼Œç¡®ä¿ç¬¦åˆå±±å³°å®šä¹‰"""
        try:
            if len(df) < 50:
                logger.warning("âš ï¸ æ•°æ®ä¸è¶³ï¼Œæ— æ³•æ£€æµ‹é˜¶æ®µä½ç‚¹")
                return []
            
            # æ‰¾åˆ°å†å²æœ€é«˜ä»·ä½ç½®
            max_high_idx = df['high'].idxmax()
            max_high_price = df.loc[max_high_idx, 'high']
            max_high_date = df.loc[max_high_idx, 'date']
            
            # è®¡ç®—70%è·Œå¹…ä½ç½®ï¼ˆå±±å³°å®šä¹‰çš„é˜ˆå€¼ï¼‰
            decline_70_threshold = max_high_price * 0.3
            
            # ä»å†å²æœ€é«˜ä»·ä¹‹åå¼€å§‹å¯»æ‰¾æœ€ä½ç‚¹
            after_peak_df = df[df.index > max_high_idx].copy()
            
            final_low_idx = None
            final_low_price = float('inf')
            final_low_date = None
            
            if len(after_peak_df) > 0:
                # åœ¨å†å²æœ€é«˜ä»·ä¹‹åå¯»æ‰¾æœ€ä½ç‚¹
                min_idx_after_peak = after_peak_df['low'].idxmin()
                min_price_after_peak = after_peak_df.loc[min_idx_after_peak, 'low']
                min_date_after_peak = after_peak_df.loc[min_idx_after_peak, 'date']
                
                # æ£€æŸ¥æ˜¯å¦ç¬¦åˆ70%è·Œå¹…æ¡ä»¶ï¼ˆå±±å³°å®šä¹‰ï¼‰
                if min_price_after_peak <= decline_70_threshold:
                    # ç¬¦åˆå±±å³°å®šä¹‰ï¼Œä½¿ç”¨å±±å³°åçš„æœ€ä½ç‚¹
                    final_low_idx = min_idx_after_peak
                    final_low_price = min_price_after_peak
                    final_low_date = min_date_after_peak
                    
                    logger.debug(f"âœ… ç¬¦åˆå±±å³°å®šä¹‰: æœ€é«˜ä»·={max_high_price:.2f}({max_high_date.strftime('%Y-%m-%d')}), "
                               f"70%è·Œå¹…é˜ˆå€¼={decline_70_threshold:.2f}, å±±å³°åæœ€ä½ä»·={final_low_price:.2f}")
                else:
                    # ä¸ç¬¦åˆå±±å³°å®šä¹‰ï¼Œä½¿ç”¨zigzagç®—æ³•å¯»æ‰¾è½¬æŠ˜ç‚¹
                    logger.debug(f"âš ï¸ ä¸ç¬¦åˆå±±å³°å®šä¹‰: å±±å³°åæœ€ä½ä»·{min_price_after_peak:.2f} > 70%è·Œå¹…é˜ˆå€¼{decline_70_threshold:.2f}")
                    
                    # å®ç°zigzagè½¬æŠ˜æ£€æµ‹ç®—æ³•ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ
                    def detect_zigzag_turning_points(prices: np.ndarray, threshold: float = 0.6) -> List[int]:
                        """æ£€æµ‹zigzagè½¬æŠ˜ç‚¹ï¼Œthresholdä¸ºè½¬æŠ˜å¹…åº¦é˜ˆå€¼ï¼ˆ60%å¯¹åº”0.6ï¼‰"""
                        if len(prices) < 3:
                            return []
                        
                        turning_points = []
                        current_trend = None  # 'up' or 'down'
                        last_extreme_idx = 0
                        last_extreme_price = prices[0]
                        
                        for i in range(1, len(prices)):
                            current_price = prices[i]
                            
                            # è®¡ç®—ç›¸å¯¹äºä¸Šä¸€ä¸ªæå€¼ç‚¹çš„å˜åŒ–å¹…åº¦
                            if last_extreme_price > 0:
                                change_ratio = abs(current_price - last_extreme_price) / last_extreme_price
                            else:
                                change_ratio = 0
                            
                            # æ£€æµ‹è½¬æŠ˜ç‚¹
                            if change_ratio >= threshold:
                                if current_price > last_extreme_price:
                                    # ä¸Šæ¶¨è¶…è¿‡é˜ˆå€¼
                                    if current_trend != 'up':
                                        # è¶‹åŠ¿è½¬ä¸ºä¸Šæ¶¨ï¼Œè®°å½•å‰ä¸€ä¸ªä½ç‚¹
                                        if current_trend == 'down':
                                            turning_points.append(last_extreme_idx)
                                        current_trend = 'up'
                                        last_extreme_idx = i
                                        last_extreme_price = current_price
                                else:
                                    # ä¸‹è·Œè¶…è¿‡é˜ˆå€¼
                                    if current_trend != 'down':
                                        # è¶‹åŠ¿è½¬ä¸ºä¸‹è·Œï¼Œè®°å½•å‰ä¸€ä¸ªé«˜ç‚¹
                                        if current_trend == 'up':
                                            turning_points.append(last_extreme_idx)
                                        current_trend = 'down'
                                        last_extreme_idx = i
                                        last_extreme_price = current_price
                            else:
                                # æ›´æ–°å½“å‰æå€¼ç‚¹
                                if current_trend == 'up' and current_price > last_extreme_price:
                                    last_extreme_idx = i
                                    last_extreme_price = current_price
                                elif current_trend == 'down' and current_price < last_extreme_price:
                                    last_extreme_idx = i
                                    last_extreme_price = current_price
                        
                        return turning_points
                    
                    # æ£€æµ‹zigzagè½¬æŠ˜ç‚¹
                    turning_points = detect_zigzag_turning_points(df['close'].values, threshold=0.6)
                    
                    if turning_points:
                        # ä»æœ€åä¸€ä¸ªè½¬æŠ˜ç‚¹å¼€å§‹å¯»æ‰¾æœ€ä½ç‚¹
                        last_turning_point = turning_points[-1]
                        search_start = max(0, last_turning_point)
                        
                        # åœ¨è½¬æŠ˜ç‚¹ä¹‹åå¯»æ‰¾æœ€ä½ç‚¹
                        for i in range(search_start, len(df)):
                            current_low = df.loc[i, 'low']
                            if current_low < final_low_price:
                                final_low_price = current_low
                                final_low_idx = i
                        
                        if final_low_idx is not None:
                            final_low_date = df.loc[final_low_idx, 'date']
            
            # å¦‚æœä»ç„¶æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„ä½ç‚¹ï¼Œä½¿ç”¨å…¨å±€æœ€ä½ç‚¹ä½œä¸ºå¤‡é€‰
            if final_low_idx is None:
                final_low_idx = df['low'].idxmin()
                final_low_price = df.loc[final_low_idx, 'low']
                final_low_date = df.loc[final_low_idx, 'date']
                logger.debug(f"âš ï¸ ä½¿ç”¨å…¨å±€æœ€ä½ç‚¹ä½œä¸ºå¤‡é€‰")
            
            # æ ¼å¼åŒ–æ—¥æœŸ
            final_low_date_str = final_low_date.strftime('%Y-%m-%d')
            
            # è¿”å›å•ä¸€ä½ç‚¹
            stage_lows = [(final_low_idx, final_low_price, final_low_date_str)]
            
            logger.debug(f"âœ… æ£€æµ‹åˆ°1ä¸ªæœ€ç»ˆä½ç‚¹: æ—¥æœŸ={final_low_date_str}, ä»·æ ¼={final_low_price:.2f}")
            return stage_lows
            
        except Exception as e:
            logger.error(f"âŒ é˜¶æ®µä½ç‚¹æ£€æµ‹å¤±è´¥: {e}")
            # å¤‡é€‰æ–¹æ¡ˆï¼šè¿”å›å…¨å±€æœ€ä½ç‚¹
            try:
                global_min_idx = df['low'].idxmin()
                global_min_price = df.loc[global_min_idx, 'low']
                global_min_date = df.loc[global_min_idx, 'date'].strftime('%Y-%m-%d')
                return [(global_min_idx, global_min_price, global_min_date)]
            except:
                return []
    
    def create_unified_chart(self, stock_code: str, stock_name: str, df: pd.DataFrame, 
                           stage_lows: List[Tuple[int, float, str]], output_file: str) -> bool:
        """åˆ›å»ºç»Ÿä¸€ç‰ˆé«˜è´¨é‡å›¾è¡¨"""
        fig = None
        try:
            # ä½¿ç”¨çº¿ç¨‹é”ç¡®ä¿matplotlibæ“ä½œçš„çº¿ç¨‹å®‰å…¨
            with matplotlib_lock:
                # åœ¨å¤šçº¿ç¨‹ç¯å¢ƒä¸‹ï¼Œç¡®ä¿matplotlibæ“ä½œçš„çº¿ç¨‹å®‰å…¨
                import matplotlib
                matplotlib.use('Agg')  # ç¡®ä¿ä½¿ç”¨éäº¤äº’å¼åç«¯
                
                # åˆ›å»ºé«˜è´¨é‡å›¾è¡¨
                fig, ax = plt.subplots(figsize=(20, 12), dpi=200)
                
                # è·å–æœ€ä½ç‚¹ä½ç½®ï¼Œåªæ˜¾ç¤ºä»æœ€ä½ç‚¹å¼€å§‹å¾€åçš„æ•°æ®
                if stage_lows:
                    lowest_idx, _, _ = stage_lows[0]  # è·å–æœ€ä½ç‚¹çš„ç´¢å¼•
                    # æˆªå–ä»æœ€ä½ç‚¹å¼€å§‹çš„æ•°æ®
                    df_display = df.iloc[lowest_idx:].copy()
                    df_display = df_display.reset_index(drop=True)
                else:
                    # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°ä½ç‚¹ï¼Œæ˜¾ç¤ºå…¨éƒ¨æ•°æ®
                    df_display = df.copy()
                
                # è®¾ç½®æ—¥æœŸæ ¼å¼
                dates = df_display['date']
                
                # 1. ç»˜åˆ¶Kçº¿å›¾ï¼ˆç®€åŒ–ç‰ˆï¼‰
                for i in range(len(df_display)):
                    try:
                        date = dates.iloc[i]
                        open_price = df_display['open'].iloc[i]
                        high_price = df_display['high'].iloc[i]
                        low_price = df_display['low'].iloc[i]
                        close_price = df_display['close'].iloc[i]
                        
                        # æ•°æ®éªŒè¯
                        if pd.isna(open_price) or pd.isna(high_price) or pd.isna(low_price) or pd.isna(close_price):
                            continue
                        if high_price < low_price or high_price <= 0 or low_price <= 0:
                            continue
                        
                        # ç¡®å®šé¢œè‰²
                        color = 'red' if close_price >= open_price else 'green'
                        
                        # ç»˜åˆ¶é«˜ä½çº¿
                        ax.plot([date, date], [low_price, high_price], color='black', linewidth=0.5)
                        
                        # ç»˜åˆ¶å®ä½“ï¼ˆæ¯10æ ¹Kçº¿ç»˜åˆ¶ä¸€æ ¹ï¼Œæé«˜æ€§èƒ½ï¼‰
                        if i % 10 == 0 or i == len(df_display) - 1:
                            body_height = abs(close_price - open_price)
                            body_bottom = min(open_price, close_price)
                            
                            # ä½¿ç”¨çŸ©å½¢ç»˜åˆ¶å®ä½“
                            rect = plt.Rectangle((date, body_bottom), pd.Timedelta(days=1), body_height, 
                                               facecolor=color, alpha=0.7, linewidth=0.5)
                            ax.add_patch(rect)
                    except Exception as e:
                        logger.debug(f"è·³è¿‡Kçº¿æ•°æ® {i}: {e}")
                        continue
                
                # 2. ç»˜åˆ¶é˜¶æ®µä½ç‚¹æ°´å¹³çº¿ï¼ˆè“è‰²ç›´çº¿ï¼‰
                for i, (idx, price, date_str) in enumerate(stage_lows):
                    # ç»˜åˆ¶è“è‰²æ°´å¹³çº¿
                    ax.axhline(y=price, color='blue', linestyle='-', linewidth=2, alpha=0.8)
                    
                    # æ ‡æ³¨ä»·æ ¼
                    ax.text(dates.iloc[-1], price, f'{price:.2f}', 
                           fontsize=10, color='blue', fontweight='bold',
                           bbox=dict(boxstyle="round,pad=0.3", facecolor='white', alpha=0.8))
                
                # 3. ç»˜åˆ¶ç™¾åˆ†æ¯”æ¶¨å¹…çº¿ï¼ˆç²‰çº¢è‰²çº¿æ®µï¼ŒåŠ ç²—æ˜¾ç¤ºï¼‰
                if stage_lows:
                    base_price = min(price for _, price, _ in stage_lows)  # ä½¿ç”¨æœ€ä½ä»·ä½œä¸ºåŸºå‡†
                    
                    for i, percent_str in enumerate(self.percent_list):
                        try:
                            percent = float(percent_str.rstrip('%')) / 100
                            target_price = base_price * (1 + percent)
                            
                            # æ£€æŸ¥ç›®æ ‡ä»·æ ¼æ˜¯å¦åœ¨åˆç†èŒƒå›´å†…
                            max_price = df_display['high'].max()
                            if target_price <= max_price * 1.5:  # ä¸è¶…è¿‡å†å²æœ€é«˜ä»·çš„1.5å€
                                # ç»˜åˆ¶ç²‰çº¢è‰²è™šçº¿ï¼ˆåŠ ç²—ï¼‰
                                ax.axhline(y=target_price, color='hotpink', linestyle='--', linewidth=3, alpha=0.8)
                                
                                # æ ‡æ³¨ç™¾åˆ†æ¯”ï¼ˆæ£•ç°è‰²å­—ä½“ï¼Œæ˜¾ç¤ºåœ¨å³è¾¹ï¼‰
                                ax.text(dates.iloc[-1], target_price, f'+{percent_str}', 
                                       fontsize=12, color='#8B7355', fontweight='bold',
                                       bbox=dict(boxstyle="round,pad=0.3", facecolor='white', alpha=0.9, edgecolor='#8B7355', linewidth=2),
                                       ha='left', va='center')
                        except (ValueError, TypeError):
                            continue
                
                # 4. è®¾ç½®å›¾è¡¨å±æ€§
                # è·å–è¡Œä¸šä¿¡æ¯
                industry = ""
                if stock_code in self.stock_info:
                    industry = self.stock_info[stock_code].get('industry', '')
                
                # æ„å»ºæ ‡é¢˜
                title_parts = [stock_code, stock_name]
                if industry and industry != "æœªçŸ¥è¡Œä¸š":
                    title_parts.append(f"({industry})")
                title = " ".join(title_parts) + " - Stage Low Points Analysis"
                
                ax.set_title(title, fontsize=16, fontweight='bold', pad=20)
                ax.set_xlabel('Date', fontsize=12)
                ax.set_ylabel('Price', fontsize=12)
                
                # è®¾ç½®Yè½´èŒƒå›´ï¼ŒåŸºäºæ˜¾ç¤ºçš„æ•°æ®
                if not df_display.empty:
                    y_min = df_display['low'].min() * 0.95
                    y_max = df_display['high'].max() * 1.1
                    ax.set_ylim(y_min, y_max)
                
                # è®¾ç½®æ—¥æœŸæ ¼å¼
                ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))
                ax.xaxis.set_major_locator(mdates.MonthLocator(interval=3))
                plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)
                
                # ç½‘æ ¼
                ax.grid(True, alpha=0.3)
                
                # è‡ªåŠ¨è°ƒæ•´å¸ƒå±€
                plt.tight_layout()
                
                # ä¿å­˜å›¾è¡¨
                plt.savefig(output_file, dpi=200, bbox_inches='tight', 
                           facecolor='white', edgecolor='none')
                
                # éªŒè¯è¾“å‡ºæ–‡ä»¶
                if os.path.exists(output_file):
                    file_size = os.path.getsize(output_file)
                    if file_size > 50000:  # è‡³å°‘50KB
                        logger.debug(f"âœ… å›¾è¡¨åˆ›å»ºæˆåŠŸ: {output_file} ({file_size} bytes)")
                        return True
                    else:
                        logger.warning(f"âš ï¸ ç”Ÿæˆçš„å›¾ç‰‡æ–‡ä»¶è¿‡å°: {output_file} ({file_size} bytes)")
                        return False
                else:
                    logger.error(f"âŒ å›¾è¡¨æ–‡ä»¶æœªç”Ÿæˆ: {output_file}")
                    return False
                    
        except Exception as e:
            logger.error(f"âŒ å›¾è¡¨åˆ›å»ºå¤±è´¥ {stock_code}: {type(e).__name__}: {e}")
            import traceback
            logger.debug(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            return False
        finally:
            # ç¡®ä¿é‡Šæ”¾matplotlibèµ„æº
            try:
                if fig is not None:
                    plt.close(fig)
                plt.close('all')  # å…³é—­æ‰€æœ‰å›¾å½¢
            except Exception as cleanup_error:
                logger.debug(f"èµ„æºæ¸…ç†å¼‚å¸¸: {cleanup_error}")
                pass
    
    def process_stock_list(self, stock_list: List[Tuple[str, str, str]], 
                          output_dir: str = None, data_dir: str = "../data", workers: int = 4):
        """å¤„ç†æŒ‡å®šçš„è‚¡ç¥¨åˆ—è¡¨"""
        # å¦‚æœæœªæŒ‡å®šè¾“å‡ºç›®å½•ï¼Œä½¿ç”¨å¸¦æ—¥æœŸçš„é»˜è®¤ç›®å½•
        if output_dir is None:
            current_date = datetime.now().strftime('%Y%m%d')
            output_dir = f'{current_date}-drawLineRes'
        
        logger.info(f"ğŸš€ å¼€å§‹å¤„ç†æŒ‡å®šè‚¡ç¥¨åˆ—è¡¨")
        logger.info(f"ğŸ“ æ•°æ®ç›®å½•: {data_dir}")
        logger.info(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        logger.info(f"ğŸ§µ çº¿ç¨‹æ•°: {workers}")
        
        if not stock_list:
            logger.error("âŒ è‚¡ç¥¨åˆ—è¡¨ä¸ºç©º")
            return
        
        self.total_count = len(stock_list)
        self.processed_count = 0
        
        logger.info(f"ğŸ“Š å¾…å¤„ç†è‚¡ç¥¨æ•°é‡: {self.total_count}")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        
        # å¤šçº¿ç¨‹å¤„ç†
        start_time = time.time()
        results = []
        
        with ThreadPoolExecutor(max_workers=workers) as executor:
            # æäº¤ä»»åŠ¡
            future_to_stock = {
                executor.submit(self._process_single_stock, code, name, output_dir, data_dir): (code, name, industry)
                for code, name, industry in stock_list
            }
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_stock):
                result = future.result()
                results.append(result)
        
        # ç»Ÿè®¡ç»“æœ
        total_time = time.time() - start_time
        success_count = sum(1 for r in results if r['success'])
        failed_count = len(results) - success_count
        
        logger.info(f"ğŸ‰ è‚¡ç¥¨åˆ—è¡¨å¤„ç†å®Œæˆ!")
        logger.info(f"ğŸ“Š æ€»è®¡: {len(results)}åªè‚¡ç¥¨")
        logger.info(f"âœ… æˆåŠŸ: {success_count}åª")
        logger.info(f"âŒ å¤±è´¥: {failed_count}åª")
        logger.info(f"â±ï¸ æ€»è€—æ—¶: {total_time:.2f}ç§’")
        logger.info(f"âš¡ å¹³å‡é€Ÿåº¦: {len(results)/total_time:.2f}åª/ç§’")
        
        # ä¿å­˜å¤„ç†ç»“æœ
        results_file = os.path.join(output_dir, "processing_results.json")
        try:
            with open(results_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            logger.info(f"ğŸ“„ å¤„ç†ç»“æœå·²ä¿å­˜: {results_file}")
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")
        
        # æ˜¾ç¤ºå¤±è´¥çš„è‚¡ç¥¨
        failed_stocks = [r for r in results if not r['success']]
        if failed_stocks:
            logger.warning(f"âš ï¸ å¤±è´¥çš„è‚¡ç¥¨:")
            for r in failed_stocks[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                logger.warning(f"   {r['stock_code']} {r['stock_name']}: {r['error']}")
            if len(failed_stocks) > 10:
                logger.warning(f"   ... è¿˜æœ‰{len(failed_stocks)-10}åªè‚¡ç¥¨å¤±è´¥")

    def _process_single_stock(self, stock_code: str, stock_name: str, 
                           output_dir: str, data_dir: str) -> dict:
        """å¤„ç†å•åªè‚¡ç¥¨ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰"""
        start_time = time.time()
        result = {
            'stock_code': stock_code,
            'stock_name': stock_name,
            'success': False,
            'elapsed_time': 0,
            'error': None,
            'stage_lows_count': 0
        }
        
        try:
            # 1. éªŒè¯å¹¶åŠ è½½æ•°æ®
            df = self.validate_and_load_data(stock_code, data_dir)
            if df is None:
                result['error'] = "æ•°æ®åŠ è½½å¤±è´¥"
                return result
            
            # 2. æ£€æµ‹é˜¶æ®µä½ç‚¹
            stage_lows = self.find_stage_lows_unified(df)
            if not stage_lows:
                result['error'] = "æœªæ£€æµ‹åˆ°é˜¶æ®µä½ç‚¹"
                return result
            
            result['stage_lows_count'] = len(stage_lows)
            
            # 3. åˆ›å»ºè¾“å‡ºç›®å½•
            os.makedirs(output_dir, exist_ok=True)
            
            # 4. ç”Ÿæˆå›¾è¡¨
            output_file = os.path.join(output_dir, f"{stock_code}_{stock_name}.png")
            success = self.create_unified_chart(stock_code, stock_name, df, stage_lows, output_file)
            
            if success:
                result['success'] = True
                
                # æ›´æ–°è¿›åº¦
                with progress_lock:
                    self.processed_count += 1
                    logger.info(f"âœ… [{self.processed_count}/{self.total_count}] {stock_code} {stock_name} - {len(stage_lows)}ä¸ªä½ç‚¹")
            else:
                result['error'] = "å›¾è¡¨åˆ›å»ºå¤±è´¥"
            
        except Exception as e:
            result['error'] = str(e)
            logger.error(f"âŒ å¤„ç†è‚¡ç¥¨å¤±è´¥ {stock_code}: {e}")
        
        finally:
            result['elapsed_time'] = time.time() - start_time
        
        return result


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="åŸºç¡€å±‚ç”»çº¿è„šæœ¬ - è¯»å–resByFilterä¸­çš„è‚¡ç¥¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # é»˜è®¤è¡Œä¸ºï¼šè¯»å–å½“å‰æ—¥æœŸçš„resByFilterä¸­çš„è‚¡ç¥¨
  python draw_lines_unified.py
  
  # è¯»å–æŒ‡å®šæ—¥æœŸçš„resByFilterä¸­çš„è‚¡ç¥¨
  python draw_lines_unified.py --date 2025-01-15
  
  # æŒ‡å®šçº¿ç¨‹æ•°
  python draw_lines_unified.py --workers 6
        """
    )
    
    # ç”Ÿæˆå¸¦æ—¥æœŸçš„é»˜è®¤è¾“å‡ºç›®å½•
    current_date = datetime.now().strftime('%Y%m%d')
    
    # å‚æ•°
    parser.add_argument('--date', type=str, 
                       help='æ—¥æœŸå‚æ•°ï¼Œæ ¼å¼ä¸ºYYYY-MM-DDï¼Œç”¨äºæ„å»ºresByFilterç›®å½•')
    parser.add_argument('--workers', type=int, default=4,
                       help='å¹¶å‘å¤„ç†çš„çº¿ç¨‹æ•° (é»˜è®¤: 4)')
    
    args = parser.parse_args()
    
    # å¤„ç†æ—¥æœŸå‚æ•°
    if args.date:
        try:
            # éªŒè¯æ—¥æœŸæ ¼å¼å¹¶è½¬æ¢
            date_obj = datetime.strptime(args.date, '%Y-%m-%d')
            date_str = date_obj.strftime('%Y%m%d')
        except ValueError:
            logger.error(f"âŒ æ—¥æœŸæ ¼å¼é”™è¯¯: {args.date}ï¼Œè¯·ä½¿ç”¨YYYY-MM-DDæ ¼å¼")
            sys.exit(1)
    else:
        date_str = current_date
    
    # åˆ›å»ºç»Ÿä¸€ç”»çº¿å™¨
    drawer = UnifiedLineDrawer()
    
    # è¯»å–æŒ‡å®šæ—¥æœŸçš„resByFilterä¸­çš„è‚¡ç¥¨
    filter_dir = f"../{date_str}-resByFilter"
    if not os.path.exists(filter_dir):
        logger.error(f"âŒ ç›®å½•ä¸å­˜åœ¨: {filter_dir}")
        logger.info(f"ğŸ’¡ æç¤ºï¼šè¯·ç¡®ä¿å­˜åœ¨ {filter_dir} ç›®å½•")
        sys.exit(1)
    
    # æŸ¥æ‰¾æ‰€æœ‰CSVæ–‡ä»¶ï¼ˆPDIå’ŒADXç»“æœæ–‡ä»¶ï¼‰
    csv_files = glob.glob(os.path.join(filter_dir, "*.csv"))
    if not csv_files:
        logger.error(f"âŒ åœ¨ç›®å½• {filter_dir} ä¸­æœªæ‰¾åˆ°CSVæ–‡ä»¶")
        logger.info(f"ğŸ’¡ æç¤ºï¼šè¯·åœ¨ {filter_dir} ç›®å½•ä¸­æ”¾ç½®è‚¡ç¥¨åˆ—è¡¨CSVæ–‡ä»¶")
        sys.exit(1)
    
    logger.info(f"ğŸ“ æ‰¾åˆ° {len(csv_files)} ä¸ªCSVæ–‡ä»¶")
    
    # è¯»å–æ‰€æœ‰CSVæ–‡ä»¶ä¸­çš„è‚¡ç¥¨ï¼Œå¹¶å»é‡
    all_stocks = {}  # ä½¿ç”¨å­—å…¸å»é‡ï¼Œkeyä¸ºè‚¡ç¥¨ä»£ç 
    
    for file_path in csv_files:
        logger.info(f"ğŸ“„ è¯»å–æ–‡ä»¶: {file_path}")
        try:
            import pandas as pd
            df = pd.read_csv(file_path)
            
            # ä»CSVæ–‡ä»¶ä¸­æå–è‚¡ç¥¨ä¿¡æ¯
            for _, row in df.iterrows():
                code = str(row.get('code', ''))
                name = str(row.get('name', code))
                industry = str(row.get('industry', 'æœªçŸ¥è¡Œä¸š'))
                
                # æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç ï¼ˆè¡¥é›¶åˆ°6ä½ï¼‰
                if code:
                    normalized_code = code.zfill(6)
                    if normalized_code not in all_stocks:
                        all_stocks[normalized_code] = (normalized_code, name, industry)
                        
        except Exception as e:
            logger.error(f"âŒ è¯»å–æ–‡ä»¶ {file_path} å¤±è´¥: {e}")
            continue
    
    if not all_stocks:
        logger.error(f"âŒ æœªè¯»å–åˆ°æœ‰æ•ˆçš„è‚¡ç¥¨æ•°æ®")
        sys.exit(1)
    
    # è½¬æ¢ä¸ºåˆ—è¡¨
    stock_list = list(all_stocks.values())
    logger.info(f"ğŸ“‹ å»é‡åå…±æœ‰ {len(stock_list)} åªè‚¡ç¥¨")
    
    # ç”Ÿæˆè¾“å‡ºç›®å½•
    output_dir = f"{date_str}-drawLineRes"
    
    # æ‰¹é‡å¤„ç†è‚¡ç¥¨åˆ—è¡¨
    drawer.process_stock_list(stock_list, output_dir, "../data", args.workers)
    
    logger.info("ğŸ‰ ç¨‹åºæ‰§è¡Œå®Œæˆ!")


if __name__ == "__main__":
    main()