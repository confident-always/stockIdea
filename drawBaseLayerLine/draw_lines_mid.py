#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç»Ÿä¸€ç‰ˆåŸºç¡€å±‚ç”»çº¿è„šæœ¬
æ•´åˆæ‰€æœ‰drawBaseLayerLineåŠŸèƒ½ä¸ºå•ä¸€å¯æ‰§è¡Œè„šæœ¬

åŠŸèƒ½ç‰¹æ€§ï¼š
1. ä»resByFilterä¸­æå–æ‰€æœ‰è‚¡ç¥¨æ•°æ®
2. æ™ºèƒ½æ•°æ®éªŒè¯å’Œæ¸…æ´—
3. å¤šç®—æ³•é˜¶æ®µä½ç‚¹æ£€æµ‹ï¼ˆå…¨å±€æœ€ä½ç‚¹ã€æ»‘åŠ¨çª—å£ã€ä»·æ ¼åˆ†ä½æ•°ã€æŠ€æœ¯æŒ‡æ ‡ï¼‰
4. é«˜è´¨é‡å›¾è¡¨ç»˜åˆ¶ï¼ˆKçº¿å›¾ã€é˜¶æ®µä½ç‚¹çº¿ã€ç™¾åˆ†æ¯”æ¶¨å¹…çº¿ï¼‰
5. å¤šçº¿ç¨‹æ‰¹é‡å¤„ç†
6. å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•
7. å‘½ä»¤è¡Œå‚æ•°æ”¯æŒ

ä½¿ç”¨æ–¹æ³•ï¼š
    # å¤„ç†å•åªè‚¡ç¥¨
    python draw_lines_unified.py --stock 002895
    
    # æ‰¹é‡å¤„ç†æ‰€æœ‰è‚¡ç¥¨
    python draw_lines_unified.py --all
    
    # æŒ‡å®šè¾“å‡ºç›®å½•å’Œçº¿ç¨‹æ•°
    python draw_lines_unified.py --all --output drawLineRes --workers 4
    
    # ä»æŒ‡å®šæ•°æ®ç›®å½•è¯»å–
    python draw_lines_unified.py --all --data-dir ../data
"""

import os
import sys
import json
import pandas as pd
import numpy as np
from pathlib import Path
from typing import List, Dict, Tuple, Optional, Union
import logging
from datetime import datetime
import glob
import argparse
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
import time
from scipy.signal import argrelextrema

# è®¾ç½®matplotlibåç«¯å’Œå­—ä½“
import matplotlib
matplotlib.use('Agg')  # éäº¤äº’å¼åç«¯ï¼Œæ”¯æŒå¤šçº¿ç¨‹
import matplotlib.pyplot as plt
import matplotlib.dates as mdates

# å­—ä½“é…ç½® - ä½¿ç”¨macOSç³»ç»Ÿæ”¯æŒçš„ä¸­æ–‡å­—ä½“
plt.rcParams['font.family'] = ['Heiti TC', 'PingFang HK', 'Arial Unicode MS', 'Arial', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] [%(threadName)s] %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('draw_lines_unified.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

# çº¿ç¨‹é”
progress_lock = threading.Lock()
matplotlib_lock = threading.Lock()  # ç”¨äºmatplotlibæ“ä½œçš„çº¿ç¨‹å®‰å…¨


class UnifiedLineDrawer:
    """ç»Ÿä¸€ç‰ˆç”»çº¿å™¨ - æ•´åˆæ‰€æœ‰åŠŸèƒ½"""
    
    def __init__(self, config_file: str = "lineConfig.json"):
        """åˆå§‹åŒ–ç»Ÿä¸€ç”»çº¿å™¨"""
        self.config_file = config_file
        self.percent_list = self._load_config()
        self.stock_info = self._load_stock_info()
        self.processed_count = 0
        self.total_count = 0
        logger.info(f"âœ… ç»Ÿä¸€ç”»çº¿å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"ğŸ“Š åŠ è½½{len(self.percent_list)}ä¸ªç™¾åˆ†æ¯”é…ç½®: {self.percent_list}")
        logger.info(f"ğŸ“ˆ åŠ è½½{len(self.stock_info)}åªè‚¡ç¥¨ä¿¡æ¯")
    
    def _load_config(self) -> List[str]:
        """åŠ è½½é…ç½®æ–‡ä»¶ä¸­çš„ç™¾åˆ†æ¯”æ•°æ®å’ŒZigZagå‚æ•°"""
        try:
            config_path = Path(self.config_file)
            if not config_path.exists():
                # å°è¯•åœ¨ä¸Šçº§ç›®å½•æŸ¥æ‰¾
                config_path = Path("..") / self.config_file
                if not config_path.exists():
                    logger.warning(f"âš ï¸ é…ç½®æ–‡ä»¶ {self.config_file} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
                    default_percents = ["3%", "16%", "25%", "34%", "50%", "67%", "128%", "228%", "247%", "323%", "457%", "589%", "636%", "770%", "823%", "935%"]
                    self.zigzag_period = 20
                    self.zigzag_threshold = 0.05
                    self.anchor_m_config = {
                        'enabled': True,
                        'zigzag_percent': 10,
                        'pivot_window': 3,
                        'm_range': {'start': 13.0, 'end': 9.0, 'step': -0.1},
                        'max_k': 20,
                        'match_tolerance_ratio': 0.006,
                        'min_matches': 3,
                        'tiebreaker_prefer_higher_M': True,
                        'line_style': {'color': '#8A2BE2', 'linewidth': 1.0, 'alpha': 0.85},
                        'text_style': {'fontsize': 8, 'x_offset': 5},
                        'annotate_format': 'K={K} ä»·æ ¼={price}',
                        'anchor_fallback_window_days': 60
                    }
                    return default_percents
            
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
                percent_dic = config.get('percent_dic', [])
                self.zigzag_period = config.get('zigzag_period', 20)
                self.zigzag_threshold = config.get('zigzag_threshold', 0.05)
                
                # åŠ è½½ anchorMLines é…ç½®
                self.anchor_m_config = config.get('anchorMLines', {})
                if not self.anchor_m_config:
                    # é»˜è®¤é…ç½®
                    self.anchor_m_config = {
                        'enabled': True,
                        'zigzag_percent': 10,
                        'pivot_window': 3,
                        'm_range': {'start': 13.0, 'end': 9.0, 'step': -0.1},
                        'max_k': 20,
                        'match_tolerance_ratio': 0.006,
                        'min_matches': 3,
                        'tiebreaker_prefer_higher_M': True,
                        'line_style': {'color': '#8A2BE2', 'linewidth': 1.0, 'alpha': 0.85},
                        'text_style': {'fontsize': 8, 'x_offset': 5},
                        'annotate_format': 'K={K} ä»·æ ¼={price}',
                        'anchor_fallback_window_days': 60
                    }
                
                logger.info(f"âœ… æˆåŠŸåŠ è½½é…ç½®æ–‡ä»¶: {config_path}")
                logger.info(f"ğŸ”§ ZigZagå‘¨æœŸ: {self.zigzag_period}, é˜ˆå€¼: {self.zigzag_threshold}")
                logger.info(f"ğŸ”§ AnchorMLinesåŠŸèƒ½: {'å¯ç”¨' if self.anchor_m_config.get('enabled', True) else 'ç¦ç”¨'}")
                return percent_dic
        except Exception as e:
            logger.error(f"âŒ åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            # ä½¿ç”¨é»˜è®¤é…ç½®
            default_percents = ["3%", "16%", "25%", "34%", "50%", "67%", "128%", "228%", "247%", "323%", "457%", "589%", "636%", "770%", "823%", "935%"]
            self.zigzag_period = 20
            self.zigzag_threshold = 0.05
            self.anchor_m_config = {
                'enabled': True,
                'zigzag_percent': 10,
                'pivot_window': 3,
                'm_range': {'start': 13.0, 'end': 9.0, 'step': -0.1},
                'max_k': 20,
                'match_tolerance_ratio': 0.006,
                'min_matches': 3,
                'tiebreaker_prefer_higher_M': True,
                'line_style': {'color': '#8A2BE2', 'linewidth': 1.0, 'alpha': 0.85},
                'text_style': {'fontsize': 8, 'x_offset': 5},
                'annotate_format': 'K={K} ä»·æ ¼={price}',
                'anchor_fallback_window_days': 60
            }
            logger.info(f"ä½¿ç”¨é»˜è®¤é…ç½®")
            return default_percents
    
    def _load_stock_info(self) -> Dict[str, Dict[str, str]]:
        """ä»stocklist.csvåŠ è½½è‚¡ç¥¨ä¿¡æ¯ï¼ˆåç§°å’Œè¡Œä¸šï¼‰"""
        stock_info = {}
        try:
            # å°è¯•å¤šä¸ªå¯èƒ½çš„stocklist.csvè·¯å¾„
            possible_paths = ["../stocklist.csv", "stocklist.csv", "./stocklist.csv"]
            stocklist_file = None
            
            for path in possible_paths:
                if os.path.exists(path):
                    stocklist_file = path
                    break
            
            if stocklist_file:
                # ä»stocklist.csvåŠ è½½è‚¡ç¥¨ä¿¡æ¯
                try:
                    df = pd.read_csv(stocklist_file)
                    logger.info(f"ğŸ“ ä»{stocklist_file}åŠ è½½è‚¡ç¥¨ä¿¡æ¯")
                    
                    if 'symbol' in df.columns and 'name' in df.columns and 'industry' in df.columns:
                        for _, row in df.iterrows():
                            code = str(row['symbol']).zfill(6)
                            name = str(row['name'])
                            industry = str(row['industry']) if pd.notna(row['industry']) else "æœªçŸ¥è¡Œä¸š"
                            stock_info[code] = {'name': name, 'industry': industry}
                        
                        logger.info(f"âœ… ä»stocklist.csvåŠ è½½è‚¡ç¥¨ä¿¡æ¯å®Œæˆï¼Œå…±{len(stock_info)}åªè‚¡ç¥¨")
                        return stock_info
                    else:
                        logger.warning(f"âš ï¸ stocklist.csvç¼ºå°‘å¿…è¦å­—æ®µ: symbol, name, industry")
                except Exception as e:
                    logger.warning(f"âš ï¸ è¯»å–stocklist.csvå¤±è´¥: {e}")
            
            # å¦‚æœstocklist.csvä¸å¯ç”¨ï¼Œå›é€€åˆ°ä»resByFilterç›®å½•åŠ è½½
            logger.info("ğŸ“ stocklist.csvä¸å¯ç”¨ï¼Œå›é€€åˆ°ä»resByFilterç›®å½•åŠ è½½è‚¡ç¥¨ä¿¡æ¯")
            possible_paths = ["../resByFilter", "resByFilter", "./resByFilter"]
            res_dir = None
            
            for path in possible_paths:
                if os.path.exists(path):
                    res_dir = path
                    break
            
            if not res_dir:
                logger.warning(f"âš ï¸ æœªæ‰¾åˆ°resByFilterç›®å½•ï¼Œå°è¯•çš„è·¯å¾„: {possible_paths}")
                return stock_info
            
            csv_files = glob.glob(os.path.join(res_dir, "*.csv"))
            logger.info(f"ğŸ“ åœ¨{res_dir}ä¸­æ‰¾åˆ°{len(csv_files)}ä¸ªCSVæ–‡ä»¶")
            
            for csv_file in csv_files:
                try:
                    df = pd.read_csv(csv_file)
                    if 'code' in df.columns and 'name' in df.columns:
                        for _, row in df.iterrows():
                            code = str(row['code']).zfill(6)
                            name = str(row['name'])
                            stock_info[code] = {'name': name, 'industry': "æœªçŸ¥è¡Œä¸š"}
                except Exception as e:
                    logger.warning(f"âš ï¸ è¯»å–æ–‡ä»¶å¤±è´¥ {csv_file}: {e}")
            
            logger.info(f"âœ… åŠ è½½è‚¡ç¥¨ä¿¡æ¯å®Œæˆï¼Œå…±{len(stock_info)}åªè‚¡ç¥¨")
            return stock_info
            
        except Exception as e:
            logger.error(f"âŒ åŠ è½½è‚¡ç¥¨ä¿¡æ¯å¤±è´¥: {e}")
            return stock_info
    
    def get_stock_list(self, data_dir: str = "../data") -> List[Tuple[str, str, str]]:
        """è·å–è‚¡ç¥¨åˆ—è¡¨ï¼Œè¿”å›(code, name, industry)"""
        stock_list = []
        
        # å¦‚æœæœ‰è‚¡ç¥¨ä¿¡æ¯ï¼Œä¼˜å…ˆä½¿ç”¨
        if self.stock_info:
            for code, info in self.stock_info.items():
                name = info.get('name', code)
                industry = info.get('industry', 'æœªçŸ¥è¡Œä¸š')
                stock_list.append((code, name, industry))
            logger.info(f"ğŸ“‹ ä»è‚¡ç¥¨ä¿¡æ¯è·å–è‚¡ç¥¨åˆ—è¡¨: {len(stock_list)}åª")
            return stock_list
        
        # å¦åˆ™ä»æ•°æ®ç›®å½•è·å–
        try:
            data_path = Path(data_dir)
            if not data_path.exists():
                logger.error(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
                return stock_list
            
            csv_files = list(data_path.glob("*.csv"))
            for csv_file in csv_files:
                code = csv_file.stem
                # å°è¯•ä»æ–‡ä»¶åæ¨æ–­è‚¡ç¥¨åç§°ï¼Œæˆ–ä½¿ç”¨ä»£ç ä½œä¸ºåç§°
                name = code
                industry = "æœªçŸ¥è¡Œä¸š"
                stock_list.append((code, name, industry))
            
            logger.info(f"ğŸ“‹ ä»æ•°æ®ç›®å½•è·å–è‚¡ç¥¨åˆ—è¡¨: {len(stock_list)}åª")
            return stock_list
            
        except Exception as e:
            logger.error(f"âŒ è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
            return stock_list
    
    def validate_and_load_data(self, stock_code: str, data_dir: str) -> Optional[pd.DataFrame]:
        """éªŒè¯å¹¶åŠ è½½è‚¡ç¥¨æ•°æ®"""
        try:
            # æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç ï¼ˆè¡¥é›¶åˆ°6ä½ï¼‰
            normalized_code = str(stock_code).zfill(6)
            
            # æ„å»ºæ–‡ä»¶è·¯å¾„
            data_path = Path(data_dir)
            csv_file = data_path / f"{normalized_code}.csv"
            
            if not csv_file.exists():
                logger.warning(f"âš ï¸ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {csv_file}")
                return None
            
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            file_size = csv_file.stat().st_size
            if file_size < 1000:  # å°äº1KBçš„æ–‡ä»¶å¯èƒ½æœ‰é—®é¢˜
                logger.warning(f"âš ï¸ æ•°æ®æ–‡ä»¶è¿‡å°: {csv_file} ({file_size} bytes)")
                return None
            
            # è¯»å–æ•°æ®
            df = pd.read_csv(csv_file)
            
            # éªŒè¯å¿…è¦åˆ—
            required_columns = ['date', 'open', 'high', 'low', 'close']
            missing_columns = [col for col in required_columns if col not in df.columns]
            if missing_columns:
                logger.warning(f"âš ï¸ ç¼ºå°‘å¿…è¦åˆ— {missing_columns}: {stock_code}")
                return None
            
            # æ£€æŸ¥æ•°æ®è¡Œæ•°
            if len(df) < 100:  # è‡³å°‘éœ€è¦100å¤©çš„æ•°æ®
                logger.warning(f"âš ï¸ æ•°æ®è¡Œæ•°ä¸è¶³: {stock_code} ({len(df)} rows)")
                return None
            
            # æ•°æ®æ¸…æ´—
            df = df.dropna(subset=required_columns)
            
            # è½¬æ¢æ—¥æœŸæ ¼å¼
            df['date'] = pd.to_datetime(df['date'])
            df = df.sort_values('date').reset_index(drop=True)
            
            # éªŒè¯ä»·æ ¼æ•°æ®åˆç†æ€§
            price_columns = ['open', 'high', 'low', 'close']
            for col in price_columns:
                if (df[col] <= 0).any():
                    logger.warning(f"âš ï¸ å‘ç°éæ­£ä»·æ ¼æ•°æ®: {stock_code}")
                    df = df[df[col] > 0]
            
            # éªŒè¯é«˜ä½ä»·å…³ç³»
            invalid_rows = (df['high'] < df['low']) | (df['high'] < df['open']) | (df['high'] < df['close']) | \
                          (df['low'] > df['open']) | (df['low'] > df['close'])
            if invalid_rows.any():
                logger.warning(f"âš ï¸ å‘ç°ä»·æ ¼é€»è¾‘é”™è¯¯: {stock_code}")
                df = df[~invalid_rows]
            
            if len(df) < 50:  # æ¸…æ´—åæ•°æ®å¤ªå°‘
                logger.warning(f"âš ï¸ æ¸…æ´—åæ•°æ®ä¸è¶³: {stock_code} ({len(df)} rows)")
                return None
            
            logger.debug(f"âœ… æ•°æ®éªŒè¯é€šè¿‡: {stock_code} ({len(df)} rows)")
            return df
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åŠ è½½å¤±è´¥ {stock_code}: {e}")
            return None
    
    def zigzag(self, high_prices: np.ndarray, low_prices: np.ndarray, 
               threshold_pct: float = 0.49) -> List[Tuple[int, float, str]]:
        """
        å®ç°ZigZagæŒ‡æ ‡ç®—æ³•ï¼Œæ‰¾åˆ°æ˜¾è‘—çš„è½¬æŠ˜ç‚¹
        
        ZigZagç®—æ³•åŸç†ï¼š
        - åªæœ‰å½“ä»·æ ¼å˜åŒ–è¶…è¿‡è®¾å®šé˜ˆå€¼æ—¶æ‰ç¡®è®¤è½¬æŠ˜ç‚¹
        - è¿‡æ»¤æ‰å°å¹…æ³¢åŠ¨ï¼Œä¿ç•™ä¸»è¦è¶‹åŠ¿
        - threshold_pct: 49% è¡¨ç¤ºä»·æ ¼å˜åŒ–éœ€è¶…è¿‡49%æ‰ç¡®è®¤è½¬æŠ˜
        
        Args:
            high_prices: æœ€é«˜ä»·æ•°ç»„
            low_prices: æœ€ä½ä»·æ•°ç»„
            threshold_pct: è½¬æŠ˜é˜ˆå€¼ï¼ˆç™¾åˆ†æ¯”ï¼Œå¦‚0.49è¡¨ç¤º49%ï¼‰
        
        Returns:
            è½¬æŠ˜ç‚¹åˆ—è¡¨ [(ç´¢å¼•, ä»·æ ¼, ç±»å‹)]ï¼Œç±»å‹ä¸º'high'æˆ–'low'
        """
        if len(high_prices) < 3:
            return []
        
        pivots = []  # å­˜å‚¨è½¬æŠ˜ç‚¹
        
        # ä»ç¬¬ä¸€ä¸ªç‚¹å¼€å§‹
        last_pivot_idx = 0
        last_pivot_price = low_prices[0]
        last_pivot_type = 'low'  # å‡è®¾ä»ä½ç‚¹å¼€å§‹
        
        # åˆå§‹åŒ–ï¼šæ‰¾åˆ°çœŸæ­£çš„ç¬¬ä¸€ä¸ªè½¬æŠ˜ç‚¹
        # å…ˆæ‰¾ç¬¬ä¸€ä¸ªé«˜ç‚¹
        searching_for = 'high'
        
        for i in range(1, len(high_prices)):
            if searching_for == 'high':
                # å¯»æ‰¾é«˜ç‚¹
                current_high = high_prices[i]
                # è®¡ç®—ä»æœ€åä¸€ä¸ªä½ç‚¹åˆ°å½“å‰çš„æ¶¨å¹…
                if last_pivot_type == 'low':
                    pct_change = (current_high - last_pivot_price) / last_pivot_price
                    if pct_change >= threshold_pct:
                        # æ‰¾åˆ°ä¸€ä¸ªæ˜¾è‘—çš„é«˜ç‚¹
                        pivots.append((last_pivot_idx, last_pivot_price, 'low'))
                        last_pivot_idx = i
                        last_pivot_price = current_high
                        last_pivot_type = 'high'
                        searching_for = 'low'
                else:
                        # æ›´æ–°æ½œåœ¨çš„èµ·ç‚¹ï¼ˆå¦‚æœæ‰¾åˆ°æ›´ä½çš„ä½ç‚¹ï¼‰
                        if low_prices[i] < last_pivot_price:
                            last_pivot_idx = i
                            last_pivot_price = low_prices[i]
                            
            else:  # searching_for == 'low'
                # å¯»æ‰¾ä½ç‚¹
                current_low = low_prices[i]
                # è®¡ç®—ä»æœ€åä¸€ä¸ªé«˜ç‚¹åˆ°å½“å‰çš„è·Œå¹…
                if last_pivot_type == 'high':
                    pct_change = (last_pivot_price - current_low) / last_pivot_price
                    if pct_change >= threshold_pct:
                        # æ‰¾åˆ°ä¸€ä¸ªæ˜¾è‘—çš„ä½ç‚¹
                        pivots.append((last_pivot_idx, last_pivot_price, 'high'))
                        last_pivot_idx = i
                        last_pivot_price = current_low
                        last_pivot_type = 'low'
                        searching_for = 'high'
                    else:
                        # æ›´æ–°æ½œåœ¨çš„é«˜ç‚¹ï¼ˆå¦‚æœæ‰¾åˆ°æ›´é«˜çš„é«˜ç‚¹ï¼‰
                        if high_prices[i] > last_pivot_price:
                            last_pivot_idx = i
                            last_pivot_price = high_prices[i]
        
        # æ·»åŠ æœ€åä¸€ä¸ªè½¬æŠ˜ç‚¹
        if pivots and last_pivot_idx != pivots[-1][0]:
            pivots.append((last_pivot_idx, last_pivot_price, last_pivot_type))
        
        return pivots

    def troughbars(self, data: np.ndarray, period: int, n: int) -> np.ndarray:
        """
        å®ç°é€šè¾¾ä¿¡TROUGHBARSå‡½æ•°
        TROUGHBARS(X,N,M) è¿”å›Nå‘¨æœŸå†…Xçš„ç¬¬Mä¸ªæ³¢è°·åˆ°å½“å‰ä½ç½®çš„å‘¨æœŸæ•°
        
        Args:
            data: ä»·æ ¼æ•°æ®æ•°ç»„ (é€šå¸¸æ˜¯æœ€ä½ä»·)
            period: æŸ¥æ‰¾å‘¨æœŸ N  
            n: ç¬¬å‡ ä¸ªæ³¢è°· M
        
        Returns:
            æ¯ä¸ªä½ç½®åˆ°ç¬¬nä¸ªæ³¢è°·çš„è·ç¦»æ•°ç»„
        """
        result = np.full(len(data), np.nan)
        
        for i in range(len(data)):
            # è·å–å½“å‰ä½ç½®å‰Nä¸ªå‘¨æœŸçš„æ•°æ®ï¼ˆåŒ…å«å½“å‰ä½ç½®ï¼‰
            start_idx = max(0, i - period + 1)
            end_idx = i + 1
            window_data = data[start_idx:end_idx]
            
            if len(window_data) < 3:  # è‡³å°‘éœ€è¦3ä¸ªç‚¹æ‰èƒ½æ‰¾åˆ°æ³¢è°·
                continue
            
            # å¯»æ‰¾æ³¢è°·ï¼ˆå±€éƒ¨æœ€å°å€¼ï¼‰
            troughs = []
            
            # æ£€æŸ¥çª—å£å†…çš„æ¯ä¸ªç‚¹æ˜¯å¦ä¸ºæ³¢è°·
            for j in range(len(window_data)):
                actual_idx = start_idx + j
                
                # è¾¹ç•Œå¤„ç†ï¼šç¬¬ä¸€ä¸ªå’Œæœ€åä¸€ä¸ªç‚¹ä¹Ÿå¯èƒ½æ˜¯æ³¢è°·
                is_trough = False
                
                if j == 0:  # ç¬¬ä¸€ä¸ªç‚¹
                    if len(window_data) > 1 and window_data[j] <= window_data[j+1]:
                        is_trough = True
                elif j == len(window_data) - 1:  # æœ€åä¸€ä¸ªç‚¹ï¼ˆå½“å‰ç‚¹ï¼‰
                    if window_data[j] <= window_data[j-1]:
                        is_trough = True
                else:  # ä¸­é—´ç‚¹
                    if window_data[j] <= window_data[j-1] and window_data[j] <= window_data[j+1]:
                        is_trough = True
                
                if is_trough:
                    troughs.append((actual_idx, window_data[j]))
            
            # æŒ‰ä»·æ ¼æ’åºï¼Œæ‰¾åˆ°ç¬¬nä¸ªæœ€ä½çš„æ³¢è°·
            if len(troughs) >= n:
                troughs.sort(key=lambda x: x[1])  # æŒ‰ä»·æ ¼ä»ä½åˆ°é«˜æ’åº
                nth_trough_idx = troughs[n-1][0]  # ç¬¬nä¸ªæ³¢è°·çš„ç´¢å¼•
                result[i] = i - nth_trough_idx  # è·ç¦»å½“å‰ä½ç½®çš„å‘¨æœŸæ•°
            
        return result

    def barslast(self, condition: np.ndarray) -> np.ndarray:
        """
        å®ç°é€šè¾¾ä¿¡BARSLASTå‡½æ•°
        BARSLAST(X) è¿”å›ä¸Šä¸€æ¬¡Xæ¡ä»¶æˆç«‹åˆ°å½“å‰çš„å‘¨æœŸæ•°
        
        Args:
            condition: å¸ƒå°”æ¡ä»¶æ•°ç»„
        
        Returns:
            è·ç¦»ä¸Šæ¬¡æ¡ä»¶æˆç«‹çš„å‘¨æœŸæ•°æ•°ç»„
        """
        result = np.full(len(condition), np.nan)
        last_true_idx = -1
        
        for i in range(len(condition)):
            if condition[i]:
                last_true_idx = i
                result[i] = 0
            elif last_true_idx >= 0:
                result[i] = i - last_true_idx
        
        return result

    def ref(self, data: np.ndarray, periods: np.ndarray) -> np.ndarray:
        """
        å®ç°é€šè¾¾ä¿¡REFå‡½æ•°
        REF(X,A) å¼•ç”¨Aå‘¨æœŸå‰çš„Xå€¼
        
        Args:
            data: æ•°æ®æ•°ç»„
            periods: å¼•ç”¨å‘¨æœŸæ•°æ•°ç»„
        
        Returns:
            å¼•ç”¨çš„å†å²æ•°æ®æ•°ç»„
        """
        result = np.full(len(data), np.nan)
        
        for i in range(len(data)):
            if not np.isnan(periods[i]):
                ref_idx = int(i - periods[i])
                if 0 <= ref_idx < len(data):
                    result[i] = data[ref_idx]
        
        return result

    # ==================== AnchorM Lines åŠŸèƒ½å‡½æ•° ====================
    
    def compute_zigzag_small(self, highs: np.ndarray, lows: np.ndarray, 
                             threshold_pct: float) -> List[Tuple[int, float, str]]:
        """
        è®¡ç®—å°çº§åˆ«ZigZagè½¬æŠ˜ç‚¹(ç”¨äºMçº¿è¯„åˆ†)
        
        Args:
            highs: æœ€é«˜ä»·æ•°ç»„
            lows: æœ€ä½ä»·æ•°ç»„
            threshold_pct: é˜ˆå€¼ç™¾åˆ†æ¯”(å¦‚0.10è¡¨ç¤º10%)
        
        Returns:
            è½¬æŠ˜ç‚¹åˆ—è¡¨ [(ç´¢å¼•, ä»·æ ¼, ç±»å‹)]
        """
        return self.zigzag(highs, lows, threshold_pct)
    
    def get_local_extremes_around_turns(self, highs: np.ndarray, lows: np.ndarray,
                                       turn_indices: List[int], window: int) -> List[Tuple[float, int]]:
        """
        è·å–ZigZagæ‹ç‚¹é™„è¿‘çš„å±€éƒ¨æå€¼
        
        Args:
            highs: æœ€é«˜ä»·æ•°ç»„
            lows: æœ€ä½ä»·æ•°ç»„
            turn_indices: æ‹ç‚¹ç´¢å¼•åˆ—è¡¨
            window: çª—å£å¤§å°(Â±window)
        
        Returns:
            æå€¼åˆ—è¡¨ [(ä»·æ ¼, ç´¢å¼•)]
        """
        extremes = []
        
        for turn_idx in turn_indices:
            start_idx = max(0, turn_idx - window)
            end_idx = min(len(highs), turn_idx + window + 1)
            
            # è·å–çª—å£å†…çš„æœ€é«˜ä»·å’Œæœ€ä½ä»·
            window_highs = highs[start_idx:end_idx]
            window_lows = lows[start_idx:end_idx]
            
            # å±€éƒ¨æœ€é«˜ä»·
            local_max_idx = start_idx + np.argmax(window_highs)
            local_max_price = highs[local_max_idx]
            extremes.append((local_max_price, local_max_idx))
            
            # å±€éƒ¨æœ€ä½ä»·
            local_min_idx = start_idx + np.argmin(window_lows)
            local_min_price = lows[local_min_idx]
            extremes.append((local_min_price, local_min_idx))
        
        # å»é‡(ç›¸åŒä»·æ ¼å’Œç´¢å¼•)
        extremes = list(set(extremes))
        extremes.sort(key=lambda x: x[0])  # æŒ‰ä»·æ ¼æ’åº
        
        return extremes
    
    def generate_B_series(self, A: float, M: float, max_k: int, 
                          max_price: float) -> Tuple[List[float], List[int]]:
        """
        ç”ŸæˆBåºåˆ—: B_k = A + (A Ã— M) Ã— k
        
        Args:
            A: é”šç‚¹ä½ä»·
            M: Må€¼(ç™¾åˆ†æ¯”,å¦‚0.127è¡¨ç¤º12.7%)
            max_k: æœ€å¤§Kå€¼
            max_price: æœ€é«˜ä»·ä¸Šæ²¿(ç”¨äºåˆ¤æ–­åœæ­¢)
        
        Returns:
            (Bå€¼åˆ—è¡¨, Kå€¼åˆ—è¡¨)
        """
        N = A * M
        B_values = []
        K_values = []
        
        for k in range(1, max_k + 1):
            B_k = A + N * k
            if B_k > max_price * 1.01:  # è¶…è¿‡æœ€é«˜ä»·+1%
                break
            B_values.append(B_k)
            K_values.append(k)
        
        return B_values, K_values
    
    def score_M(self, B_values: List[float], extremes: List[Tuple[float, int]], 
                match_tolerance_ratio: float) -> Dict:
        """
        å¯¹æŸä¸ªMå€¼è¿›è¡Œè¯„åˆ†
        
        Args:
            B_values: Båºåˆ—
            extremes: æå€¼åˆ—è¡¨ [(ä»·æ ¼, ç´¢å¼•)]
            match_tolerance_ratio: åŒ¹é…å®¹å·®æ¯”(å¦‚0.006è¡¨ç¤º0.6%)
        
        Returns:
            {'avg_score': float, 'matches_count': int, 'per_k_matches': List}
        """
        if not B_values or not extremes:
            return {'avg_score': 0, 'matches_count': 0, 'per_k_matches': []}
        
        extreme_prices = [e[0] for e in extremes]
        extreme_prices_sorted = sorted(extreme_prices)
        
        scores = []
        per_k_matches = []
        
        for k_idx, B_k in enumerate(B_values):
            # æ‰¾åˆ°ä¸B_kæœ€æ¥è¿‘çš„ä¸¤ä¸ªæå€¼(ä¸€ä¸Šä¸€ä¸‹)
            upper = None
            lower = None
            
            for e_price in extreme_prices_sorted:
                if e_price >= B_k:
                    upper = e_price
                    break
            
            for e_price in reversed(extreme_prices_sorted):
                if e_price <= B_k:
                    lower = e_price
                    break
            
            # è®¡ç®—å¾—åˆ†
            selected_extremes = []
            if upper is not None:
                selected_extremes.append(upper)
            if lower is not None and lower != upper:
                selected_extremes.append(lower)
            
            if not selected_extremes:
                # å¦‚æœæ²¡æœ‰åŒ¹é…çš„æå€¼,å–æœ€è¿‘çš„ä¸€ä¸ª
                distances = [(abs(e_price - B_k), e_price) for e_price in extreme_prices]
                distances.sort()
                if distances:
                    selected_extremes.append(distances[0][1])
            
            # è®¡ç®—è¯¥B_kçš„å¾—åˆ†
            k_scores = []
            for e_price in selected_extremes:
                r = abs(e_price - B_k) / B_k
                s_e = 100 * max(0, 1 - min(r / match_tolerance_ratio, 1))
                k_scores.append(s_e)
            
            if k_scores:
                avg_k_score = sum(k_scores) / len(k_scores)
                scores.append(avg_k_score)
                per_k_matches.append({
                    'k': k_idx + 1,
                    'B_k': B_k,
                    'matched_extremes': selected_extremes,
                    'score': avg_k_score
                })
        
        avg_score = sum(scores) / len(scores) if scores else 0
        matches_count = len([s for s in scores if s > 0])
        
        return {
            'avg_score': avg_score,
            'matches_count': matches_count,
            'per_k_matches': per_k_matches
        }
    
    def select_best_M(self, M_results: Dict[float, Dict], min_matches: int,
                     prefer_higher_M: bool = True) -> Tuple[Optional[float], Optional[Dict]]:
        """
        ä»æ‰€æœ‰Må€™é€‰ä¸­é€‰æ‹©æœ€ä½³M
        
        Args:
            M_results: {Må€¼: è¯„åˆ†ç»“æœ}å­—å…¸
            min_matches: æœ€å°åŒ¹é…æ•°è¦æ±‚
            prefer_higher_M: å¹¶åˆ—æ—¶ä¼˜å…ˆé€‰æ‹©æ›´å¤§çš„M
        
        Returns:
            (æœ€ä½³Må€¼, æœ€ä½³ç»“æœè¯¦æƒ…)
        """
        # è¿‡æ»¤åŒ¹é…æ•°ä¸è¶³çš„M
        valid_M = {M: result for M, result in M_results.items() 
                   if result['matches_count'] >= min_matches}
        
        if not valid_M:
            return None, None
        
        # æŒ‰å¹³å‡åˆ†æ’åº
        sorted_M = sorted(valid_M.items(), 
                         key=lambda x: (x[1]['avg_score'], 
                                       x[1]['matches_count'],
                                       x[0] if prefer_higher_M else -x[0]),
                         reverse=True)
        
        best_M, best_result = sorted_M[0]
        return best_M, best_result
    
    def compute_anchor_M_lines(self, df: pd.DataFrame, anchor_low: float, 
                              anchor_date: pd.Timestamp) -> Optional[Dict]:
        """
        è®¡ç®—æœ€ä½³Må€¼ä¸Båºåˆ—
        
        Args:
            df: Kçº¿æ•°æ®
            anchor_low: é”šç‚¹ä½ä»·A
            anchor_date: é”šå®šæ—¥æœŸ
        
        Returns:
            æœ€ä½³Mçº¿ç»“æœå­—å…¸,å¤±è´¥è¿”å›None
        """
        try:
            config = self.anchor_m_config
            
            if not config.get('enabled', True):
                return None
            
            # è·å–é”šå®šæ—¥æœŸä¹‹åçš„æ•°æ®
            df_after = df[df['date'] > anchor_date].copy()
            
            if len(df_after) < 10:
                logger.debug(f"âš ï¸ é”šå®šæ—¥æœŸä¹‹åæ•°æ®ä¸è¶³: {len(df_after)}å¤©")
                return None
            
            # è®¡ç®—å°çº§åˆ«ZigZag
            zigzag_percent = config.get('zigzag_percent', 10) / 100.0
            highs_after = df_after['high'].values
            lows_after = df_after['low'].values
            
            turns = self.compute_zigzag_small(highs_after, lows_after, zigzag_percent)
            
            if not turns:
                logger.debug(f"âš ï¸ é”šå®šæ—¥æœŸåæœªæ‰¾åˆ°ZigZagè½¬æŠ˜ç‚¹")
                return None
            
            # è·å–æ‹ç‚¹ç´¢å¼•(ç›¸å¯¹äºdf_after)
            turn_indices = [t[0] for t in turns]
            
            # è·å–å±€éƒ¨æå€¼
            pivot_window = config.get('pivot_window', 3)
            extremes = self.get_local_extremes_around_turns(
                highs_after, lows_after, turn_indices, pivot_window
            )
            
            if not extremes:
                logger.debug(f"âš ï¸ æœªæ‰¾åˆ°å±€éƒ¨æå€¼")
                return None
            
            # éå†Må€¼
            m_range = config.get('m_range', {'start': 13.0, 'end': 9.0, 'step': -0.1})
            M_start = m_range['start']
            M_end = m_range['end']
            M_step = abs(m_range['step'])
            
            M_values = []
            M_current = M_start
            while M_current >= M_end - 0.001:  # æµ®ç‚¹æ•°å®¹å·®
                M_values.append(M_current)
                M_current -= M_step
            
            max_k = config.get('max_k', 20)
            max_price = df_after['high'].max()
            match_tolerance = config.get('match_tolerance_ratio', 0.006)
            
            M_results = {}
            
            for M_pct in M_values:
                M = M_pct / 100.0  # è½¬æ¢ä¸ºå°æ•°
                B_values, K_values = self.generate_B_series(anchor_low, M, max_k, max_price)
                
                if not B_values:
                    continue
                
                score_result = self.score_M(B_values, extremes, match_tolerance)
                M_results[M_pct] = {
                    'B_values': B_values,
                    'K_values': K_values,
                    'avg_score': score_result['avg_score'],
                    'matches_count': score_result['matches_count'],
                    'per_k_matches': score_result['per_k_matches']
                }
            
            # é€‰æ‹©æœ€ä½³M
            min_matches = config.get('min_matches', 3)
            prefer_higher_M = config.get('tiebreaker_prefer_higher_M', True)
            
            best_M, best_result = self.select_best_M(M_results, min_matches, prefer_higher_M)
            
            if best_M is None:
                logger.debug(f"âš ï¸ æœªæ‰¾åˆ°æ»¡è¶³æ¡ä»¶çš„Må€¼(æœ€å°åŒ¹é…æ•°={min_matches})")
                return None
            
            logger.debug(f"âœ… æœ€ä½³M={best_M:.1f}%, å¹³å‡åˆ†={best_result['avg_score']:.2f}, "
                        f"åŒ¹é…æ•°={best_result['matches_count']}")
            
            return {
                'best_M': best_M,
                'B_values': best_result['B_values'],
                'K_values': best_result['K_values'],
                'avg_score': best_result['avg_score'],
                'matches_count': best_result['matches_count'],
                'per_k_matches': best_result['per_k_matches'],
                'anchor_low': anchor_low,
                'anchor_date': anchor_date,
                'extremes': extremes
            }
            
        except Exception as e:
            logger.error(f"âŒ è®¡ç®—AnchorMçº¿å¤±è´¥: {e}")
            import traceback
            logger.debug(traceback.format_exc())
            return None

    def find_stage_lows_unified(self, df: pd.DataFrame) -> List[Tuple[int, float, str]]:
        """
        ç»Ÿä¸€ç‰ˆé˜¶æ®µä½ç‚¹æ£€æµ‹ - ä½¿ç”¨ZigZag(L,49)ç®—æ³•
        å‚æ•°49ä»lineConfig.jsonçš„zigzag_periodè¯»å–ï¼Œè¡¨ç¤º49%çš„ä»·æ ¼å˜åŒ–é˜ˆå€¼
        """
        try:
            # å°†zigzag_periodè½¬æ¢ä¸ºç™¾åˆ†æ¯”é˜ˆå€¼ï¼ˆ49 -> 0.49ï¼‰
            threshold_pct = self.zigzag_period / 100.0
            logger.debug(f"ğŸ” å¼€å§‹ZigZagé˜¶æ®µä½ç‚¹æ£€æµ‹ (é˜ˆå€¼={self.zigzag_period}%)")
            
            # å‡†å¤‡æ•°æ®
            high_prices = df['high'].values
            low_prices = df['low'].values
            dates = df['date'].values
            
            # 1. ä½¿ç”¨ZigZagç®—æ³•æ‰¾åˆ°æ‰€æœ‰è½¬æŠ˜ç‚¹
            pivots = self.zigzag(high_prices, low_prices, threshold_pct)
            
            stage_lows = []
            
            if not pivots:
                logger.warning("âš ï¸ ZigZagæœªæ‰¾åˆ°è½¬æŠ˜ç‚¹ï¼Œä½¿ç”¨å…¨å±€æœ€ä½ç‚¹")
                min_idx = df['low'].idxmin()
                min_price = df.loc[min_idx, 'low']
                min_date = df.loc[min_idx, 'date']
                
                if hasattr(min_date, 'strftime'):
                    min_date_str = min_date.strftime("%Y-%m-%d")
                else:
                    min_date_str = str(min_date)
                
                stage_lows = [(min_idx, min_price, min_date_str)]
            else:
                # 2. ä»ZigZagè½¬æŠ˜ç‚¹ä¸­ç­›é€‰å‡ºä½ç‚¹ï¼ˆ'low'ç±»å‹ï¼‰
                low_pivots = [(idx, price, pivot_type) for idx, price, pivot_type in pivots if pivot_type == 'low']
                
                if not low_pivots:
                    logger.warning("âš ï¸ ZigZagæœªæ‰¾åˆ°ä½ç‚¹è½¬æŠ˜ï¼Œä½¿ç”¨å…¨å±€æœ€ä½ç‚¹")
                    min_idx = df['low'].idxmin()
                    min_price = df.loc[min_idx, 'low']
                    min_date = df.loc[min_idx, 'date']
                else:
                    # 3. ä½¿ç”¨æœ€åä¸€ä¸ªï¼ˆæœ€è¿‘çš„ï¼‰ä½ç‚¹è½¬æŠ˜ä½œä¸ºåˆå§‹é˜¶æ®µä½ç‚¹
                    idx, price, _ = low_pivots[-1]
                    low_date = df.loc[idx, 'date']
                    
                    logger.debug(f"âœ… ZigZagæ‰¾åˆ° {len(low_pivots)} ä¸ªä½ç‚¹è½¬æŠ˜")
                    logger.debug(f"âœ… ZigZagæœ€è¿‘ä½ç‚¹: ç´¢å¼•={idx}, ä»·æ ¼={price:.2f}")
                    
                    # 4. ä¼˜åŒ–ä½ç‚¹é”šå®šï¼šæ£€æŸ¥è¯¥ä½ç‚¹ä¹‹åæ˜¯å¦æœ‰æ›´ä½çš„ä»·æ ¼
                    # åœ¨è¯¥ä½ç‚¹ä¹‹åçš„æ‰€æœ‰äº¤æ˜“æ—¥ä¸­æŸ¥æ‰¾æ›´ä½çš„ä»·æ ¼
                    if idx < len(df) - 1:  # å¦‚æœä¸æ˜¯æœ€åä¸€ä¸ªäº¤æ˜“æ—¥
                        after_low_df = df.iloc[idx+1:]  # è·å–è¯¥ä½ç‚¹ä¹‹åçš„æ•°æ®
                        
                        # æŸ¥æ‰¾ä¹‹åçš„æœ€ä½ä»·
                        after_min_idx = after_low_df['low'].idxmin()
                        after_min_price = after_low_df.loc[after_min_idx, 'low']
                        
                        # å¦‚æœä¹‹åæœ‰æ›´ä½çš„ä»·æ ¼ï¼Œä½¿ç”¨è¯¥æ›´ä½ä»·æ ¼
                        if after_min_price < price:
                            logger.debug(f"ğŸ”½ å‘ç°æ›´ä½ä»·æ ¼: åŸä»·æ ¼={price:.2f}, æ–°ä»·æ ¼={after_min_price:.2f}")
                            idx = after_min_idx
                            price = after_min_price
                            low_date = df.loc[after_min_idx, 'date']
                            logger.debug(f"âœ… æ›´æ–°é”šå®šä½ç‚¹: ç´¢å¼•={idx}, æ—¥æœŸ={low_date}, ä»·æ ¼={price:.2f}")
                    
                    min_idx = idx
                    min_price = price
                    min_date = low_date
                
                # æ ¼å¼åŒ–æ—¥æœŸ
                if hasattr(min_date, 'strftime'):
                    min_date_str = min_date.strftime("%Y-%m-%d")
                else:
                    min_date_str = str(min_date)
                
                stage_lows = [(min_idx, min_price, min_date_str)]
            
            logger.debug(f"âœ… æœ€ç»ˆé˜¶æ®µä½ç‚¹: ç´¢å¼•={stage_lows[0][0]}, æ—¥æœŸ={stage_lows[0][2]}, ä»·æ ¼={stage_lows[0][1]:.2f}")
            return stage_lows
            
        except Exception as e:
            logger.error(f"âŒ ZigZagé˜¶æ®µä½ç‚¹æ£€æµ‹å¤±è´¥: {e}")
            import traceback
            logger.debug(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            
            # å¤‡é€‰æ–¹æ¡ˆï¼šè¿”å›å…¨å±€æœ€ä½ç‚¹
            try:
                global_min_idx = df['low'].idxmin()
                global_min_price = df.loc[global_min_idx, 'low']
                global_min_date = df.loc[global_min_idx, 'date']
                
                if hasattr(global_min_date, 'strftime'):
                    global_min_date_str = global_min_date.strftime('%Y-%m-%d')
                else:
                    global_min_date_str = str(global_min_date)
                
                return [(global_min_idx, global_min_price, global_min_date_str)]
            except Exception as backup_e:
                logger.error(f"âŒ å¤‡é€‰æ–¹æ¡ˆä¹Ÿå¤±è´¥: {backup_e}")
                return []
    
    def create_unified_chart(self, stock_code: str, stock_name: str, df: pd.DataFrame, 
                           stage_lows: List[Tuple[int, float, str]], output_file: str) -> Tuple[bool, Optional[Dict]]:
        """åˆ›å»ºç»Ÿä¸€ç‰ˆé«˜è´¨é‡å›¾è¡¨ - ä½¿ç”¨mplfinanceç»˜åˆ¶ä¸“ä¸šKçº¿å›¾"""
        try:
            # ä½¿ç”¨çº¿ç¨‹é”ç¡®ä¿matplotlibæ“ä½œçš„çº¿ç¨‹å®‰å…¨
            with matplotlib_lock:
                # åœ¨å¤šçº¿ç¨‹ç¯å¢ƒä¸‹ï¼Œç¡®ä¿matplotlibæ“ä½œçš„çº¿ç¨‹å®‰å…¨
                import matplotlib
                matplotlib.use('Agg')  # ç¡®ä¿ä½¿ç”¨éäº¤äº’å¼åç«¯
                
                import mplfinance as mpf
                
                # è·å–æœ€ä½ç‚¹ä½ç½®ï¼Œåªæ˜¾ç¤ºä»æœ€ä½ç‚¹å¼€å§‹å¾€åçš„æ•°æ®
                if stage_lows:
                    lowest_idx, _, _ = stage_lows[0]  # è·å–æœ€ä½ç‚¹çš„ç´¢å¼•
                    # æˆªå–ä»æœ€ä½ç‚¹å¼€å§‹çš„æ•°æ®
                    df_display = df.iloc[lowest_idx:].copy()
                    # ä¸è¦é‡ç½®ç´¢å¼•ï¼Œä¿æŒåŸå§‹ç´¢å¼•
                else:
                    # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°ä½ç‚¹ï¼Œæ˜¾ç¤ºå…¨éƒ¨æ•°æ®
                    df_display = df.copy()
                
                # å‡†å¤‡mplfinanceéœ€è¦çš„æ•°æ®æ ¼å¼
                df_mpf = df_display.copy()
                df_mpf['date'] = pd.to_datetime(df_mpf['date'])
                df_mpf.set_index('date', inplace=True)
                
                # ç¡®ä¿åˆ—åç¬¦åˆmplfinanceè¦æ±‚
                df_mpf = df_mpf[['open', 'high', 'low', 'close']].copy()
                
                # æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸ºç©º
                if df_mpf.empty:
                    logger.warning(f"âš ï¸ å¤„ç†åçš„æ•°æ®ä¸ºç©º: {stock_code}")
                    return False
                
                logger.debug(f"ğŸ“Š mplfinanceæ•°æ®: {len(df_mpf)} è¡Œ, åˆ—: {list(df_mpf.columns)}")
                
                # å‡†å¤‡é¢å¤–çš„ç»˜å›¾å…ƒç´ 
                additional_plots = []
                
                # 1. æ·»åŠ é˜¶æ®µä½ç‚¹æ°´å¹³çº¿
                for i, (idx, price, date_str) in enumerate(stage_lows):
                    # åˆ›å»ºæ°´å¹³çº¿æ•°æ®
                    hline_data = [price] * len(df_mpf)
                    additional_plots.append(mpf.make_addplot(hline_data, color='blue', linestyle='-', width=2, alpha=0.8))
                
                # 2. æ·»åŠ ç™¾åˆ†æ¯”æ¶¨å¹…çº¿
                if stage_lows:
                    base_price = min(price for _, price, _ in stage_lows)  # ä½¿ç”¨æœ€ä½ä»·ä½œä¸ºåŸºå‡†
                    max_price = df_mpf['high'].max()
                    
                    # å…ˆç”»Kçº¿è¦†ç›–èŒƒå›´å†…çš„ç™¾åˆ†æ¯”çº¿ï¼Œæ‰¾å‡ºæœ€ä¸Šæ–¹çš„ç™¾åˆ†æ¯”çº¿
                    visible_percent_lines = []
                    highest_visible_idx = -1  # è®°å½•æœ€é«˜å¯è§ç™¾åˆ†æ¯”çº¿çš„ç´¢å¼•
                    
                    for i, percent_str in enumerate(self.percent_list):
                        try:
                            percent = float(percent_str.rstrip('%')) / 100
                            target_price = base_price * (1 + percent)
                            
                            # Kçº¿è¦†ç›–èŒƒå›´å†…çš„ç™¾åˆ†æ¯”çº¿
                            if target_price <= max_price:
                                visible_percent_lines.append((percent_str, target_price))
                                highest_visible_idx = i  # æ›´æ–°æœ€é«˜å¯è§çº¿ç´¢å¼•
                                # åˆ›å»ºæ°´å¹³çº¿æ•°æ®
                                hline_data = [target_price] * len(df_mpf)
                                additional_plots.append(mpf.make_addplot(hline_data, color='hotpink', linestyle='--', width=3, alpha=0.8))
                        except (ValueError, TypeError):
                            continue
                
                    # åœ¨Kçº¿è¦†ç›–ä¸åˆ°çš„åŒºåŸŸå†ç”»ä¸€æ ¹ç™¾åˆ†æ¯”çº¿ï¼ˆå¦‚æœè¿˜æœ‰ä¸‹ä¸€æ ¹ï¼‰
                    if highest_visible_idx >= 0 and highest_visible_idx + 1 < len(self.percent_list):
                        try:
                            next_percent_str = self.percent_list[highest_visible_idx + 1]
                            next_percent = float(next_percent_str.rstrip('%')) / 100
                            next_target_price = base_price * (1 + next_percent)
                            
                            # ç”»å‡ºKçº¿ä¸Šæ–¹çš„ä¸‹ä¸€æ ¹ç™¾åˆ†æ¯”çº¿
                            hline_data = [next_target_price] * len(df_mpf)
                            additional_plots.append(mpf.make_addplot(hline_data, color='hotpink', linestyle='--', width=3, alpha=0.8))
                            visible_percent_lines.append((next_percent_str, next_target_price))
                            
                            logger.debug(f"âœ… åœ¨Kçº¿ä¸Šæ–¹æ·»åŠ é¢å¤–ç™¾åˆ†æ¯”çº¿: +{next_percent_str}")
                        except (ValueError, TypeError):
                            pass
                
                
                # è·å–è¡Œä¸šä¿¡æ¯
                industry = ""
                if stock_code in self.stock_info:
                    industry = self.stock_info[stock_code].get('industry', '')
                
                # æ„å»ºæ ‡é¢˜
                title_parts = [stock_code, stock_name]
                if industry and industry != "æœªçŸ¥è¡Œä¸š":
                    title_parts.append(f"({industry})")
                title = " ".join(title_parts) + " - Stage Low Points Analysis"
                
                # è®¾ç½®ä¸­æ–‡å­—ä½“
                import matplotlib.pyplot as plt
                plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
                plt.rcParams['axes.unicode_minus'] = False
                
                # è®¾ç½®mplfinanceæ ·å¼ - ä¸­å›½æ ‡å‡†é…è‰²ï¼šçº¢æ¶¨ç»¿è·Œ
                style = mpf.make_mpf_style(
                    base_mpf_style='charles',
                    marketcolors=mpf.make_marketcolors(
                        up='red',        # ä¸Šæ¶¨ä¸ºçº¢è‰²
                        down='green',    # ä¸‹è·Œä¸ºç»¿è‰²
                        edge='inherit',  # è¾¹æ¡†é¢œè‰²ç»§æ‰¿èœ¡çƒ›é¢œè‰²
                        wick='inherit',  # å½±çº¿é¢œè‰²ç»§æ‰¿èœ¡çƒ›é¢œè‰²
                        volume='inherit' # æˆäº¤é‡é¢œè‰²ç»§æ‰¿èœ¡çƒ›é¢œè‰²
                    ),
                    gridstyle='-',
                    gridcolor='lightgray',
                    y_on_right=True,
                    facecolor='white',
                    edgecolor='black',
                    figcolor='white',
                    rc={'font.size': 12, 'axes.titlesize': 20, 'axes.labelsize': 14, 
                        'font.sans-serif': ['SimHei', 'Arial Unicode MS', 'DejaVu Sans'],
                        'axes.unicode_minus': False}
                )
                
                # åˆ›å»ºå›¾è¡¨
                fig, axes = mpf.plot(
                    df_mpf,
                    type='candle',
                    style=style,
                    title=title,
                    ylabel='Price',
                    volume=False,
                    addplot=additional_plots if additional_plots else None,
                    figsize=(20, 12),
                    tight_layout=True,
                    returnfig=True,
                    panel_ratios=(1,),  # åªæ˜¾ç¤ºä¸»å›¾
                    show_nontrading=False,  # ä¸æ˜¾ç¤ºéäº¤æ˜“æ—¥
                    datetime_format='%Y-%m',  # æ—¥æœŸæ ¼å¼
                    xrotation=45  # Xè½´æ ‡ç­¾æ—‹è½¬
                )
                
                # æ·»åŠ ä»·æ ¼æ ‡æ³¨
                ax = axes[0]  # è·å–ä¸»å›¾è½´
                
                # è®¡ç®—éœ€è¦è°ƒæ•´çš„Yè½´èŒƒå›´
                if stage_lows:
                    base_price = min(price for _, price, _ in stage_lows)
                    max_price = df_mpf['high'].max()
                    min_price = df_mpf['low'].min()
                    
                    # è®¡ç®—æœ€é«˜çš„ç™¾åˆ†æ¯”çº¿ä»·æ ¼ï¼ˆåŒ…æ‹¬é¢å¤–çš„ä¸€æ ¹ï¼‰
                    highest_percent_price = max_price
                    highest_visible_idx = -1
                    
                    for i, percent_str in enumerate(self.percent_list):
                        try:
                            percent = float(percent_str.rstrip('%')) / 100
                            target_price = base_price * (1 + percent)
                            if target_price <= max_price:
                                highest_visible_idx = i
                                highest_percent_price = target_price
                        except (ValueError, TypeError):
                            continue
                    
                    # å¦‚æœæœ‰é¢å¤–çš„ç™¾åˆ†æ¯”çº¿ï¼Œè®¡ç®—å…¶ä»·æ ¼
                    if highest_visible_idx >= 0 and highest_visible_idx + 1 < len(self.percent_list):
                        try:
                            next_percent_str = self.percent_list[highest_visible_idx + 1]
                            next_percent = float(next_percent_str.rstrip('%')) / 100
                            next_target_price = base_price * (1 + next_percent)
                            highest_percent_price = next_target_price
                        except (ValueError, TypeError):
                            pass
                    
                    # è°ƒæ•´Yè½´èŒƒå›´ï¼Œç¡®ä¿æœ€é«˜çš„ç™¾åˆ†æ¯”çº¿åœ¨æ–¹æ¡†å†…
                    # ç•™å‡ºä¸€äº›ä¸Šä¸‹è¾¹è·ï¼ˆçº¦5%ï¼‰
                    y_margin = (highest_percent_price - min_price) * 0.05
                    ax.set_ylim(min_price - y_margin, highest_percent_price + y_margin)
                    
                    logger.debug(f"ğŸ“Š è°ƒæ•´Yè½´èŒƒå›´: {min_price:.2f} - {highest_percent_price:.2f}")
                
                # æ ‡æ³¨é˜¶æ®µä½ç‚¹ä»·æ ¼
                for i, (idx, price, date_str) in enumerate(stage_lows):
                    ax.text(1.02, price, f'{price:.2f}', 
                           fontsize=16, color='blue', fontweight='bold',
                           bbox=dict(boxstyle="round,pad=0.3", facecolor='white', alpha=0.8),
                           transform=ax.get_yaxis_transform(), ha='left', va='center')
                
                # æ ‡æ³¨ç™¾åˆ†æ¯”æ¶¨å¹…çº¿
                if stage_lows:
                    base_price = min(price for _, price, _ in stage_lows)
                    max_price = df_mpf['high'].max()
                    
                    # æ ‡æ³¨Kçº¿è¦†ç›–èŒƒå›´å†…çš„ç™¾åˆ†æ¯”çº¿ï¼Œå¹¶æ‰¾å‡ºæœ€é«˜çš„
                    highest_visible_idx = -1
                    for i, percent_str in enumerate(self.percent_list):
                        try:
                            percent = float(percent_str.rstrip('%')) / 100
                            target_price = base_price * (1 + percent)
                            
                            if target_price <= max_price:  # Kçº¿è¦†ç›–èŒƒå›´å†…
                                highest_visible_idx = i
                                ax.text(1.02, target_price, f'+{percent_str}', 
                                       fontsize=18, color='#8B7355', fontweight='bold',
                                       bbox=dict(boxstyle="round,pad=0.3", facecolor='white', alpha=0.9, edgecolor='#8B7355', linewidth=2),
                                       transform=ax.get_yaxis_transform(), ha='left', va='center')
                        except (ValueError, TypeError):
                            continue
                    
                    # æ ‡æ³¨Kçº¿ä¸Šæ–¹çš„é¢å¤–ç™¾åˆ†æ¯”çº¿
                    if highest_visible_idx >= 0 and highest_visible_idx + 1 < len(self.percent_list):
                        try:
                            next_percent_str = self.percent_list[highest_visible_idx + 1]
                            next_percent = float(next_percent_str.rstrip('%')) / 100
                            next_target_price = base_price * (1 + next_percent)
                            
                            ax.text(1.02, next_target_price, f'+{next_percent_str}', 
                                   fontsize=18, color='#8B7355', fontweight='bold',
                                   bbox=dict(boxstyle="round,pad=0.3", facecolor='white', alpha=0.9, edgecolor='#8B7355', linewidth=2),
                                   transform=ax.get_yaxis_transform(), ha='left', va='center')
                        except (ValueError, TypeError):
                            pass
                
                # ==================== ç»˜åˆ¶AnchorMçº¿ ====================
                m_lines_result = None
                if self.anchor_m_config.get('enabled', True) and stage_lows:
                    try:
                        # ç›´æ¥ä½¿ç”¨find_stage_lows_unifiedè®¡ç®—çš„é˜¶æ®µä½ç‚¹ä½œä¸ºé”šå®šä½ç‚¹
                        # è¯¥ä½ç‚¹å·²ç»é€šè¿‡ZigZag(L,49)ç®—æ³•å’Œä½ç‚¹ä¼˜åŒ–é€»è¾‘å¤„ç†è¿‡äº†
                        anchor_idx, anchor_low, anchor_date = stage_lows[0]
                        logger.debug(f"ğŸ“ AnchorMé”šç‚¹: æ—¥æœŸ={anchor_date}, ä»·æ ¼={anchor_low:.2f}")
                        
                        # è®¡ç®—æœ€ä½³Må€¼å’ŒBåºåˆ—
                        m_lines_result = self.compute_anchor_M_lines(df, anchor_low, anchor_date)
                        
                        if m_lines_result:
                            best_M = m_lines_result['best_M']
                            B_values = m_lines_result['B_values']
                            K_values = m_lines_result['K_values']
                            per_k_matches = m_lines_result['per_k_matches']
                            
                            # ç»˜åˆ¶ç´«è‰²æ¨ªçº¿(ç”¨äºè¯„åˆ†çš„æå€¼)
                            line_style = self.anchor_m_config.get('line_style', {})
                            line_color = line_style.get('color', '#8A2BE2')
                            line_width = line_style.get('linewidth', 1.0)
                            line_alpha = line_style.get('alpha', 0.85)
                            
                            text_style = self.anchor_m_config.get('text_style', {})
                            text_fontsize = text_style.get('fontsize', 8)
                            annotate_format = self.anchor_m_config.get('annotate_format', 'K={K} ä»·æ ¼={price}')
                            
                            # ç»˜åˆ¶ç´«è‰²æ¨ªçº¿ - æ¯ä¸ªKå€¼å¯¹åº”ä¸€æ¡çº¿(B_kä»·æ ¼)
                            # ä½¿ç”¨æœ€ä½³Må€¼å¯¹åº”çš„Båºåˆ—å’ŒKå€¼
                            for k_val, B_k_price in zip(K_values, B_values):
                                # ç»˜åˆ¶æ¨ªçº¿(åŠ ç²—) - ä½¿ç”¨B_kçš„ä»·æ ¼
                                ax.axhline(y=B_k_price, color=line_color, 
                                          linestyle='-', linewidth=line_width, 
                                          alpha=line_alpha, zorder=2.5)
                                
                                # æ ‡æ³¨ä»·æ ¼å’ŒKå€¼(æ”¾åœ¨å·¦è¾¹,åŠ ç²—)
                                label_text = annotate_format.replace('{K}', str(k_val)).replace('{price}', f'{B_k_price:.2f}')
                                ax.text(-0.02, B_k_price, label_text,
                                       fontsize=text_fontsize, color=line_color, fontweight='bold',
                                       bbox=dict(boxstyle="round,pad=0.4", facecolor='white', alpha=0.85, edgecolor=line_color, linewidth=2),
                                       transform=ax.get_yaxis_transform(), ha='right', va='center')
                            
                            # åœ¨å›¾ç‰‡å·¦ä¸Šè§’æ·»åŠ Må€¼å’ŒBåºåˆ—ä¿¡æ¯
                            # æ„å»ºæ–‡æœ¬å†…å®¹
                            text_lines = [f"M={best_M:.1f}%"]
                            # Båºåˆ—å¯èƒ½å¾ˆé•¿,é™åˆ¶æ˜¾ç¤ºå‰10ä¸ª
                            B_display = [f'{b:.2f}' for b in B_values[:10]]
                            if len(B_values) > 10:
                                B_display.append('...')
                            text_lines.append(f"B: [{', '.join(B_display)}]")
                            text_lines.append(f"Score: {m_lines_result['avg_score']:.1f}")
                            text_lines.append(f"Matches: {m_lines_result['matches_count']}")
                            
                            # åœ¨å·¦ä¸Šè§’æ·»åŠ æ–‡æœ¬æ¡†(æ”¾å¤§å­—ä½“)
                            text_content = '\n'.join(text_lines)
                            ax.text(0.01, 0.98, text_content,
                                   transform=ax.transAxes,
                                   fontsize=12, color='purple', fontweight='bold',
                                   bbox=dict(boxstyle="round,pad=0.6", facecolor='white', alpha=0.95, edgecolor='purple', linewidth=2.5),
                                   ha='left', va='top', family='monospace')
                            
                            logger.debug(f"âœ… å·²ç»˜åˆ¶AnchorMçº¿: M={best_M:.1f}%, {len(B_values)}æ¡B_kçº¿")
                        else:
                            logger.debug(f"âš ï¸ æœªèƒ½è®¡ç®—AnchorMçº¿")
                    except Exception as e:
                        logger.warning(f"âš ï¸ ç»˜åˆ¶AnchorMçº¿æ—¶å‡ºé”™: {e}")
                        import traceback
                        logger.debug(traceback.format_exc())
                
                # é‡æ–°ä¿å­˜å¸¦æ ‡æ³¨çš„å›¾è¡¨
                plt.savefig(output_file, dpi=200, bbox_inches='tight', facecolor='white', edgecolor='none')
                
                # å…³é—­å›¾å½¢ä»¥é‡Šæ”¾å†…å­˜
                plt.close(fig)
                
                # è°ƒæ•´å›¾ç‰‡å°ºå¯¸åˆ°ç²¾ç¡®çš„ç›®æ ‡å°ºå¯¸
                try:
                    from PIL import Image
                    with Image.open(output_file) as img:
                        # è°ƒæ•´åˆ°ç²¾ç¡®çš„ç›®æ ‡å°ºå¯¸ (3991 x 2392)
                        target_width = 3991
                        target_height = 2392
                        resized_img = img.resize((target_width, target_height), Image.Resampling.LANCZOS)
                        resized_img.save(output_file, 'PNG', quality=95)
                        logger.debug(f"âœ… å›¾ç‰‡å°ºå¯¸å·²è°ƒæ•´: {target_width}x{target_height}")
                except ImportError:
                    logger.warning("âš ï¸ PILæœªå®‰è£…ï¼Œæ— æ³•è°ƒæ•´å›¾ç‰‡å°ºå¯¸")
                except Exception as e:
                    logger.warning(f"âš ï¸ è°ƒæ•´å›¾ç‰‡å°ºå¯¸å¤±è´¥: {e}")
                
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æˆåŠŸç”Ÿæˆ
                if os.path.exists(output_file):
                    file_size = os.path.getsize(output_file)
                    if file_size > 1000:  # è‡³å°‘1KB
                        logger.debug(f"âœ… å›¾è¡¨æ–‡ä»¶ç”ŸæˆæˆåŠŸ: {output_file} ({file_size} bytes)")
                        return True, m_lines_result
                    else:
                        logger.warning(f"âš ï¸ ç”Ÿæˆçš„å›¾ç‰‡æ–‡ä»¶è¿‡å°: {output_file} ({file_size} bytes)")
                        return False, None
                else:
                    logger.error(f"âŒ å›¾è¡¨æ–‡ä»¶æœªç”Ÿæˆ: {output_file}")
                    return False, None
                    
        except Exception as e:
            logger.error(f"âŒ å›¾è¡¨åˆ›å»ºå¤±è´¥ {stock_code}: {type(e).__name__}: {e}")
            import traceback
            logger.debug(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            return False, None
        finally:
            # ç¡®ä¿é‡Šæ”¾matplotlibèµ„æº
            try:
                plt.close('all')  # å…³é—­æ‰€æœ‰å›¾å½¢
            except Exception as cleanup_error:
                logger.debug(f"èµ„æºæ¸…ç†å¼‚å¸¸: {cleanup_error}")
                pass
    
    def process_stock_list(self, stock_list: List[Tuple[str, str, str, str]], 
                          output_dir: str = None, data_dir: str = "../data", workers: int = 4):
        """å¤„ç†æŒ‡å®šçš„è‚¡ç¥¨åˆ—è¡¨"""
        # å¦‚æœæœªæŒ‡å®šè¾“å‡ºç›®å½•ï¼Œä½¿ç”¨å¸¦æ—¥æœŸçš„é»˜è®¤ç›®å½•
        if output_dir is None:
            current_date = datetime.now().strftime('%Y%m%d')
            output_dir = f'{current_date}-drawLineRes'
        
        logger.info(f"ğŸš€ å¼€å§‹å¤„ç†æŒ‡å®šè‚¡ç¥¨åˆ—è¡¨")
        logger.info(f"ğŸ“ æ•°æ®ç›®å½•: {data_dir}")
        logger.info(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        logger.info(f"ğŸ§µ çº¿ç¨‹æ•°: {workers}")
        
        if not stock_list:
            logger.error("âŒ è‚¡ç¥¨åˆ—è¡¨ä¸ºç©º")
            return
        
        self.total_count = len(stock_list)
        self.processed_count = 0
        
        logger.info(f"ğŸ“Š å¾…å¤„ç†è‚¡ç¥¨æ•°é‡: {self.total_count}")
        
        # æ¸…ç©ºå¹¶é‡æ–°åˆ›å»ºè¾“å‡ºç›®å½•
        if os.path.exists(output_dir):
            import shutil
            logger.info(f"ğŸ—‘ï¸  æ¸…ç©ºè¾“å‡ºç›®å½•: {output_dir}")
            try:
                shutil.rmtree(output_dir)
                logger.info(f"âœ… å·²æ¸…ç©ºè¾“å‡ºç›®å½•")
            except Exception as e:
                logger.warning(f"âš ï¸  æ¸…ç©ºè¾“å‡ºç›®å½•æ—¶å‡ºé”™: {e}")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        logger.info(f"ğŸ“ åˆ›å»ºè¾“å‡ºç›®å½•: {output_dir}")
        
        # å¤šçº¿ç¨‹å¤„ç†
        start_time = time.time()
        results = []
        
        with ThreadPoolExecutor(max_workers=workers) as executor:
            # æäº¤ä»»åŠ¡
            future_to_stock = {
                executor.submit(self._process_single_stock, code, name, output_dir, data_dir, file_prefix): (code, name, industry, file_prefix)
                for code, name, industry, file_prefix in stock_list
            }
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_stock):
                result = future.result()
                results.append(result)
        
        # ç»Ÿè®¡ç»“æœ
        total_time = time.time() - start_time
        success_count = sum(1 for r in results if r['success'])
        failed_count = len(results) - success_count
        
        logger.info(f"ğŸ‰ è‚¡ç¥¨åˆ—è¡¨å¤„ç†å®Œæˆ!")
        logger.info(f"ğŸ“Š æ€»è®¡: {len(results)}åªè‚¡ç¥¨")
        logger.info(f"âœ… æˆåŠŸ: {success_count}åª")
        logger.info(f"âŒ å¤±è´¥: {failed_count}åª")
        logger.info(f"â±ï¸ æ€»è€—æ—¶: {total_time:.2f}ç§’")
        logger.info(f"âš¡ å¹³å‡é€Ÿåº¦: {len(results)/total_time:.2f}åª/ç§’")
        
        # ä¿å­˜å¤„ç†ç»“æœ
        results_file = os.path.join(output_dir, "processing_results.json")
        try:
            with open(results_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            logger.info(f"ğŸ“„ å¤„ç†ç»“æœå·²ä¿å­˜: {results_file}")
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")
        
        # æ˜¾ç¤ºå¤±è´¥çš„è‚¡ç¥¨
        failed_stocks = [r for r in results if not r['success']]
        if failed_stocks:
            logger.warning(f"âš ï¸ å¤±è´¥çš„è‚¡ç¥¨:")
            for r in failed_stocks[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                logger.warning(f"   {r['stock_code']} {r['stock_name']}: {r['error']}")
            if len(failed_stocks) > 10:
                logger.warning(f"   ... è¿˜æœ‰{len(failed_stocks)-10}åªè‚¡ç¥¨å¤±è´¥")

    def _process_single_stock(self, stock_code: str, stock_name: str, 
                           output_dir: str, data_dir: str, file_prefix: str = "") -> dict:
        """å¤„ç†å•åªè‚¡ç¥¨ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰"""
        start_time = time.time()
        result = {
            'stock_code': stock_code,
            'stock_name': stock_name,
            'success': False,
            'elapsed_time': 0,
            'error': None,
            'stage_lows_count': 0
        }
        
        try:
            # 1. éªŒè¯å¹¶åŠ è½½æ•°æ®
            df = self.validate_and_load_data(stock_code, data_dir)
            if df is None:
                result['error'] = "æ•°æ®åŠ è½½å¤±è´¥"
                return result
            
            # 2. æ£€æµ‹é˜¶æ®µä½ç‚¹
            stage_lows = self.find_stage_lows_unified(df)
            if not stage_lows:
                result['error'] = "æœªæ£€æµ‹åˆ°é˜¶æ®µä½ç‚¹"
                return result
            
            result['stage_lows_count'] = len(stage_lows)
            
            # 3. åˆ›å»ºè¾“å‡ºç›®å½•
            os.makedirs(output_dir, exist_ok=True)
            
            # 4. ç”Ÿæˆå›¾è¡¨
            # æ ¹æ®æ–‡ä»¶å‰ç¼€ç”Ÿæˆå¸¦å‰ç¼€çš„æ–‡ä»¶å
            if file_prefix and file_prefix != "UNKNOWN":
                output_file = os.path.join(output_dir, f"{file_prefix}_{stock_code}_{stock_name}.png")
            else:
                output_file = os.path.join(output_dir, f"{stock_code}_{stock_name}.png")
            success, m_lines_result = self.create_unified_chart(stock_code, stock_name, df, stage_lows, output_file)
            
            if success:
                result['success'] = True
                
                # æ·»åŠ AnchorMçº¿ç»“æœ
                if m_lines_result:
                    result['anchorMLines'] = {
                        'best_M': m_lines_result['best_M'],
                        'avg_score': m_lines_result['avg_score'],
                        'matches_count': m_lines_result['matches_count'],
                        'B_values': m_lines_result['B_values'][:10],  # åªä¿å­˜å‰10ä¸ª
                        'anchor_low': m_lines_result['anchor_low'],
                        'anchor_date': str(m_lines_result['anchor_date'])
                    }
                
                # æ›´æ–°è¿›åº¦
                with progress_lock:
                    self.processed_count += 1
                    m_info = f", M={m_lines_result['best_M']:.1f}%" if m_lines_result else ""
                    logger.info(f"âœ… [{self.processed_count}/{self.total_count}] {stock_code} {stock_name} - {len(stage_lows)}ä¸ªä½ç‚¹{m_info}")
            else:
                result['error'] = "å›¾è¡¨åˆ›å»ºå¤±è´¥"
            
        except Exception as e:
            result['error'] = str(e)
            logger.error(f"âŒ å¤„ç†è‚¡ç¥¨å¤±è´¥ {stock_code}: {e}")
        
        finally:
            result['elapsed_time'] = time.time() - start_time
        
        return result


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="åŸºç¡€å±‚ç”»çº¿è„šæœ¬ - è¯»å–resByFilterä¸­çš„è‚¡ç¥¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # é»˜è®¤è¡Œä¸ºï¼šè¯»å–å½“å‰æ—¥æœŸçš„resByFilterä¸­çš„è‚¡ç¥¨
  python draw_lines_unified.py
  
  # è¯»å–æŒ‡å®šæ—¥æœŸçš„resByFilterä¸­çš„è‚¡ç¥¨
  python draw_lines_unified.py --date 2025-01-15
  
  # æŒ‡å®šçº¿ç¨‹æ•°
  python draw_lines_unified.py --workers 6
        """
    )
    
    # ç”Ÿæˆå¸¦æ—¥æœŸçš„é»˜è®¤è¾“å‡ºç›®å½•
    current_date = datetime.now().strftime('%Y%m%d')
    
    # å‚æ•°
    parser.add_argument('--date', type=str, 
                       help='æ—¥æœŸå‚æ•°ï¼Œæ ¼å¼ä¸ºYYYY-MM-DDï¼Œç”¨äºæ„å»ºresByFilterç›®å½•')
    parser.add_argument('--workers', type=int, default=4,
                       help='å¹¶å‘å¤„ç†çš„çº¿ç¨‹æ•° (é»˜è®¤: 4)')
    
    args = parser.parse_args()
    
    # å¤„ç†æ—¥æœŸå‚æ•°
    if args.date:
        try:
            # éªŒè¯æ—¥æœŸæ ¼å¼å¹¶è½¬æ¢
            date_obj = datetime.strptime(args.date, '%Y-%m-%d')
            date_str = date_obj.strftime('%Y%m%d')
        except ValueError:
            logger.error(f"âŒ æ—¥æœŸæ ¼å¼é”™è¯¯: {args.date}ï¼Œè¯·ä½¿ç”¨YYYY-MM-DDæ ¼å¼")
            sys.exit(1)
    else:
        date_str = current_date
    
    # åˆ›å»ºç»Ÿä¸€ç”»çº¿å™¨
    drawer = UnifiedLineDrawer()
    
    # è¯»å–æŒ‡å®šæ—¥æœŸçš„resByFilterä¸­çš„è‚¡ç¥¨
    filter_dir = f"../{date_str}-resByFilter"
    if not os.path.exists(filter_dir):
        logger.error(f"âŒ ç›®å½•ä¸å­˜åœ¨: {filter_dir}")
        logger.info(f"ğŸ’¡ æç¤ºï¼šè¯·ç¡®ä¿å­˜åœ¨ {filter_dir} ç›®å½•")
        sys.exit(1)
    
    # æŸ¥æ‰¾æ‰€æœ‰CSVæ–‡ä»¶ï¼ˆPDIå’ŒADXç»“æœæ–‡ä»¶ï¼‰
    csv_files = glob.glob(os.path.join(filter_dir, "*.csv"))
    if not csv_files:
        logger.error(f"âŒ åœ¨ç›®å½• {filter_dir} ä¸­æœªæ‰¾åˆ°CSVæ–‡ä»¶")
        logger.info(f"ğŸ’¡ æç¤ºï¼šè¯·åœ¨ {filter_dir} ç›®å½•ä¸­æ”¾ç½®è‚¡ç¥¨åˆ—è¡¨CSVæ–‡ä»¶")
        sys.exit(1)
    
    logger.info(f"ğŸ“ æ‰¾åˆ° {len(csv_files)} ä¸ªCSVæ–‡ä»¶")
    
    # è¯»å–æ‰€æœ‰CSVæ–‡ä»¶ä¸­çš„è‚¡ç¥¨ï¼Œå¹¶å»é‡
    all_stocks = {}  # ä½¿ç”¨å­—å…¸å»é‡ï¼Œkeyä¸ºè‚¡ç¥¨ä»£ç 
    
    for file_path in csv_files:
        logger.info(f"ğŸ“„ è¯»å–æ–‡ä»¶: {file_path}")
        try:
            import pandas as pd
            df = pd.read_csv(file_path)
            
            # ä»æ–‡ä»¶åæå–å‰ç¼€ç±»å‹ï¼ˆä¿æŒåŸå§‹æ•°å­—ï¼‰
            file_name = os.path.basename(file_path)
            file_prefix = ""
            
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–ADXæˆ–PDIåçš„æ•°å­—
            import re
            
            # å®šä¹‰åŒ¹é…æ¨¡å¼
            patterns = [
                (r'^ADX(\d+)', 'ADX'),  # åŒ¹é…å¼€å¤´çš„ADX
                (r'^PDI(\d+)', 'PDI'),  # åŒ¹é…å¼€å¤´çš„PDI
                (r'ADX(\d+)', 'ADX'),    # åŒ¹é…ä»»æ„ä½ç½®çš„ADX
                (r'PDI(\d+)', 'PDI')     # åŒ¹é…ä»»æ„ä½ç½®çš„PDI
            ]
            
            # æŒ‰ä¼˜å…ˆçº§å°è¯•åŒ¹é…
            for pattern, prefix_type in patterns:
                match = re.search(pattern, file_name.upper())
                if match:
                    file_prefix = f"{prefix_type}{match.group(1)}"
                    break
            
            logger.info(f"ğŸ“Š æ–‡ä»¶ç±»å‹: {file_prefix}")
            
            # ä»CSVæ–‡ä»¶ä¸­æå–è‚¡ç¥¨ä¿¡æ¯
            for _, row in df.iterrows():
                code = str(row.get('code', ''))
                name = str(row.get('name', code))
                industry = str(row.get('industry', 'æœªçŸ¥è¡Œä¸š'))
                
                # æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç ï¼ˆè¡¥é›¶åˆ°6ä½ï¼‰
                if code:
                    normalized_code = code.zfill(6)
                    if normalized_code not in all_stocks:
                        # æ‰©å±•è‚¡ç¥¨ä¿¡æ¯ï¼ŒåŒ…å«æ–‡ä»¶å‰ç¼€
                        all_stocks[normalized_code] = (normalized_code, name, industry, file_prefix)
                        
        except Exception as e:
            logger.error(f"âŒ è¯»å–æ–‡ä»¶ {file_path} å¤±è´¥: {e}")
            continue
    
    if not all_stocks:
        logger.error(f"âŒ æœªè¯»å–åˆ°æœ‰æ•ˆçš„è‚¡ç¥¨æ•°æ®")
        sys.exit(1)
    
    # è½¬æ¢ä¸ºåˆ—è¡¨
    stock_list = list(all_stocks.values())
    logger.info(f"ğŸ“‹ å»é‡åå…±æœ‰ {len(stock_list)} åªè‚¡ç¥¨")
    
    # ç”Ÿæˆè¾“å‡ºç›®å½•
    output_dir = f"{date_str}-drawLineRes"
    
    # æ‰¹é‡å¤„ç†è‚¡ç¥¨åˆ—è¡¨
    drawer.process_stock_list(stock_list, output_dir, "../data", args.workers)
    
    logger.info("ğŸ‰ ç¨‹åºæ‰§è¡Œå®Œæˆ!")


if __name__ == "__main__":
    main()